[
  {
    "id": "552661142",
    "name": "langchain",
    "full_name": "langchain-ai/langchain",
    "category": "llm_rag",
    "stars": 124281,
    "forks": 20479,
    "description": "ğŸ¦œğŸ”— The platform for reliable agents.",
    "url": "https://github.com/langchain-ai/langchain",
    "homepage": "https://docs.langchain.com/oss/python/langchain/",
    "language": "Python",
    "topics": "[\"agents\", \"ai\", \"ai-agents\", \"anthropic\", \"chatgpt\", \"deepagents\", \"enterprise\", \"framework\", \"gemini\", \"generative-ai\", \"langchain\", \"langgraph\", \"llm\", \"multiagent\", \"open-source\", \"openai\", \"pydantic\", \"python\", \"rag\"]",
    "created_at": "2022-10-17T02:58:36Z",
    "updated_at": "2026-01-15T17:45:33Z",
    "readme_content": null,
    "ai_summary": "LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¯é å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†å’Œåº”ç”¨çš„æ¡†æ¶ï¼Œé€šè¿‡æ¨¡å—åŒ–è®¾è®¡å®ç°ç»„ä»¶é—´çš„äº’æ“ä½œæ€§ï¼Œæ”¯æŒå¤šä»£ç†åä½œã€å·¥å…·è°ƒç”¨ã€è®°å¿†ç®¡ç†å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆç­‰åŠŸèƒ½ã€‚",
    "ai_tech_stack": "[\"Python\", \"FastAPI\", \"ChromaDB\", \"LangGraph\"]",
    "ai_use_cases": "[\"\\u6784\\u5efa\\u4f01\\u4e1a\\u7ea7\\u667a\\u80fd\\u5ba2\\u670d\\u7cfb\\u7edf\", \"\\u5f00\\u53d1\\u81ea\\u52a8\\u5316\\u4e1a\\u52a1\\u6d41\\u7a0b\\u4ee3\\u7406\\uff08\\u5982\\u8ba2\\u5355\\u5904\\u7406\\u673a\\u5668\\u4eba\\uff09\", \"\\u5b9e\\u73b0\\u591a\\u6a21\\u6001\\u5bf9\\u8bdd\\u5e94\\u7528\", \"\\u642d\\u5efa\\u68c0\\u7d22\\u589e\\u5f3a\\u751f\\u6210\\uff08RAG\\uff09\\u77e5\\u8bc6\\u5e93\\u95ee\\u7b54\\u7cfb\\u7edf\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "pip install langchain",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nLangChain çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äºï¼š**å®ƒä¸æ˜¯å¦ä¸€ä¸ª LLM è°ƒç”¨å°è£…åº“ï¼Œè€Œæ˜¯ç¬¬ä¸€ä¸ªçœŸæ­£å°†â€œAI Agentâ€ä½œä¸ºä¸€ç­‰å…¬æ°‘è¿›è¡Œç³»ç»Ÿæ€§å»ºæ¨¡çš„å·¥ä¸šåŒ–æ¡†æ¶**ã€‚\n\nä¸åŒç±»é¡¹ç›®ï¼ˆå¦‚ LlamaIndexã€AutoGenã€Semantic Kernelï¼‰ç›¸æ¯”ï¼š\n\n- **LlamaIndex** ä¸“æ³¨æ£€ç´¢å¢å¼ºï¼ˆRAGï¼‰ï¼Œæ˜¯â€œæ–‡æ¡£â†’å‘é‡â†’ç­”æ¡ˆâ€çš„å•å‘æµæ°´çº¿ï¼Œç¼ºä¹åŠ¨æ€å†³ç­–èƒ½åŠ›ã€‚\n- **AutoGen** å¼ºè°ƒå¤šæ™ºèƒ½ä½“åä½œï¼Œä½†å…¶é€šä¿¡åè®®å’ŒçŠ¶æ€ç®¡ç†é«˜åº¦è€¦åˆäºå¾®è½¯çš„ Azure æœåŠ¡ç”Ÿæ€ï¼Œå¯ç§»æ¤æ€§å·®ã€‚\n- **Semantic Kernel** ä¸ Microsoft ç”Ÿæ€ç»‘å®šå¤ªæ·±ï¼ˆ.NETã€Azure AIï¼‰ï¼ŒPython å¼€å‘è€…ä½“éªŒå‰²è£‚ã€‚\n\nLangChain çš„çªç ´åœ¨äºï¼š\n> âœ… **æ ‡å‡†åŒ–â€œå·¥å…·è°ƒç”¨ â†’ è®¡åˆ’ â†’ æ‰§è¡Œ â†’ åé¦ˆâ€å¾ªç¯çš„æŠ½è±¡æ¥å£**ï¼Œè®© Agent ä¸å†æ˜¯é»‘ç›’ prompt å·¥ç¨‹ï¼Œè€Œæ˜¯ä¸€ä¸ªå¯ç»„åˆã€å¯è§‚æµ‹ã€å¯è°ƒè¯•çš„è½¯ä»¶æ„ä»¶ã€‚\n>\n> âœ… **é€šè¿‡ `Runnable` æ¥å£ç»Ÿä¸€äº† LLMã€Promptã€Toolã€Retrieverã€Chain çš„è°ƒç”¨è¯­ä¹‰** â€”â€” æ‰€æœ‰ç»„ä»¶éƒ½æ”¯æŒ `.invoke()`ã€`.stream()`ã€`.batch()`ï¼Œå®ç°çœŸæ­£çš„â€œæ’ä»¶å¼æµæ°´çº¿â€ã€‚\n>\n> âœ… **LangSmith é›†æˆæ˜¯ç”Ÿäº§çº§çš„æ€æ‰‹é”**ï¼šç«¯åˆ°ç«¯ tracingã€è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚ faithfulness, relevanceï¼‰ã€A/B æµ‹è¯•ã€æ•°æ®é›†ç‰ˆæœ¬ç®¡ç†ï¼Œè®© Agent å¼€å‘ä»â€œå®éªŒâ€èµ°å‘â€œå·¥ç¨‹â€ã€‚\n\nå®ƒè§£å†³çš„æ ¸å¿ƒç—›ç‚¹æ˜¯ï¼š**åœ¨ LLM æ¨¡å‹å¿«é€Ÿè¿­ä»£ã€å·¥å…·ç”Ÿæ€ç¢ç‰‡åŒ–çš„èƒŒæ™¯ä¸‹ï¼Œå¦‚ä½•æ„å»ºå¯ç»´æŠ¤ã€å¯å¤ç”¨ã€å¯ç›‘æ§çš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼Ÿ**\n\n---\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n1. **Runnable Protocolï¼ˆå¯è¿è¡Œåè®®ï¼‰**\n   - æ‰€æœ‰ç»„ä»¶ï¼ˆPromptTemplateã€LLMã€Toolã€Chainï¼‰éƒ½å®ç° `Runnable` æ¥å£ï¼š`.invoke(input) â†’ output`, `.stream(input) â†’ iterator`, `.batch(inputs) â†’ list[outputs]`\n   - **å·§å¦™ä¹‹å¤„**ï¼šé€šè¿‡ç±»å‹æ³¨è§£ `Input, Output, Config` å®ç°æ³›å‹ç¼–è¯‘æ—¶å®‰å…¨ï¼ŒåŒæ—¶æ”¯æŒå¼‚æ­¥/åŒæ­¥åŒæ¨¡å¼ã€‚\n   - ä½¿å¾—ä½ å¯ä»¥åƒç»„åˆå‡½æ•°ä¸€æ ·å†™ï¼š`chain = prompt | llm | output_parser`\n\n2. **åŠ¨æ€å·¥å…·æ³¨å†Œä¸æ‰§è¡Œå™¨ï¼ˆToolExecutorï¼‰**\n   - å·¥å…·ï¼ˆToolï¼‰è¢«æŠ½è±¡ä¸º `BaseTool`ï¼ŒåŒ…å« `name`, `description`, `args_schema`, `_run()`/`_arun()`\n   - æ”¯æŒè‡ªåŠ¨å‚æ•°è§£æï¼ˆPydantic Schema â†’ JSON Schema â†’ OpenAI Function Callingï¼‰\n   - **å…³é”®åˆ›æ–°**ï¼šå·¥å…·æ‰§è¡Œå™¨æ”¯æŒâ€œå¤±è´¥é‡è¯• + è¯­ä¹‰æ¢å¤â€â€”â€”å½“ LLM è¿”å›æ— æ•ˆå‡½æ•°è°ƒç”¨æ—¶ï¼Œè‡ªåŠ¨æç¤ºæ¨¡å‹ä¿®æ­£ï¼Œè€Œéç›´æ¥æŠ¥é”™ã€‚\n\n3. **Memory with Stateful Context**\n   - `BaseChatMessageHistory` æŠ½è±¡å±‚æ”¯æŒ Redisã€PostgreSQLã€In-Memory ç­‰å¤šç§åç«¯\n   - é€šè¿‡ `RunnableWithMessageHistory` å®ç°â€œå¯¹è¯çŠ¶æ€æ„ŸçŸ¥é“¾â€ï¼Œåœ¨ä¸ä¿®æ”¹ä¸šåŠ¡é€»è¾‘çš„å‰æä¸‹ï¼Œè‡ªåŠ¨æ³¨å…¥å†å²ä¸Šä¸‹æ–‡ã€‚\n\n4. **LangGraphï¼šåŸºäºæœ‰å‘å›¾çš„çŠ¶æ€æœºå¼•æ“**\n   - éå¸¸è§„è®¾è®¡ï¼šç”¨ `StateGraph` + `Node` + `Edge` æ„å»º Agent çš„å†³ç­–æµï¼ˆéçº¿æ€§ï¼ï¼‰\n   - æ”¯æŒæ¡ä»¶åˆ†æ”¯ã€å¾ªç¯ã€å¹¶è¡Œæ‰§è¡Œï¼ˆå¦‚ â€œè‹¥ç½®ä¿¡åº¦<0.7ï¼Œåˆ™è°ƒç”¨äººå·¥å®¡æ ¸â€ï¼‰\n   - ä¸ LangChain è§£è€¦ä½†æ— ç¼é›†æˆï¼Œæ˜¯ç”Ÿäº§çº§ Agent ç¼–æ’çš„é‡Œç¨‹ç¢‘ã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n#### 1. æ•´ä½“æ¶æ„å›¾ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\n[User Input]\n      â†“\n[RunnableSequence] â†â”€â”€â”€â”\n     â”‚ (invoke/stream)   â”‚\n     â†“                   â”‚\n[PromptTemplate]         â”‚\n     â†“                   â”‚\n[LLM/ChatModel]          â”‚  â†â”€ å¯æ›¿æ¢æ¨¡å‹åç«¯ï¼ˆOpenAI, Anthropic, Local LLMï¼‰\n     â†“                   â”‚\n[OutputParser]           â”‚\n     â†“                   â”‚\n[ToolExecutor] â†â”€â”€â”€â”€â”€â”€â”   â”‚\n     â”‚ (è°ƒç”¨å¤–éƒ¨API)    â”‚   â”‚\n     â†“                 â”‚   â”‚\n[Memory] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â†â”€ çŠ¶æ€æŒä¹…åŒ–\n     â†“                    â”‚\n[Output to User]          â”‚\n                          â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ LangSmith (Tracing, Evaluation, Datasets, Feedback) â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n#### 2. æ ¸å¿ƒæ¨¡å—åˆ’åˆ†\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| `llms/` | æŠ½è±¡æ¨¡å‹æ¥å£ï¼ˆOpenAIã€Cohereã€HuggingFaceã€Localï¼‰ |\n| `prompts/` | æ”¯æŒæ¨¡æ¿å˜é‡ã€few-shot ç¤ºä¾‹ã€ç»“æ„åŒ–è¾“å‡ºæ ¼å¼ï¼ˆå¦‚ JSON Modeï¼‰ |\n| `tools/` | é¢„ç½®å·¥å…·åº“ï¼ˆSearch, PythonREPL, WolframAlpha...ï¼‰ï¼Œæ”¯æŒè‡ªå®šä¹‰ |\n| `retrievers/` | å‘é‡æ£€ç´¢ + æ··åˆæ£€ç´¢ï¼ˆBM25 + Denseï¼‰+ å¤šè·¯å¬å›èåˆ |\n| `memory/` | ä¼šè¯çŠ¶æ€ç®¡ç†ï¼Œæ”¯æŒä¸Šä¸‹æ–‡å‹ç¼©ã€æ‘˜è¦ç¼“å­˜ |\n| `chains/` | é¢„æ„å»ºæµæ°´çº¿ï¼ˆå¦‚ QA Chain, StuffChain, MapReduceï¼‰ |\n| `agents/` | åŸºäº ReAct / Plan-and-Execute çš„å†³ç­–å¼•æ“ï¼Œè°ƒç”¨ ToolExecutor |\n| `callbacks/` | äº‹ä»¶é’©å­ï¼štoken è®¡æ•°ã€æ—¥å¿—ã€ç›‘æ§æŒ‡æ ‡ä¸ŠæŠ¥ |\n| `langgraph/` | çŠ¶æ€å›¾ç¼–æ’å™¨ï¼ˆç‹¬ç«‹åŒ…ï¼Œä½†æ·±åº¦é›†æˆï¼‰ |\n\n#### 3. æ•°æ®æµå‘\n\n```\nç”¨æˆ·è¾“å…¥ â†’ PromptTemplate (å¡«å……ä¸Šä¸‹æ–‡) \n         â†’ LLM (ç”Ÿæˆç»“æ„åŒ–æŒ‡ä»¤/å‡½æ•°è°ƒç”¨)\n         â†’ ToolExecutor (éªŒè¯å¹¶æ‰§è¡Œå·¥å…·ï¼Œæ•è·è¿”å›å€¼)\n         â†’ å›ä¼ ç»™ LLM (äºŒæ¬¡æ¨ç†)\n         â†’ OutputParser (æå–æœ€ç»ˆç­”æ¡ˆ)\n         â†’ Memory (å†™å…¥ä¼šè¯å†å²)\n         â†’ LangSmith (è®°å½• trace + è¯„ä¼°è´¨é‡)\n```\n\n#### 4. å…³é”®è®¾è®¡æ¨¡å¼\n\n| æ¨¡å¼ | åº”ç”¨åœºæ™¯ | ä¸ºä»€ä¹ˆ |\n|------|----------|--------|\n| **ç­–ç•¥æ¨¡å¼** | LLM å®ç°ï¼ˆOpenAI vs. LocalLLMï¼‰ | å…è®¸è¿è¡Œæ—¶åˆ‡æ¢æ¨¡å‹ï¼Œä¸ä¿®æ”¹è°ƒç”¨ä»£ç  |\n| **è£…é¥°å™¨æ¨¡å¼** | `RunnableWithMessageHistory` åŒ…è£…ä»»æ„ Chain | åœ¨ä¸ä¾µå…¥åŸæœ‰é€»è¾‘ä¸‹æ·»åŠ çŠ¶æ€ç®¡ç† |\n| **å·¥å‚æ¨¡å¼** | `load_chain()`, `load_agent()` | é€šè¿‡ YAML/JSON é…ç½®åŠ¨æ€æ„å»ºå¤æ‚æµæ°´çº¿ |\n| **è§‚å¯Ÿè€…æ¨¡å¼** | Callbacks ç³»ç»Ÿ | ç›‘æ§ã€æ—¥å¿—ã€è®¡è´¹ç­‰æ¨ªåˆ‡å…³æ³¨ç‚¹è§£è€¦ |\n| **çŠ¶æ€æœºæ¨¡å¼ï¼ˆLangGraphï¼‰** | å¤šè½® Agent å†³ç­–æµ | æ˜ç¡®çŠ¶æ€è½¬ç§»è¾¹ç•Œï¼Œé¿å…æ— é™å¾ªç¯æˆ–æ­»é” |\n\n---\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| æŠ€æœ¯ | ä¸ºä»€ä¹ˆé€‰ï¼Ÿ | æ›¿ä»£æ–¹æ¡ˆ | æ³¨æ„äº‹é¡¹ |\n|------|-----------|----------|----------|\n| **Python 3.8+** | ç”Ÿæ€ä¸°å¯Œã€AI ç¤¾åŒºä¸»æµ | Rust/Goï¼ˆæ€§èƒ½å¥½ä½†ç”Ÿæ€å¼±ï¼‰ | ä¸æ”¯æŒ Python <3.8ï¼Œæ³¨æ„å…¼å®¹æ€§ |\n| **Pydantic v2** | ç±»å‹å®‰å…¨ + è‡ªåŠ¨ JSON Schema ç”Ÿæˆ | dataclasses, attrs | å¿…é¡»ç”¨ `Field()` å£°æ˜å·¥å…·å‚æ•°ç»“æ„ |\n| **httpx** | å¼‚æ­¥/åŒæ­¥ç»Ÿä¸€ã€è‡ªåŠ¨é‡è¯• | requests + asyncio | æŸäº›ä»£ç†ç¯å¢ƒéœ€é…ç½® CA è¯ä¹¦ |\n| **tiktoken** | OpenAI Token è®¡æ•°æƒå¨å®ç° | HuggingFace tokenizer | éœ€æ‰‹åŠ¨å®‰è£… `pip install tiktoken`ï¼Œå¦åˆ™æŠ¥é”™ |\n| **langchain-core** | æ ¸å¿ƒæŠ½è±¡åŒ…ï¼ˆæ— å¤–éƒ¨ä¾èµ–ï¼‰ | è‡ªå»ºæ¥å£ | æ‰€æœ‰æ‰©å±•å¿…é¡»ä¾èµ–æ­¤åŒ…ï¼Œé¿å…ç‰ˆæœ¬æ¼‚ç§» |\n| **langsmith-sdk** | ä¸ LangSmith å¹³å°é€šä¿¡ | è‡ªå»º Prometheus + Grafana | éœ€ API Keyï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ç§æœ‰éƒ¨ç½² |\n\n> ğŸ’¡ **é‡è¦å…¼å®¹æ€§æç¤º**ï¼šLangChain v0.2+ å¼•å…¥äº†é‡å¤§é‡æ„ï¼ˆ`Runnable` æ›¿ä»£ `Chain`ï¼‰ï¼Œæ—§ä»£ç éœ€è¿ç§»ã€‚å®˜æ–¹æä¾› [migration guide](https://python.langchain.com/docs/migrate_from_v0_to_v1/)ã€‚\n\n---\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. åŸºç¡€å®‰è£…ï¼ˆæ¨èï¼šæœ€å°ä¾èµ–ï¼‰\npip install langchain\n\n# 2. å¦‚æœéœ€è¦ä½¿ç”¨ OpenAI æ¨¡å‹ + å‘é‡å­˜å‚¨ï¼ˆæ¨èç”Ÿäº§èµ·æ­¥ï¼‰\npip install langchain openai chromadb tiktoken\n\n# 3. å¦‚æœè¦ä½¿ç”¨ LangGraphï¼ˆå¤æ‚å·¥ä½œæµï¼‰\npip install langgraph\n\n# 4. è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆOpenAI API Keyï¼‰\nexport OPENAI_API_KEY=\"your-key-here\"\n# æˆ–å†™å…¥ .env æ–‡ä»¶ï¼Œç”¨ python-dotenv åŠ è½½\n\n# 5. ï¼ˆå¯é€‰ï¼‰å¯ç”¨ LangSmith ç›‘æ§\nexport LANGCHAIN_API_KEY=\"your-langsmith-key\"\nexport LANGCHAIN_PROJECT=\"my-agent-project\"\n\n# 6. éªŒè¯å®‰è£…ï¼ˆè¿è¡Œæµ‹è¯•ï¼‰\npython -c \"from langchain_openai import ChatOpenAI; print(ChatOpenAI().model_name)\"\n```\n\n> âœ… **æœ€ä½³å®è·µ**ï¼šä½¿ç”¨ `pyproject.toml` ç®¡ç†ä¾èµ–ï¼Œé¿å…ç‰ˆæœ¬å†²çªã€‚æ¨èé”å®šç‰ˆæœ¬ï¼š\n```toml\n[dependencies]\nlangchain = \"^0.2\"\nlangchain-openai = \"^0.1\"\nchromadb = \"^0.5\"\ntiktoken = \"^0.7\"\n```\n\n---\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n#### åœºæ™¯ï¼šæ„å»ºä¸€ä¸ªâ€œå¤©æ°”æŸ¥è¯¢ + å»ºè®®â€æ™ºèƒ½ä½“\n\n```python\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.tools import tool\nfrom langchain.agents import create_tool_calling_agent, AgentExecutor\nfrom langchain import hub\n\n# 1. å®šä¹‰å·¥å…·ï¼ˆPydantic Schema è‡ªåŠ¨è½¬æ¢ä¸º OpenAI Functionï¼‰\n@tool\ndef get_weather(city: str) -> dict:\n    \"\"\"è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯\"\"\"\n    # æ¨¡æ‹Ÿ API è°ƒç”¨\n    return {\"city\": city, \"temperature\": 22, \"condition\": \"sunny\", \"humidity\": 65}\n\n# 2. åˆå§‹åŒ–æ¨¡å‹ï¼ˆä½¿ç”¨ Function Callingï¼‰\nllm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n\n# 3. è·å–å®˜æ–¹é¢„è®¾ Promptï¼ˆReAct é£æ ¼ï¼‰\nprompt = hub.pull(\"hwchase17/openai-functions-agent\")\n\n# 4. æ„å»º Agent\nagent = create_tool_calling_agent(llm, [get_weather], prompt)\n\n# 5. æ‰§è¡Œå™¨ï¼ˆè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯ï¼‰\nagent_executor = AgentExecutor(agent=agent, tools=[get_weather], verbose=True)\n\n# 6. è¾“å…¥ï¼šçœŸå®ç”¨æˆ·é—®é¢˜\nuser_input = \"æˆ‘æ˜å¤©å»å·´é»ï¼Œè¯¥ç©¿ä»€ä¹ˆï¼Ÿ\"\n\n# 7. è¾“å‡º\nresponse = agent_executor.invoke({\"input\": user_input})\n\nprint(response[\"output\"])\n```\n\n#### âœ… é¢„æœŸè¾“å‡ºï¼š\n```\n[INFO] Calling tool: get_weather with args {'city': 'Paris'}\n[INFO] Tool returned: {\"city\": \"Paris\", \"temperature\": 18, \"condition\": \"partly cloudy\", \"humidity\": 70}\n[INFO] LLM reasoning: \"å·´é»æ˜å¤©æ°”æ¸©18Â°Cï¼Œå¤šäº‘ï¼Œå»ºè®®ç©¿é•¿è¢–è¡¬è¡«+è–„å¤–å¥—ã€‚\"\n```\n\n#### ğŸ” å…³é”®å‚æ•°è¯´æ˜ï¼š\n- `model=\"gpt-4-turbo\"`ï¼šå¯ç”¨ Function Calling èƒ½åŠ›ï¼ˆå¿…é¡»æ”¯æŒï¼‰\n- `temperature=0`ï¼šç¡®ä¿è¾“å‡ºç¨³å®šï¼Œé€‚åˆå·¥å…·è°ƒç”¨\n- `verbose=True`ï¼šè°ƒè¯•æ—¶æŸ¥çœ‹æ¯ä¸€æ­¥æ¨ç†è¿‡ç¨‹\n\n---\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n#### ğŸ“‰ æ½œåœ¨ç“¶é¢ˆï¼š\n| ç¯èŠ‚ | é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |\n|------|------|----------|\n| LLM å»¶è¿Ÿ | å¤šè½®å¯¹è¯å¯¼è‡´å¤šæ¬¡è°ƒç”¨ | ä½¿ç”¨ç¼“å­˜ï¼ˆRedisï¼‰ã€æµå¼è¾“å‡ºã€å¹¶è¡ŒæŸ¥è¯¢ |\n| å·¥å…·æ‰§è¡Œæ…¢ | å¤–éƒ¨ API è°ƒç”¨å»¶è¿Ÿé«˜ | å¼‚æ­¥ `asyncio.gather()` + é‡è¯•ç­–ç•¥ |\n| å‘é‡æ£€ç´¢ | é«˜ç»´å‘é‡æœç´¢æ…¢ | ä½¿ç”¨ HNSW ç´¢å¼•ï¼ˆFAISSï¼‰ã€é‡åŒ–ï¼ˆPQï¼‰ |\n| å†…å­˜è†¨èƒ€ | é•¿å¯¹è¯å†å²å æ»¡ä¸Šä¸‹æ–‡ | å®ç° `SummaryBufferMemory`ï¼Œå®šæœŸæ‘˜è¦å‹ç¼© |\n\n#### ğŸ“ˆ ç”Ÿäº§æ‰©å±•å»ºè®®ï¼š\n- **å¹¶å‘**ï¼šç”¨ FastAPI + Uvicorn å¼‚æ­¥éƒ¨ç½²ï¼Œæ¯ä¸ªè¯·æ±‚ç‹¬ç«‹ `AgentExecutor`\n- **ç¼“å­˜**ï¼šRedis ç¼“å­˜ `prompt + input â†’ output` æ˜ å°„ï¼ˆæ³¨æ„è¯­ä¹‰ä¸€è‡´æ€§ï¼‰\n- **é™æµ**ï¼šå¯¹ LLM API ä½¿ç”¨ä»¤ç‰Œæ¡¶é™æµï¼ˆå¦‚ `tenacity` + `ratelimit`ï¼‰\n- **ç›‘æ§**ï¼šé€šè¿‡ LangSmith ç›‘æ§ token æ¶ˆè€—ã€å“åº”æ—¶é—´ã€å·¥å…·å¤±è´¥ç‡\n- **æˆæœ¬æ§åˆ¶**ï¼šè®¾ç½® `max_tokens=2048`, ä½¿ç”¨ cheaper model for routing\n\n#### ğŸ’° èµ„æºæ¶ˆè€—ä¼°ç®—ï¼ˆå•æ¬¡ Agent ä¼šè¯ï¼‰ï¼š\n| ç»„ä»¶ | æˆæœ¬/è¯·æ±‚ | æ—¶å»¶ |\n|------|-----------|------|\n| LLM (GPT-4-turbo) | $0.01~$0.03 | 800ms~2s |\n",
    "last_scanned": "2026-01-16T02:03:15.384216",
    "last_analyzed": "2026-01-15T04:49:48.221634",
    "screenshot": "static/screenshots/552661142.jpg",
    "ai_visual_summary": "è¯¥æˆªå›¾å±•ç¤ºäº†ä¸€ä¸ªåä¸º `langchain` çš„ GitHub å¼€æºé¡¹ç›®é¡µé¢ï¼Œå…¶UIè®¾è®¡é£æ ¼ç®€æ´ã€ç°ä»£ï¼Œé‡‡ç”¨æ·±è‰²å¯¼èˆªæ å’Œæµ…è‰²ä¸»ä½“å†…å®¹åŒºï¼Œç¬¦åˆGitHubçš„æ ‡å‡†ç•Œé¢ã€‚é¡¹ç›®ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬ä»£ç ä»“åº“ã€é—®é¢˜è·Ÿè¸ªã€æ‹‰å–è¯·æ±‚å’Œè®¨è®ºåŒºã€‚å…³é”®æŠ€æœ¯å…³é”®è¯åŒ…æ‹¬ `python`ã€`open-source`ã€`agents`ã€`ai`ã€`langchain`ã€`generative-ai`ï¼Œè¡¨æ˜è¿™æ˜¯ä¸€ä¸ªåŸºäºPythonçš„å¼€æºäººå·¥æ™ºèƒ½é¡¹ç›®ã€‚æ ¹æ®é¡¹ç›®æè¿°â€œğŸ¤–ğŸ”— The platform for reliable agents.â€ï¼ˆå¯é çš„ä»£ç†å¹³å°ï¼‰ï¼Œè¯¥åº”ç”¨æ—¨åœ¨ä¸ºæ„å»ºå’Œç®¡ç†äººå·¥æ™ºèƒ½ä»£ç†ï¼ˆAgentsï¼‰æä¾›ä¸€ä¸ªå¯é çš„å¹³å°ï¼Œæ˜¯ä¸€ä¸ªä¸“æ³¨äºç”Ÿæˆå¼AIå’Œä»£ç†æŠ€æœ¯çš„å¼€å‘æ¡†æ¶ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "612354784",
    "name": "llama.cpp",
    "full_name": "ggml-org/llama.cpp",
    "category": "llm_rag",
    "stars": 93032,
    "forks": 14486,
    "description": "LLM inference in C/C++",
    "url": "https://github.com/ggml-org/llama.cpp",
    "homepage": "",
    "language": "C++",
    "topics": "[\"ggml\"]",
    "created_at": "2023-03-10T18:58:00Z",
    "updated_at": "2026-01-15T17:36:06Z",
    "readme_content": null,
    "ai_summary": "åŸºäºC/C++çš„æœ¬åœ°å¤§æ¨¡å‹æ¨ç†æ¡†æ¶ï¼Œæ”¯æŒGGMLé‡åŒ–å¼•æ“ã€å¤šæ¨¡æ€è¾“å…¥è¾“å‡ºåŠGPUåŠ é€Ÿ",
    "ai_tech_stack": "[\"C/C++\", \"GGML\", \"ONNX Runtime\", \"OpenAI API\\u517c\\u5bb9\"]",
    "ai_use_cases": "[\"\\u672c\\u5730LLM\\u670d\\u52a1\\u90e8\\u7f72\\uff08\\u65e0\\u9700\\u4e91\\u8d44\\u6e90\\uff09\", \"IDE\\u63d2\\u4ef6\\u96c6\\u6210\\uff08\\u5982VS Code\\u4ee3\\u7801\\u8865\\u5168\\uff09\", \"\\u8fb9\\u7f18\\u8ba1\\u7b97\\u573a\\u666f\\u7684\\u8f7b\\u91cf\\u7ea7\\u5927\\u6a21\\u578b\\u5e94\\u7528\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "llama-cli -m my_model.gguf æˆ– llama-server -hf ggml-org/gemma-3-1b-it-GGUF",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\n`llama.cpp` çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äºï¼š**å®ƒç”¨çº¯ C/C++ å®ç°äº†å·¥ä¸šçº§ LLM æ¨ç†çš„â€œé›¶ä¾èµ–ã€è·¨å¹³å°ã€å…¨ç¡¬ä»¶åŠ é€Ÿâ€é—­ç¯ï¼Œå½»åº•æ‘†è„±äº† Python ç”Ÿæ€å’Œå¤§å‹æ¡†æ¶ï¼ˆå¦‚ PyTorch/TensorRTï¼‰çš„æŸç¼šã€‚**\n\nåŒç±»é¡¹ç›®å¦‚ vLLMã€TensorRT-LLMã€HuggingFace TGI è™½ç„¶æ€§èƒ½ä¼˜å¼‚ï¼Œä½†éƒ½ä¸¥é‡ä¾èµ– CUDAã€Python è¿è¡Œæ—¶ã€æˆ–å¤æ‚çš„ä¾èµ–æ ‘ï¼ˆå¦‚ ONNX Runtimeï¼‰ã€‚å®ƒä»¬é€‚åˆäº‘åŸç”Ÿéƒ¨ç½²ï¼Œä½†åœ¨è¾¹ç¼˜è®¾å¤‡ã€åµŒå…¥å¼ç³»ç»Ÿã€ç¦»çº¿ç¯å¢ƒã€æˆ–èµ„æºå—é™çš„å¼€å‘æœºä¸Šå‡ ä¹æ— æ³•è½åœ°ã€‚\n\n`llama.cpp` è§£å†³äº†ä¸‰ä¸ªè¢«ä¸»æµæ–¹æ¡ˆå¿½è§†çš„å…³é”®ç—›ç‚¹ï¼š\n\n1. **â€œèƒ½è·‘åœ¨ä»»ä½•åœ°æ–¹â€**ï¼šä»æ ‘è“æ´¾åˆ° Apple M4 Maxï¼Œä» RISC-V å¼€å‘æ¿åˆ° NVIDIA H100ï¼Œä¸€å¥—ä»£ç ã€æ— å¤–éƒ¨ä¾èµ–ï¼ˆç”šè‡³ä¸ä¾èµ– libc++ï¼‰ï¼Œç›´æ¥ç¼–è¯‘å³ç”¨ã€‚\n2. **é‡åŒ–å³é»˜è®¤**ï¼šGGUF æ ¼å¼æ˜¯å…¶åŸç”Ÿæ•°æ®æ ¼å¼ï¼Œæ”¯æŒ 1.5-bit åˆ° 8-bit çš„æ•´æ•°é‡åŒ–ï¼ˆå« AWQ/GPTQ/QRK ç­‰å˜ç§ï¼‰ï¼Œä¸”æ¨ç†å¼•æ“å¯¹é‡åŒ–å¼ é‡æœ‰åŸç”Ÿé›¶å¼€é”€æ”¯æŒâ€”â€”è€Œå…¶ä»–ç³»ç»Ÿé€šå¸¸éœ€é¢å¤–è½¬æ¢æˆ–ç‰ºç‰²ç²¾åº¦ã€‚\n3. **API å…¼å®¹å³æ’æ‹”**ï¼šå®ƒä¸æ»¡è¶³äºâ€œèƒ½è·‘æ¨¡å‹â€ï¼Œè€Œæ˜¯ç›´æ¥å®ç° OpenAI ChatCompletion APIï¼Œä½¿å¾—ä»»ä½•å·²æœ‰çš„åŸºäº OpenAI SDK çš„åº”ç”¨ï¼ˆå¦‚ LangChainã€AutoGenã€å‰ç«¯ UIï¼‰æ— éœ€æ”¹ä¸€è¡Œä»£ç å³å¯è¿ç§»åˆ°æœ¬åœ°éƒ¨ç½²â€”â€”è¿™æ˜¯å·¥ç¨‹è½åœ°çš„â€œæœ€åä¸€å…¬é‡Œâ€çªç ´ã€‚\n\n> âœ… å®ƒä¸æ˜¯â€œå¦ä¸€ä¸ªæ¨ç†å¼•æ“â€ï¼Œè€Œæ˜¯**LLM çš„å¯ç§»æ¤äºŒè¿›åˆ¶å‘è¡Œç‰ˆ**ï¼Œè®©æ¨¡å‹ä»â€œäº‘ç«¯å®éªŒå“â€å˜æˆâ€œæœ¬åœ°å¯åˆ†å‘è½¯ä»¶â€ã€‚\n\n---\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n#### 1. **GGUFï¼šä¸ºé‡åŒ–è€Œç”Ÿçš„æ¨¡å‹æ ¼å¼**\n- æ›¿ä»£äº† Hugging Face çš„ `.bin`/`.safetensors`ï¼ŒGGUF æ˜¯è‡ªæè¿°ã€æ”¯æŒå…ƒæ•°æ®æ‰©å±•ï¼ˆå¦‚ quantization typeã€tokenizer configã€LoRA æŒ‡é’ˆï¼‰çš„äºŒè¿›åˆ¶æ ¼å¼ã€‚\n- **å…³é”®åˆ›æ–°**ï¼šå°† `tensor metadata + quantized weights + tokenizer` å…¨éƒ¨æ‰“åŒ…åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œæ— éœ€å¤–éƒ¨ vocab æ–‡ä»¶æˆ–é…ç½® JSON â€”â€” æè‡´ç®€åŒ–éƒ¨ç½²ã€‚\n- æ”¯æŒåŠ¨æ€åŠ è½½å¤šä¸ª LoRA adapter åˆ°åŒä¸€æ¨¡å‹å®ä¾‹ï¼ˆå†…å­˜å…±äº«ï¼‰ï¼Œé¿å…é‡å¤åŠ è½½ä¸»æƒé‡ã€‚\n\n#### 2. **ggmlï¼šè½»é‡çº§è‡ªåŠ¨å¾®åˆ† + å¼ é‡è®¡ç®—å›¾å¼•æ“**\n- ä¸æ˜¯â€œä»¿ PyTorchâ€ï¼Œè€Œæ˜¯ä¸º**æ¨ç†ä¼˜åŒ–**è®¾è®¡çš„æç®€å¼ é‡åº“ã€‚\n- æ‰€æœ‰æ“ä½œï¼ˆGEMMã€RoPEã€SwiGLUã€LayerNormï¼‰å‡ä¸ºæ‰‹å·¥ä¼˜åŒ–çš„ SIMD å†…æ ¸ï¼Œæ— åŠ¨æ€å†…å­˜åˆ†é…ï¼Œæ— å¼‚å¸¸å¤„ç†ï¼Œæ—  RTTIã€‚\n- æ”¯æŒ **â€œin-placeâ€ é‡ç”¨ä¸­é—´ç¼“å†²åŒº**ï¼šå¦‚ `llama_kv_cache` ä½¿ç”¨ç¯å½¢ buffer + æŒ‡é’ˆåç§»å¤ç”¨ï¼Œé¿å…æ¯æ¬¡æ¨ç†é‡å»º KV ç¼“å­˜ã€‚\n\n#### 3. **å¤šåç«¯ç»Ÿä¸€æŠ½è±¡ï¼ˆBackend Abstraction Layerï¼‰**\n```cpp\nstruct ggml_backend {\n    const char * name;\n    ggml_tensor * (*alloc_tensor)(struct ggml_context *, struct ggml_tensor *);\n    void (*free_tensor)(struct ggml_tensor *);\n    void (*cpy_tensor)(struct ggml_tensor *, struct ggml_tensor *);\n    void (*graph_compute)(struct ggml_cgraph *, struct ggml_backend *);\n};\n```\n- åç«¯åŒ…æ‹¬ï¼š`ggml-backend-cpu`, `ggml-backend-metal`, `ggml-backend-cuda`, `ggml-backend-vulkan`, `ggml-backend-sycl`ã€‚\n- æ‰€æœ‰æ¨¡å‹å›¾ï¼ˆ`ggml_cgraph`ï¼‰å¯**åŠ¨æ€ç»‘å®šåˆ°ä¸åŒåç«¯**ï¼Œå®ç° CPU+GPU æ··åˆæ¨ç†ï¼šä¾‹å¦‚ 70B æ¨¡å‹çš„å‰10å±‚åœ¨ GPUï¼Œå…¶ä½™åœ¨ CPUï¼Œé€šè¿‡å¼‚æ­¥å†…å­˜æ‹·è´æµæ°´çº¿é‡å ã€‚\n\n#### 4. **æ— é”ã€å•çº¿ç¨‹ä¸»å¾ªç¯ + å¤šçº¿ç¨‹å¼‚æ­¥ I/O**\n- `llama_decode()` æ˜¯çº¯åŒæ­¥ã€å•çº¿ç¨‹ã€æ—  malloc çš„æ ¸å¿ƒå‡½æ•°ã€‚\n- å¼‚æ­¥åŠ è½½ï¼ˆå¦‚ä»ç£ç›˜è¯»å– GGUFï¼‰ã€tokenizer åˆ†è¯ã€HTTP è¯·æ±‚å¤„ç†å‡åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ï¼Œé¿å…é˜»å¡æ¨ç†ä¸»çº¿ç¨‹ã€‚\n- **å…³é”®è®¾è®¡**ï¼šæ¨¡å‹çŠ¶æ€ï¼ˆKV Cache, logitsï¼‰å®Œå…¨é©»ç•™åœ¨ CPU/GPU å†…å­˜ï¼Œä¸é€šè¿‡å…±äº«å†…å­˜æˆ– IPC ä¼ é€’ â€”â€” é¿å…åºåˆ—åŒ–å¼€é”€ã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n#### 1. æ•´ä½“æ¶æ„ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\n[User Input] \n   â”‚\n   â–¼\n[llama-cli / llama-server] â† HTTP REST/WS æ¥å£ (OpenAI å…¼å®¹)\n   â”‚\n   â–¼\n[ggml_context] â† æ¨¡å‹å…ƒæ•°æ®åŠ è½½ (GGUF parser)\n   â”‚\n   â–¼\n[Model Loader] â†’ è§£æ GGUF â†’ åˆ†é… tensor å†…å­˜ â†’ åŠ è½½é‡åŒ–æƒé‡\n   â”‚\n   â–¼\n[Compute Graph (ggml_cgraph)] â† æ‰€æœ‰ ops ç»„æˆçš„é™æ€å›¾ï¼ˆé™æ€åˆ†é…ï¼‰\n   â”‚\n   â”œâ”€â–º [CPU Backend] â”€â”€ AVX512/NEON/RVV ä¼˜åŒ–å†…æ ¸\n   â”œâ”€â–º [Metal Backend] â”€â”€ Apple Silicon GPU (MTLCommandBuffer)\n   â”œâ”€â–º [CUDA Backend] â”€â”€ è‡ªå®šä¹‰ CUDA kernelï¼ˆæ”¯æŒ MXFP4ï¼‰\n   â”œâ”€â–º [Vulkan/SYCL] â”€â”€ è·¨å¹³å° GPGPU æ”¯æŒ\n   â”‚\n   â–¼\n[KV Cache Manager] â† ç¯å½¢ç¼“å†²åŒºï¼ŒæŒ‰ token ä½ç½®ç´¢å¼•ï¼Œå†…å­˜é¢„åˆ†é…\n   â”‚\n   â–¼\n[Tokenizer (sentencepiece)] â† å†…åµŒï¼Œæ”¯æŒ BPE/WordPieceï¼Œæ— å¤–éƒ¨ä¾èµ–\n   â”‚\n   â–¼\n[Output Tokens] â†’ è¾“å‡ºåˆ° stdout / HTTP stream\n```\n\n#### 2. æ ¸å¿ƒæ¨¡å—èŒè´£\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| `llama.cpp` ä¸»ä½“ | å‘½ä»¤è¡Œå…¥å£ã€æ¨¡å‹åŠ è½½ã€API å®ç°ã€çº¿ç¨‹è°ƒåº¦ |\n| `ggml.h/.c` | å¼ é‡æŠ½è±¡ã€å†…å­˜æ± ï¼ˆarena allocatorï¼‰ã€æ“ä½œå®šä¹‰ã€åç«¯æ¥å£ |\n| `ggml-backend-*` | ç¡¬ä»¶åŠ é€Ÿåç«¯å®ç°ï¼Œå°è£…è®¾å¤‡å†…å­˜ç®¡ç†ä¸ kernel è°ƒç”¨ |\n| `llama.cpp/grammar.cpp` | æ”¯æŒç»“æ„åŒ–è¾“å‡ºï¼ˆJSON Schema, BNFï¼‰çš„è¯­æ³•çº¦æŸè§£ç å™¨ |\n| `tokenizer.cpp` | å†…ç½® sentencepiece è§£ç å™¨ï¼Œæ”¯æŒå¤šè¯­è¨€ã€æ— å¤–éƒ¨ä¾èµ– |\n| `gguf-parser.h` | GGUF æ ¼å¼è§£æå™¨ï¼šè¯»å–å¼ é‡åã€ç±»å‹ã€åç§»ã€é‡åŒ–å‚æ•° |\n\n#### 3. æ•°æ®æµå‘\n\n```\nè¾“å…¥: ç”¨æˆ· prompt (text)\n      â†“\nTokenizer â†’ è½¬æ¢ä¸º token_ids (std::vector<int>)\n      â†“\nggml_context åˆ†é… tensor å†…å­˜ (é¢„åˆ†é…å›ºå®šå¤§å° buffer)\n      â†“\næ„å»ºè®¡ç®—å›¾ï¼šembeddings â†’ transformer layers (xN) â†’ norm â†’ logits\n      â†“\nç»‘å®šåˆ°æœ€ä¼˜åç«¯ï¼ˆå¦‚ Metal æˆ– CUDAï¼‰\n      â†“\næ‰§è¡Œ ggml_graph_compute() â€”â€” çº¯ C å‡½æ•°è°ƒç”¨ï¼Œæ— å †åˆ†é…\n      â†“\né‡‡æ ·ï¼štop_p / top_k / temperature â†’ ç”Ÿæˆ token_id\n      â†“\nå¾ªç¯ç›´åˆ°ç»“æŸæˆ– max_tokens\n      â†“\nè¾“å‡º: token_ids â†’ detokenizer â†’ text stream (stdout æˆ– HTTP SSE)\n```\n\n#### 4. å…³é”®è®¾è®¡æ¨¡å¼\n\n| æ¨¡å¼ | åº”ç”¨åœºæ™¯ | åŸå›  |\n|------|----------|------|\n| **å·¥å‚æ¨¡å¼** | `ggml_backend_init()` è¿”å›ä¸åŒåç«¯å®ä¾‹ | è§£è€¦ç¡¬ä»¶ä¾èµ–ï¼Œæ”¯æŒæ’ä»¶åŒ–æ‰©å±• |\n| **ç­–ç•¥æ¨¡å¼** | `llama_sampling` ç­–ç•¥ï¼ˆtop_p, top_k, mirostatï¼‰å¯åŠ¨æ€åˆ‡æ¢ | å…è®¸è¿è¡Œæ—¶è°ƒæ•´é‡‡æ ·è¡Œä¸ºï¼Œä¸ä¿®æ”¹æ ¸å¿ƒæ¨ç†é€»è¾‘ |\n| **äº«å…ƒæ¨¡å¼** | KV Cache å¤ç”¨ç¯å½¢ buffer | é¿å…æ¯æ¬¡è§£ç é‡å»ºç¼“å­˜ï¼ŒèŠ‚çœå†…å­˜ä¸ memcpy å¼€é”€ |\n| **å¤–è§‚æ¨¡å¼** | `llama.cpp` æä¾› `llama_load_model_from_file()` ç­‰é«˜å±‚ API | å°†å¤æ‚çš„ ggml + backend + tokenizer é€»è¾‘å°è£…ä¸ºå•æ¥å£ |\n| **æ— çŠ¶æ€è®¡ç®—å›¾** | æ‰€æœ‰ tensor æŒ‡é’ˆåœ¨ç¼–è¯‘æ—¶ç¡®å®šï¼Œè¿è¡Œæ—¶ä¸åŠ¨æ€åˆ›å»º | é¿å… GCã€å†…å­˜ç¢ç‰‡ã€é”ç«äº‰ï¼Œå®ç°æè‡´ä½å»¶è¿Ÿ |\n\n---\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| æŠ€æœ¯ | ä¸ºä»€ä¹ˆé€‰ï¼Ÿ | æ›¿ä»£æ–¹æ¡ˆ | æ³¨æ„äº‹é¡¹ |\n|------|------------|----------|----------|\n| **C++17** | ç²¾ç¡®æ§åˆ¶å†…å­˜å¸ƒå±€ + é›¶æˆæœ¬æŠ½è±¡ï¼Œæ— è¿è¡Œæ—¶å¼€é”€ | Rustï¼ˆæ€§èƒ½æ¥è¿‘ä½†ç”Ÿæ€ç¢ç‰‡åŒ–ï¼‰ | å¿…é¡»ç¦ç”¨å¼‚å¸¸/RTTI ä»¥å‡å°‘äºŒè¿›åˆ¶ä½“ç§¯ï¼ˆ`-fno-exceptions -fno-rtti`ï¼‰ |\n| **ggml** | è‡ªç ”å¼ é‡åº“ï¼Œä¸“ä¸ºæ¨ç†ä¼˜åŒ–ï¼Œæ— ä¾èµ– | ONNX Runtime / TVM | ggml ä¸æ”¯æŒåŠ¨æ€å½¢çŠ¶ï¼Œä½† LLama æ¨¡å‹æ˜¯é™æ€åºåˆ—é•¿åº¦ï¼Œå®Œå…¨é€‚é… |\n| **GGUF** | åŸç”Ÿæ ¼å¼ï¼Œæ”¯æŒå…ƒæ•°æ®æ‰©å±•ã€å¤šæ¨¡æ€æŒ‡é’ˆ | PyTorch .bin + config.json | å¿…é¡»ç”¨ `quantize` å·¥å…·è½¬æ¢æ¨¡å‹ï¼Œä¸èƒ½ç›´æ¥åŠ è½½ HuggingFace æ ¼å¼ |\n| **Metal / CUDA / Vulkan** | Apple ç”Ÿæ€é¦–é€‰ï¼›NVIDIA æ€§èƒ½æ ‡æ†ï¼›è·¨å¹³å°å›¾å½¢ API é€šç”¨æ€§ | OpenCLï¼ˆå·²æ·˜æ±°ï¼‰, HIPï¼ˆä»… AMDï¼‰ | éœ€è¦å®‰è£…å¯¹åº” SDKï¼ˆå¦‚ Metal SDK åœ¨ macOS è‡ªå¸¦ï¼ŒCUDA éœ€é©±åŠ¨ï¼‰ |\n| **CMake** | è·¨å¹³å°æ„å»ºï¼Œæ”¯æŒå¤æ‚åç«¯å¼€å…³ | Bazel / Ninja æ‰‹å†™ Makefile | CMakeLists.txt æå…¶å¤æ‚ï¼Œéœ€ç†è§£ `find_package(CUDA)`, `find_package(Metal)` ç­‰æ¨¡å— |\n\n> ğŸ’¡ **å…¼å®¹æ€§æ³¨æ„**ï¼š  \n> - ä½¿ç”¨ `-march=native` ç¼–è¯‘å¯å¯ç”¨ AVX512/NEONï¼Œä½†ä¼šé™ä½äºŒè¿›åˆ¶ç§»æ¤æ€§ã€‚  \n> - ä¸ºåµŒå…¥å¼è®¾å¤‡ç¼–è¯‘æ—¶ï¼Œå¿…é¡»å…³é—­æ‰€æœ‰ SIMD æŒ‡ä»¤ï¼ˆ`-DGGML_USE_ACCELERATE=OFF -DGGML_USE_OPENMP=OFF`ï¼‰ã€‚\n\n---\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. å…‹éš†ä»“åº“ï¼ˆæ¨èä½¿ç”¨ --recursive è·å– ggml å­æ¨¡å—ï¼‰\ngit clone --recursive https://github.com/ggml-org/llama.cpp && cd llama.cpp\n\n# 2. ç¼–è¯‘ï¼šå¯ç”¨æ‰€æœ‰åç«¯ï¼ˆmacOS è‡ªåŠ¨æ£€æµ‹ Metalï¼ŒLinux é»˜è®¤ CPU + CUDAï¼‰\ncmake -S . -B build \\\n  -DGGML_CUDA=ON \\          # å¯ç”¨ NVIDIA GPU åŠ é€Ÿ\n  -DGGML_VULKAN=ON \\        # å¯ç”¨ Vulkanï¼ˆæ”¯æŒ AMD/Intelï¼‰\n  -DGGML_SYCL=ON \\          # å¯ç”¨ SYCLï¼ˆIntel oneAPIï¼‰\n  -DBUILD_SHARED_LIBS=OFF   # é™æ€é“¾æ¥ï¼Œé¿å…åŠ¨æ€åº“ä¾èµ–\n\n# 3. ç¼–è¯‘\ncmake --build build -j$(nproc)\n\n# 4. å®‰è£…å¯æ‰§è¡Œæ–‡ä»¶åˆ° PATHï¼ˆå¯é€‰ï¼‰\nsudo cp build/llama-cli /usr/local/bin/\nsudo cp build/llama-server /usr/local/bin/\n\n# 5. ä¸‹è½½æ¨¡å‹ï¼ˆç¤ºä¾‹ï¼šGemma-3B GGUFï¼Œå·²é‡åŒ–ä¸º Q4_K_Mï¼‰\nwget https://huggingface.co/ggml-org/gemma-3b-it-GGUF/resolve/main/gemma-3b-it.Q4_K_M.gguf\n\n# âœ… å®Œæˆï¼ç°åœ¨å¯ç›´æ¥è¿è¡Œï¼š\nllama-cli -m gemma-3b-it.Q4_K_M.gguf -n 128 --temp 0.7\n```\n\n> ğŸ’¡ **Docker å¿«é€Ÿå¯åŠ¨**ï¼ˆæ— éœ€ç¼–è¯‘ï¼‰ï¼š\n```bash\ndocker run --rm -it \\\n  -v $(pwd):/models \\\n  ghcr.io/ggml-org/llama.cpp:latest \\\n  llama-cli -m /models/gemma-3b-it.Q4_K_M.gguf -n 100\n```\n\n---\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n#### åœºæ™¯ï¼šæœ¬åœ°éƒ¨ç½² AI ç¼–ç¨‹åŠ©æ‰‹ï¼Œæ”¯æŒ FIMï¼ˆFill-in-the-Middleï¼‰\n\n```bash\n# å¯åŠ¨ OpenAI å…¼å®¹ API æœåŠ¡å™¨\nllama-server \\\n  -m gemma-3b-it.Q4_K_M.gguf \\\n  -c 2048 \\           # ä¸Šä¸‹æ–‡é•¿åº¦\n  --n-gpu-layers 35 \\ # å°†å‰35å±‚åŠ è½½åˆ° GPUï¼ˆå‡è®¾ A100 æœ‰ 40GBï¼‰\n  --port 8080 \\\n  --log-disable\n\n# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼Œå‘é€ FIM è¯·æ±‚ï¼ˆæ¨¡æ‹Ÿ VS Code è¡¥å…¨ï¼‰\ncurl -X POST http://localhost:8080/v1/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"gemma-3b-it\",\n    \"prompt\": \"def fibonacci(n):\\n    if n <= 1:\\n        return n\\n    else:\\n        \",\n    \"max_tokens\": 64,\n    \"temperature\": 0.2",
    "last_scanned": "2026-01-16T02:03:15.385818",
    "last_analyzed": "2026-01-15T05:19:31.182856",
    "screenshot": "static/screenshots/612354784.jpg",
    "ai_visual_summary": "æ ¹æ®æˆªå›¾åˆ†æï¼Œè¿™æ˜¯ä¸€ä¸ªåä¸º `llama.cpp` çš„å¼€æºé¡¹ç›®ï¼Œå…¶ç•Œé¢ä¸ºå…¸å‹çš„ GitHub é¡¹ç›®ä¸»é¡µã€‚ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬ `llama-cli` å‘½ä»¤è¡Œå·¥å…·å’Œ `llama-server` HTTP æœåŠ¡å™¨ã€‚å…³é”®æŠ€æœ¯å…³é”®è¯åŒ…æ‹¬ `LLM inference`ï¼ˆå¤§è¯­è¨€æ¨¡å‹æ¨ç†ï¼‰ã€`GGUF`ã€`LoRA`ã€`quantization`ï¼ˆé‡åŒ–ï¼‰ã€`OpenAI API` å…¼å®¹ã€`HTTP server` å’Œ `C/C++`ã€‚è¯¥åº”ç”¨æ˜¯ä¸€ä¸ªç”¨ C/C++ ç¼–å†™çš„è½»é‡çº§åº“ï¼Œç”¨äºåœ¨æœ¬åœ°æˆ–äº‘ç«¯é«˜æ•ˆè¿è¡Œå’Œéƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒé€šè¿‡å‘½ä»¤è¡Œäº¤äº’æˆ–æä¾› API æœåŠ¡ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "612344730",
    "name": "NextChat",
    "full_name": "ChatGPTNextWeb/NextChat",
    "category": "llm_rag",
    "stars": 87057,
    "forks": 60560,
    "description": "âœ¨ Light and Fast AI Assistant. Support: Web | iOS | MacOS | Android |  Linux | Windows",
    "url": "https://github.com/ChatGPTNextWeb/NextChat",
    "homepage": "https://nextnext.chat",
    "language": "TypeScript",
    "topics": "[\"calclaude\", \"chatgpt\", \"claude\", \"cross-platform\", \"desktop\", \"fe\", \"gemini\", \"gemini-pro\", \"gemini-server\", \"gemini-ultra\", \"gpt-4o\", \"groq\", \"nextjs\", \"ollama\", \"react\", \"tauri\", \"tauri-app\", \"vercel\", \"webui\"]",
    "created_at": "2023-03-10T18:27:54Z",
    "updated_at": "2026-01-15T17:20:20Z",
    "readme_content": null,
    "ai_summary": "è½»é‡çº§å¤šå¹³å°AIåŠ©æ‰‹ç³»ç»Ÿï¼Œæ”¯æŒClaude/DeepSeek/GPT4ç­‰å¤šç§æ¨¡å‹ï¼Œé‡‡ç”¨React+Next.jsæ„å»ºè·¨ç«¯èŠå¤©ç•Œé¢ï¼Œå¹¶é€šè¿‡APIé›†æˆå®ç°å“åº”å¼äº¤äº’",
    "ai_tech_stack": "[\"Next.js\", \"TypeScript\", \"React\", \"Electron\", \"FastAPI\"]",
    "ai_use_cases": "[\"\\u667a\\u80fd\\u5ba2\\u670d\\u673a\\u5668\\u4eba\", \"\\u6559\\u80b2\\u8f85\\u5bfc\\u7b54\\u7591\\u7cfb\\u7edf\", \"\\u7f16\\u7a0b\\u52a9\\u624b\\u4ee3\\u7801\\u751f\\u6210\"]",
    "ai_difficulty": 3,
    "ai_quick_start": "npx create-next-app@latest --typescript && cd your-project-name && npm install react-icons @heroicons/react tailwindcss",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nNextChat çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äºï¼š**å®ƒæ˜¯å”¯ä¸€ä¸€ä¸ªåœ¨å¼€æºé¢†åŸŸå®ç°â€œå…¨å¹³å°ä¸€è‡´ä½“éªŒ + å¤šæ¨¡å‹ä»£ç† + ä¼ä¸šçº§ç§æœ‰åŒ–èƒ½åŠ›â€ä¸‰ä½ä¸€ä½“çš„ AI åŠ©æ‰‹å®¢æˆ·ç«¯æ¡†æ¶ã€‚**\n\nä¸»æµç«å“å¦‚ï¼š\n- **LangChain/LlamaIndex**ï¼šä¸“æ³¨åç«¯ Agent æ„å»ºï¼Œæ— åŸç”Ÿ UIï¼›\n- **OpenWebUI / Ollama WebUI**ï¼šä»…æ”¯æŒæœ¬åœ°æ¨¡å‹+å•å¹³å°ï¼ˆWebï¼‰ï¼›\n- **Cursor / Devin**ï¼šé—­æºå•†ä¸šäº§å“ï¼Œæ— äºŒæ¬¡å¼€å‘å…¥å£ï¼›\n- **Chatbot UI / Vercel AI SDK ç¤ºä¾‹**ï¼šè½»é‡ä½†ç¼ºä¹å¤šç«¯åŒæ­¥ä¸ä¼ä¸šåŠŸèƒ½ã€‚\n\nNextChat çªç ´ç‚¹ï¼š\n1. **è·¨å¹³å°ä¸€è‡´æ€§**ï¼šåŒä¸€å¥— TypeScript ä»£ç åº“ï¼ˆReact + Next.jsï¼‰é€šè¿‡ Tauriï¼ˆæ¡Œé¢ï¼‰ã€Capacitorï¼ˆç§»åŠ¨ç«¯ï¼‰ã€PWAï¼ˆWebï¼‰å®ç°åŸç”Ÿçº§ä½“éªŒï¼Œæ— éœ€ç»´æŠ¤ä¸‰å¥— UIã€‚\n2. **æ¨¡å‹ä»£ç†å±‚æŠ½è±¡**ï¼šä¸ç»‘å®š OpenAIï¼Œæ”¯æŒ Claudeã€Geminiã€DeepSeek ç­‰å¤šå®¶å‚å•† APIï¼Œé€šè¿‡ç»Ÿä¸€ `ChatProvider` æ¥å£å®ç°é›¶æ„ŸçŸ¥åˆ‡æ¢ï¼Œè§„é¿ä¾›åº”å•†é”å®šã€‚\n3. **ä¼ä¸šç§æœ‰åŒ–å³å¼€ç®±**ï¼šå†…ç½® Admin Panel + æƒé™ç³»ç»Ÿ + å®¡è®¡æ—¥å¿— + çŸ¥è¯†åº“é›†æˆï¼Œä¸æ˜¯â€œå¯é€‰æ’ä»¶â€ï¼Œè€Œæ˜¯æ¶æ„åŸç”Ÿæ¨¡å—â€”â€”è¿™æ˜¯ç»å¤§å¤šæ•°å¼€æºé¡¹ç›®åšä¸åˆ°çš„ã€‚\n\nå®ƒè§£å†³äº†å¼€å‘è€…/ä¼ä¸šçš„æ ¸å¿ƒçŸ›ç›¾ï¼š**æ—¢è¦è½»é‡å¿«é€Ÿçš„ä¸ªäººä½“éªŒï¼Œåˆè¦ä¼ä¸šçº§å¯æ§æ€§ï¼Œè€Œä¸æ„¿ä¸º SaaS ä»˜è´¹æˆ–å¿å—é—­æºé™åˆ¶ã€‚**\n\n---\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n1. **åŠ¨æ€ API è·¯ç”±ä»£ç† + è¯·æ±‚é‡å†™å¼•æ“ï¼ˆRequest Interceptorï¼‰**\n   - æ‰€æœ‰å¤–éƒ¨æ¨¡å‹è¯·æ±‚é€šè¿‡ `/api/proxy/[model]` ç»Ÿä¸€å…¥å£ï¼ŒæœåŠ¡ç«¯æ ¹æ® `X-Provider` å¤´æˆ–ç¯å¢ƒå˜é‡è‡ªåŠ¨æ³¨å…¥å¯¹åº” API Keyã€Endpointã€Header æ ¼å¼ã€‚\n   - æ”¯æŒ **å“åº”æµå¼é‡ç¼–ç **ï¼šå°†ä¸åŒå‚å•†çš„ SSE æµï¼ˆOpenAIï¼‰è½¬ä¸ºæ ‡å‡† JSON Linesï¼ˆClaudeï¼‰ï¼Œç»Ÿä¸€å‰ç«¯æ¶ˆè´¹é€»è¾‘ã€‚\n   - å®ç°äº† `transformStream()` + `TextDecoderStream` çš„é“¾å¼å¤„ç†ï¼Œé¿å…å†…å­˜çˆ†æ¶¨ã€‚\n\n2. **æœ¬åœ°ç¼“å­˜+ç¦»çº¿é˜Ÿåˆ—ï¼ˆIndexedDB + WorkManager æ¨¡æ‹Ÿï¼‰**\n   - åœ¨ PWA/ç§»åŠ¨ç«¯ï¼Œæ¶ˆæ¯æœªå‘é€æ—¶è‡ªåŠ¨å­˜å…¥ IndexedDBï¼Œå¹¶åœ¨æ¢å¤ç½‘ç»œåé‡è¯•ã€‚\n   - ä½¿ç”¨ `queue-async` å®ç°ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼šç”¨æˆ·è¾“å…¥ > ç³»ç»Ÿé€šçŸ¥ > å†å²åŒæ­¥ã€‚\n\n3. **MCPï¼ˆModel Control Protocolï¼‰åè®®æ”¯æŒ**\n   - è‡ªå®šä¹‰è½»é‡åè®®ï¼Œå…è®¸æ’ä»¶å¼æ³¨å…¥æ¨¡å‹è¡Œä¸ºï¼š\n     ```ts\n     interface MCPPlugin {\n       canHandle(prompt: string): boolean;\n       handle(prompt: string, context: Context): AsyncGenerator<Chunk>;\n     }\n     ```\n   - é€šè¿‡ `ENABLE_MCP=true` å¯ç”¨ï¼Œå®ç°â€œæœ¬åœ°è§„åˆ™æ‹¦æˆªâ€ï¼ˆå¦‚ï¼šè¿‡æ»¤æ•æ„Ÿè¯ã€è‡ªåŠ¨æ‘˜è¦ã€è°ƒç”¨å†…éƒ¨å·¥å…·ï¼‰ï¼Œæ— éœ€ä¿®æ”¹æ ¸å¿ƒé€»è¾‘ã€‚\n\n4. **UI çŠ¶æ€æœºé©±åŠ¨çš„å¯¹è¯ç®¡ç†**\n   - ä½¿ç”¨ XState å®ç°å¯¹è¯çŠ¶æ€ï¼š`idle â†’ streaming â†’ error â†’ finished â†’ editing`\n   - æ¯ä¸ªçŠ¶æ€è§¦å‘ä¸åŒ UI è¡Œä¸ºï¼ˆå¦‚ï¼šæµå¼æ»šåŠ¨ã€å–æ¶ˆæŒ‰é’®æ˜¾éšã€è¾“å…¥æ¡†ç¦ç”¨ï¼‰ï¼Œæå¤§æå‡äº¤äº’ä¸€è‡´æ€§ã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n#### 1. æ•´ä½“æ¶æ„å›¾ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Frontend (React) â”‚â—„----â”‚    API Gateway    â”‚â—„----â”‚ External AI APIs   â”‚\nâ”‚  (Web/iOS/Android) â”‚     â”‚ (Next.js App Dir) â”‚     â”‚ (OpenAI, Claude..) â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â”‚                           â”‚                         â”‚\n          â–¼                           â–¼                         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  State Manager     â”‚     â”‚   Request Proxy   â”‚     â”‚   MCP Plugin      â”‚\nâ”‚ (Zustand/XState)   â”‚â—„----â”‚ (Auth/Key Routing)â”‚â—„----â”‚ (Rule Engine)     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â”‚                           â”‚                         â”‚\n          â–¼                           â–¼                         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Local Storage      â”‚     â”‚  Audit Log DB     â”‚     â”‚  Knowledge Base   â”‚\nâ”‚ (IndexedDB)        â”‚     â”‚ (PostgreSQL/SQLite)â”‚     â”‚ (FAISS/Pinecone)  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n#### 2. æ ¸å¿ƒæ¨¡å—åˆ’åˆ†ä¸èŒè´£\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| `app/` (Next.js App Router) | å¤„ç†è·¯ç”±ã€API æ¥å£ã€SSR/CSR åˆ†å‘ |\n| `lib/chat/` | å¯¹è¯æ ¸å¿ƒé€»è¾‘ï¼šæ¶ˆæ¯ç®¡ç†ã€æµå¼å¤„ç†ã€çŠ¶æ€æœºã€é‡è¯•æœºåˆ¶ |\n| `lib/providers/` | æ¨¡å‹é€‚é…å™¨ï¼ˆOpenAI, Claude, Gemini ç­‰ï¼‰ï¼Œå®ç°ç»Ÿä¸€æ¥å£ `ChatProvider` |\n| `lib/mcp/` | MCP æ’ä»¶ç³»ç»Ÿï¼Œæ”¯æŒè¿è¡Œæ—¶åŠ è½½ JS è„šæœ¬è§„åˆ™ |\n| `components/ui/` | æ— çŠ¶æ€ UI ç»„ä»¶ï¼Œå¤ç”¨ç‡ >90%ï¼Œè·¨å¹³å°ä¸€è‡´ |\n| `server/admin/` | ä¼ä¸šç‰ˆä¸“ç”¨ï¼šRBAC æƒé™ã€å®¡è®¡æ—¥å¿—ã€çŸ¥è¯†åº“ç®¡ç†ï¼ˆNode.js + Prismaï¼‰ |\n| `electron/`, `capacitor/` | å¹³å°é€‚é…å±‚ï¼šè°ƒç”¨åŸç”Ÿ APIï¼ˆæ–‡ä»¶ç³»ç»Ÿã€é€šçŸ¥ã€å‰ªè´´æ¿ï¼‰ |\n\n#### 3. æ•°æ®æµå‘\n\n```\nç”¨æˆ·è¾“å…¥ â†’ [UI] â†’ è°ƒç”¨ chat.send() â†’ \n   â”œâ”€ æ£€æŸ¥ MCP æ’ä»¶æ˜¯å¦æ‹¦æˆª â†’ æ˜¯ï¼šè¿”å›æ’ä»¶è¾“å‡º\n   â””â”€ å¦ï¼šé€‰æ‹© Providerï¼ˆæ ¹æ®é…ç½®/ä¼šè¯è®¾ç½®ï¼‰\n       â†’ æ³¨å…¥ API Key & è¯·æ±‚å¤´\n       â†’ å‘é€ POST /v1/chat/completions (æ ‡å‡†åŒ–ä¸º OpenAI æ ¼å¼)\n       â†’ æ¥æ”¶ SSE æµ â†’ è§£æå¹¶è½¬ä¸º {role, content, done}\n       â†’ å†™å…¥ IndexedDBï¼ˆæœ¬åœ°æŒä¹…åŒ–ï¼‰\n       â†’ æ›´æ–° Zustand Store â†’ è§¦å‘ UI é‡æ¸²æŸ“\n       â†’ åŒæ­¥å®¡è®¡æ—¥å¿—åˆ°åç«¯ï¼ˆä¼ä¸šç‰ˆï¼‰\n```\n\n#### 4. å…³é”®è®¾è®¡æ¨¡å¼\n\n| æ¨¡å¼ | åº”ç”¨åœºæ™¯ | åŸå›  |\n|------|----------|------|\n| **ç­–ç•¥æ¨¡å¼** | `ChatProvider` æ¥å£ï¼ˆOpenAIProvider, ClaudeProviderï¼‰ | è§£è€¦æ¨¡å‹å®ç°ï¼Œå¯çƒ­æ’æ‹” |\n| **ä¸­ä»‹è€…æ¨¡å¼** | Zustand Store ä½œä¸ºå”¯ä¸€çŠ¶æ€æºï¼ŒUI ç»„ä»¶ä¸ç›´æ¥é€šä¿¡ | é¿å…ç»„ä»¶æ ‘åµŒå¥—è¿‡æ·±å¯¼è‡´çš„ props drilling |\n| **è§‚å¯Ÿè€…æ¨¡å¼** | MCP æ’ä»¶ç›‘å¬ `onPrompt` äº‹ä»¶ | å®ç°éä¾µå…¥å¼åŠŸèƒ½æ‰©å±•ï¼ˆå¦‚ï¼šè‡ªåŠ¨ç¿»è¯‘ã€æ•æ„Ÿè¯è¿‡æ»¤ï¼‰ |\n| **å¤–è§‚æ¨¡å¼** | `/api/chat` ç»Ÿä¸€å…¥å£å°è£…æ‰€æœ‰æ¨¡å‹è°ƒç”¨ç»†èŠ‚ | å‰ç«¯æ— éœ€å…³å¿ƒ API å·®å¼‚ï¼Œé™ä½è®¤çŸ¥è´Ÿè· |\n\n---\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| æŠ€æœ¯ | é€‰æ‹©ç†ç”± | æ›¿ä»£æ–¹æ¡ˆ | æ³¨æ„äº‹é¡¹ |\n|------|----------|----------|----------|\n| **TypeScript + Next.js 14 (App Router)** | ç±»å‹å®‰å…¨ + Server Actions æ”¯æŒ API è·¯ç”± + åŸç”Ÿ SSR/SSG | Remix / Nuxt | å¿…é¡»ç”¨ `use client` æ ‡è®°çŠ¶æ€ç®¡ç†ç»„ä»¶ï¼Œå¦åˆ™ Zustand åœ¨ SSR ç«¯æŠ¥é”™ |\n| **Zustand** | æ¯” Redux Toolkit æ›´è½»é‡ï¼Œæ”¯æŒå¼‚æ­¥ action å’Œ hooks ç›´æ¥è®¢é˜… | Jotai / Recoil | ä¸èƒ½åœ¨ Server Component ä¸­ä½¿ç”¨ï¼Œæ‰€æœ‰ state å¿…é¡»å®¢æˆ·ç«¯æ¸²æŸ“ |\n| **Tauri (æ¡Œé¢ç«¯)** | æ›¿ä»£ Electronï¼šRust å†…æ ¸ï¼Œä½“ç§¯ <10MBï¼Œå†…å­˜å ç”¨ä½ | Electron | éœ€é…ç½® `tauri.conf.json` å¼€å¯ `shell` API ä»¥è°ƒç”¨ç³»ç»Ÿå‘½ä»¤ï¼ˆå¦‚å¯åŠ¨æœ¬åœ°æ¨¡å‹ï¼‰ |\n| **Capacitor (ç§»åŠ¨ç«¯)** | åŸç”Ÿ WebView åŒ…è£… + æ”¯æŒ iOS/Android åŸç”Ÿæ’ä»¶ | React Native | ä¸æ”¯æŒ Web Workersï¼Œæµå¼å“åº”éœ€é™çº§ä¸ºåˆ†å— JSON |\n| **IndexedDB + idb-keyval** | æµè§ˆå™¨åŸç”Ÿå­˜å‚¨ï¼Œæ”¯æŒå¤§æ–‡æœ¬ï¼ˆ>50MBï¼‰ | localStorage / SQLite (via react-native-sqlite) | å¿…é¡»å¼‚æ­¥æ“ä½œï¼Œé¿å…é˜»å¡ UIï¼›å»ºè®®å¯ç”¨å‹ç¼©ï¼ˆlz-stringï¼‰ |\n| **Vercel/Zeabur éƒ¨ç½²** | æ— ç¼é›†æˆ Git Hook + ç¯å¢ƒå˜é‡ç®¡ç† | Docker + Nginx | `OPENAI_API_KEY` å¿…é¡»é€šè¿‡ç¯å¢ƒå˜é‡æ³¨å…¥ï¼Œä¸å¯ç¡¬ç¼–ç åœ¨ä»£ç ä¸­ |\n\n> âš ï¸ ç‰ˆæœ¬å…¼å®¹æ€§é™·é˜±ï¼šNext.js 14.2+ å¯¹ Server Actions çš„ CSRF éªŒè¯ä¸¥æ ¼ï¼Œè‹¥ä½¿ç”¨è‡ªå®šä¹‰ç™»å½•ï¼Œéœ€é…ç½® `next.config.js: experimental: { serverActions: { allowedOrigins: ['*'] } }`\n\n---\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. å…‹éš†é¡¹ç›®ï¼ˆæ¨èä½¿ç”¨ SSHï¼‰\ngit clone git@github.com:ChatGPTNextWeb/ChatGPT-Next-Web.git\ncd ChatGPT-Next-Web\n\n# 2. å®‰è£…ä¾èµ–ï¼ˆç¡®ä¿ Node.js >=18ï¼‰\nnpm install\n\n# 3. åˆ›å»º .env.local æ–‡ä»¶ï¼ˆå…³é”®ï¼ï¼‰\ncp .env.example .env.local\n\n# ç¼–è¾‘ .env.localï¼Œå¡«å…¥è‡³å°‘ä¸€ä¸ª API Keyï¼š\nOPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxx\n# å¯é€‰ï¼šæ·»åŠ å…¶ä»–æ¨¡å‹\nCLAUDE_API_KEY=sk-ant-something...\nGEMINI_API_KEY=AIzaSyxxxxxxxxx\n\n# 4. å¯åŠ¨å¼€å‘æœåŠ¡å™¨ï¼ˆWebï¼‰\nnpm run dev\n\n# 5. æ„å»ºæ¡Œé¢ç‰ˆï¼ˆéœ€å®‰è£… Tauri CLIï¼‰\nnpm install -g @tauri-apps/cli\ncd tauri\ntauri build  # è¾“å‡º dist/ ä¸‹çš„ .exe/.dmg/.deb\n\n# 6. æ„å»º iOS/Androidï¼ˆéœ€ Capacitorï¼‰\nnpx cap add ios   # æˆ– android\nnpx cap open ios  # åœ¨ Xcode ä¸­ç¼–è¯‘è¿è¡Œ\n```\n\n> ğŸ’¡ æç¤ºï¼šè‹¥æƒ³å¯ç”¨ MCPï¼Œå¯åŠ¨å‰æ·»åŠ ï¼š\n```bash\nENABLE_MCP=true npm run dev\n```\n\n---\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n**åœºæ™¯**ï¼šç”¨æˆ·è¦æ±‚ç”¨ DeepSeek æ¨¡å‹å†™ä¸€æ®µ Python çˆ¬è™«ï¼Œå¹¶å¸Œæœ›è‡ªåŠ¨è¿‡æ»¤â€œæš´åŠ›â€å…³é”®è¯ã€‚\n\n```ts\n// ç”¨æˆ·è¾“å…¥ï¼ˆå‰ç«¯ï¼‰\nconst prompt = \"å¸®æˆ‘å†™ä¸€ä¸ªçˆ¬å–è±†ç“£ç”µå½± Top250 çš„ Python è„šæœ¬ï¼Œä¸è¦åŒ…å«ä»»ä½•æš´åŠ›å†…å®¹ã€‚\"\n\n// åç«¯å¤„ç†æµç¨‹ï¼ˆlib/providers/deepseek.tsï¼‰\nexport class DeepSeekProvider implements ChatProvider {\n  async stream(messages: Message[]): AsyncGenerator<ChatCompletionChunk> {\n    const response = await fetch('https://api.deepseek.com/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${process.env.DEEPSEEK_API_KEY}`,\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        model: 'deepseek-chat',\n        messages,\n        stream: true\n      })\n    })\n\n    const reader = response.body?.getReader()\n    const decoder = new TextDecoder()\n\n    while (true) {\n      const { done, value } = await reader!.read()\n      if (done) break\n\n      const chunk = decoder.decode(value)\n      for (const line of chunk.split('\\n')) {\n        if (!line.startsWith('data:')) continue\n        const json = JSON.parse(line.slice(5))\n        if (json.choices[0]?.delta?.content) {\n          // MCP æ’ä»¶ç›‘å¬ï¼šæ£€æŸ¥æ˜¯å¦å«æš´åŠ›è¯\n          const filtered = await mcpFilter(json.choices[0].delta.content)\n          yield { content: filtered, done: false }\n        }\n      }\n    }\n\n    yield { content: '', done: true }\n  }\n}\n```\n\n**é¢„æœŸè¾“å‡º**ï¼š\n```json\n{\n  \"role\": \"assistant\",\n  \"content\": \"import requests\\nfrom bs4 import BeautifulSoup\\n\\nurl = \\\"https://movie.douban.com/top250\\\"\\nresponse = requests.get(url)\\nsoup = BeautifulSoup(response.text, 'html.parser')\\ntitles = [h3.find('span').text for h3 in soup.select('.hd a span')]\\nprint(titles)\"\n}\n```\n\n**å…³é”®å‚æ•°è¯´æ˜**ï¼š\n- `model: 'deepseek-chat'` â†’ å¿…é¡»ä¸ DeepSeek API æ–‡æ¡£ä¸€è‡´\n- `stream: true` â†’ å¯ç”¨æµå¼å“åº”ï¼Œå‰ç«¯æ‰èƒ½å®æ—¶æ¸²æŸ“\n- MCP æ’ä»¶è‡ªåŠ¨æ‹¦æˆªâ€œæš´åŠ›â€ç­‰è¯å¹¶æ›¿æ¢ä¸ºâ€œä¸é€‚å®œå†…å®¹â€ï¼Œæ— éœ€ç”¨æˆ·æ‰‹åŠ¨ä¿®æ”¹æç¤ºè¯\n\n---\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n| æŒ‡æ ‡ | ä¼°ç®—å€¼ | è¯´æ˜ |\n|------|--------|------|\n| **é¦–å±åŠ è½½æ—¶é—´ï¼ˆWebï¼‰** | <800ms (gzip) | Next.js é™æ€èµ„æºé¢„åŠ è½½ + code splitting |\n| **å•æ¡æ¶ˆæ¯å»¶è¿Ÿï¼ˆGPT-",
    "last_scanned": "2026-01-16T02:03:15.386822",
    "last_analyzed": "2026-01-15T05:32:54.286919",
    "screenshot": "static/screenshots/612344730.jpg",
    "ai_visual_summary": "æ ¹æ®æä¾›çš„æˆªå›¾å’Œä¿¡æ¯ï¼Œè¿™æ˜¯ä¸€ä¸ªåä¸º **NextChat** çš„å¼€æº AI åŠ©æ‰‹é¡¹ç›®ã€‚è¯¥åº”ç”¨çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯ä½œä¸ºä¸€æ¬¾è½»é‡ä¸”å¿«é€Ÿçš„ AI åŠ©æ‰‹ï¼Œæ”¯æŒåœ¨ Webã€iOSã€macOSã€Androidã€Linux å’Œ Windows ç­‰å¤šç§å¹³å°è¿è¡Œã€‚ä»ç•Œé¢ä¸­â€œç¯å¢ƒå˜é‡â€ï¼ˆEnvironment Variablesï¼‰çš„é…ç½®æ¥çœ‹ï¼Œè¯¥é¡¹ç›®éœ€è¦ç”¨æˆ·é…ç½® `OPENAI_API_KEY` ç­‰å…³é”®å‚æ•°ï¼Œè¿™è¡¨æ˜å®ƒæ˜¯ä¸€ä¸ªåŸºäº OpenAI æœåŠ¡ï¼ˆå¦‚ GPT æ¨¡å‹ï¼‰çš„å®¢æˆ·ç«¯åº”ç”¨ã€‚å…¶ UI è®¾è®¡é£æ ¼ç®€æ´ã€ç°ä»£ï¼Œä»¥çº¯æ–‡æœ¬å’Œæ¸…æ™°çš„åˆ†ç»„ä¸ºä¸»ï¼Œæ³¨é‡åŠŸèƒ½æ€§ï¼Œç¬¦åˆå…¸å‹çš„å¼€æºé¡¹ç›® README æ–‡æ¡£é£æ ¼ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "669879380",
    "name": "LLMs-from-scratch",
    "full_name": "rasbt/LLMs-from-scratch",
    "category": "llm_rag",
    "stars": 83100,
    "forks": 12495,
    "description": "Implement a ChatGPT-like LLM in PyTorch from scratch, step by step",
    "url": "https://github.com/rasbt/LLMs-from-scratch",
    "homepage": "https://amzn.to/4fqvn0D",
    "language": "Jupyter Notebook",
    "topics": "[\"ai\", \"artificial-intelligence\", \"chatbot\", \"chatgpt\", \"deep-learning\", \"from-scratch\", \"generative-ai\", \"gpt\", \"language-model\", \"large-language-models\", \"llm\", \"machine-learning\", \"neural-networks\", \"python\", \"pytorch\", \"transformers\"]",
    "created_at": "2023-07-23T18:15:57Z",
    "updated_at": "2026-01-15T17:33:09Z",
    "readme_content": null,
    "ai_summary": "ä»é›¶å¼€å§‹æ„å»ºGPTç±»å¤§å‹è¯­è¨€æ¨¡å‹çš„æ•™å­¦å®è·µé¡¹ç›®ï¼Œé€šè¿‡PyTorchå®ç°åˆ†æ­¥è®­ç»ƒä¸å¾®è°ƒ",
    "ai_tech_stack": "[\"Python\", \"PyTorch\"]",
    "ai_use_cases": "[\"\\u6559\\u80b2\\u7528\\u9014\\uff1a\\u7406\\u89e3LLM\\u5185\\u90e8\\u5de5\\u4f5c\\u539f\\u7406\\u7684\\u5b9e\\u8df5\\u6848\\u4f8b\", \"\\u57fa\\u7840\\u6784\\u5efa\\uff1a\\u5c0f\\u89c4\\u6a21\\u529f\\u80fd\\u6027LLM\\u5f00\\u53d1\\u793a\\u4f8b\", \"\\u4ee3\\u7801\\u5e93\\u5f00\\u53d1\\uff1a\\u63d0\\u4f9b\\u5b8c\\u6574\\u53ef\\u8fd0\\u884c\\u7684\\u57fa\\u7840\\u6a21\\u578b\\u5b9e\\u73b0\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "git clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\n**å”¯ä¸€ä¸€ä¸ªä»é›¶åˆ°ç”Ÿäº§çº§ GPT æ¶æ„çš„â€œå®Œæ•´å¯è¿è¡Œâ€æ•™å­¦å®ç°**ã€‚  \nä¸å¤§å¤šæ•°ä»…å±•ç¤º Transformer ç¼–ç å™¨æˆ– toy LLM çš„å¼€æºæ•™ç¨‹ä¸åŒï¼Œè¯¥é¡¹ç›®**ç«¯åˆ°ç«¯å®ç°äº† GPT-2/3 çº§æ¶æ„çš„é¢„è®­ç»ƒã€å¾®è°ƒã€æ¨ç†å’Œæƒé‡åŠ è½½**ï¼Œä¸”æ‰€æœ‰ä»£ç å‡ä¸ºçº¯ PyTorch æ‰‹å†™ï¼ˆæ—  Hugging Face `transformers` ä¾èµ–ï¼‰ï¼Œåœ¨æ™®é€šç¬”è®°æœ¬ä¸Šå¯è¿è¡Œã€‚å®ƒè§£å†³äº†â€œ**ç†è®ºæ‡‚äº†ï¼Œä½†ä»£ç ä»å“ªå¼€å§‹å†™ï¼Ÿ**â€è¿™ä¸€å¼€å‘è€…ç—›ç‚¹â€”â€”å¸‚é¢ä¸Šç»å¤§å¤šæ•°æ•™ç¨‹æ­¢æ­¥äºâ€œå®ç°ä¸€ä¸ª Transformer blockâ€ï¼Œè€Œæœ¬é¡¹ç›®ä¸€è·¯èµ°é€šï¼š\n\n- **è¯å…ƒåŒ–ï¼ˆTokenizerï¼‰**ï¼šè‡ªç ” BPE å®ç°ï¼ˆéä¾èµ– `tiktoken`ï¼‰\n- **æ¨¡å‹æ¶æ„**ï¼šå®Œæ•´ GPT-2 ç»“æ„ï¼ˆLayerNormã€GELUã€å¤šå¤´æ³¨æ„åŠ›ã€ä½ç½®ç¼–ç ã€æ®‹å·®è¿æ¥ï¼‰\n- **è®­ç»ƒå¾ªç¯**ï¼šè‡ªå®šä¹‰ DataLoader + æ¢¯åº¦ç´¯ç§¯ + å­¦ä¹ ç‡è°ƒåº¦\n- **é¢„è®­ç»ƒ**ï¼šåœ¨ WikiText-103 ä¸Šä»é›¶è®­ç»ƒï¼ˆéå¾®è°ƒï¼‰\n- **æ¨ç†ä¼˜åŒ–**ï¼šå®ç° KV ç¼“å­˜ã€è´ªå©ªè§£ç ã€æ¸©åº¦é‡‡æ ·\n- **æƒé‡è¿ç§»**ï¼šåŠ è½½ Hugging Face é¢„è®­ç»ƒæ¨¡å‹å¹¶æ˜ å°„å‚æ•°ç”¨äºå¾®è°ƒ\n\nå®ƒä¸æ˜¯â€œç©å…·â€ï¼Œè€Œæ˜¯**å·¥ä¸šçº§ LLM æ¶æ„çš„æ•™å­¦å¤åˆ»ç‰ˆ**ï¼ŒçœŸæ­£è®©å¼€å‘è€…èƒ½è¯´ï¼šâ€œæˆ‘å†™è¿‡ä¸€ä¸ªèƒ½è·‘çš„ ChatGPTâ€ã€‚\n\n---\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n1. **æ‰‹å†™ BPE Tokenizer + ä¸æ¨¡å‹ç«¯åˆ°ç«¯é›†æˆ**  \n   ä¸ä¾èµ– `tiktoken` æˆ– `transformers` çš„ tokenizerï¼Œå®Œå…¨ä»æ–‡æœ¬åˆ‡åˆ†ã€è¯è¡¨æ„å»ºã€ç¼–ç /è§£ç å®ç°ï¼Œç†è§£ tokenization å¦‚ä½•å½±å“æ¨¡å‹è¾“å…¥ç©ºé—´ã€‚\n\n2. **åŠ¨æ€ä½ç½®ç¼–ç ï¼ˆRotary Position Embedding ç®€åŒ–ç‰ˆï¼‰**  \n   è™½æœªç”¨ RoPEï¼ˆGPT-2 ç”¨çš„æ˜¯ç»å¯¹ä½ç½®åµŒå…¥ï¼‰ï¼Œä½†ä»£ç æ¸…æ™°åˆ†ç¦»äº† `PositionalEncoding` æ¨¡å—ï¼Œä¸ºåç»­è¿ç§»åˆ° RoPEã€ALiBi æä¾›äº†å¹²å‡€æ¥å£ã€‚\n\n3. **KV ç¼“å­˜å®ç°ï¼ˆInference-Time Scalingï¼‰**  \n   åœ¨æ¨ç†é˜¶æ®µå®ç°é”®å€¼ç¼“å­˜ï¼ˆKey-Value Cacheï¼‰ï¼Œé¿å…é‡å¤è®¡ç®—å†å² token çš„ QK çŸ©é˜µï¼Œä½¿ç”Ÿæˆé€Ÿåº¦æå‡ 5â€“10xï¼Œæ˜¯ç”Ÿäº§éƒ¨ç½²çš„**å…³é”®ä¼˜åŒ–ç‚¹**ã€‚\n\n4. **å‚æ•°æ˜ å°„å±‚ï¼šä» HF æƒé‡åˆ°è‡ªå®šä¹‰æ¨¡å‹**  \n   å®ç°äº† `load_weights_from_hf()` å‡½æ•°ï¼Œå°† Hugging Face çš„ GPT-2 checkpointï¼ˆå¦‚ `gpt2-small`ï¼‰è‡ªåŠ¨æ˜ å°„åˆ°è‡ªå·±å®ç°çš„æ¨¡å—ä¸­ï¼ˆåŒ…æ‹¬ LayerNormã€Attentionã€MLP ç­‰ï¼‰ï¼Œè§£å†³äº†â€œæˆ‘å†™äº†ä¸€å †ä»£ç ï¼Œæ€ä¹ˆçŸ¥é“å®ƒå¯¹ä¸å¯¹ï¼Ÿâ€çš„é—®é¢˜ã€‚\n\n5. **æ¢¯åº¦ç´¯ç§¯ + æ··åˆç²¾åº¦è®­ç»ƒæ”¯æŒ**  \n   åœ¨æœ‰é™ GPU å†…å­˜ä¸‹ï¼Œé€šè¿‡ `torch.cuda.amp` å®ç°è‡ªåŠ¨æ··åˆç²¾åº¦ï¼Œå¹¶æ‰‹åŠ¨å®ç°æ¢¯åº¦ç´¯ç§¯ï¼ˆæ¯ N æ­¥æ›´æ–°ä¸€æ¬¡ï¼‰ï¼Œä½¿ 124M å‚æ•°æ¨¡å‹èƒ½åœ¨ 8GB æ˜¾å­˜ä¸Šé¢„è®­ç»ƒã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n#### 1. æ•´ä½“æ¶æ„å›¾ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\n[è¾“å…¥æ–‡æœ¬] \n    â†’ Tokenizer (BPE) \n    â†’ Embedding Layer (Token + Positional) \n    â†’ [Transformer Block Ã— N] \n        â”œâ”€â”€ MultiHeadAttention (QKV + Masked Self-Attn + Proj)\n        â”œâ”€â”€ Add & Norm (Residual + LayerNorm)\n        â”œâ”€â”€ MLP (GELU + Linear)\n        â””â”€â”€ Add & Norm\n    â†’ Final LayerNorm \n    â†’ Output Head (Linear â†’ Logits) \n    â†’ Softmax â†’ Token Probabilities\n```\n\nè®­ç»ƒæ—¶ï¼š`Loss = CrossEntropy(é¢„æµ‹token, çœŸå®token)`  \næ¨ç†æ—¶ï¼š`Autoregressive Sampling â†’ é€ token ç”Ÿæˆï¼Œå¸¦ KV Cache`\n\n#### 2. æ ¸å¿ƒæ¨¡å—åˆ’åˆ†ä¸èŒè´£\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| `GPTModel` | ä¸»æ¨¡å‹ç±»ï¼Œç»„åˆ Embedding + NÃ—TransformerBlock |\n| `TransformerBlock` | å•ä¸ª Transformer å—ï¼šAttention â†’ AddNorm â†’ MLP â†’ AddNorm |\n| `MultiHeadAttention` | å®ç° masked self-attentionï¼Œæ”¯æŒ batch & sequence masking |\n| `PositionalEncoding` | ç»å¯¹ä½ç½®åµŒå…¥ï¼ˆsinusoidalï¼‰æˆ–å¯å­¦ä¹ åµŒå…¥ |\n| `Tokenizer` | è‡ªç ” BPE åˆ†è¯å™¨ï¼Œæ”¯æŒ vocab æ„å»ºã€ç¼–ç /è§£ç  |\n| `Dataset` | æ–‡æœ¬åˆ†å—ï¼ˆblock_size=1024ï¼‰ã€æ»‘åŠ¨çª—å£é‡‡æ · |\n| `Trainer` | è®­ç»ƒå¾ªç¯ï¼šloss.backward() + grad clipping + optimizer.step() |\n\n#### 3. æ•°æ®æµå‘\n\n```\nåŸå§‹æ–‡æœ¬ â†’ Tokenize â†’ [token_ids: (batch, seq_len)] \nâ†’ Embedding Lookup â†’ (batch, seq_len, d_model)\nâ†’ Positional Encoding åŠ å…¥\nâ†’ ä¼ å…¥ TransformerBlock Ã— Nï¼ˆæ¯å±‚å« Attention + MLPï¼‰\nâ†’ LayerNorm è¾“å‡º â†’ Linear Head â†’ Logits (batch, seq_len, vocab_size)\nâ†’ Softmax â†’ æ¦‚ç‡åˆ†å¸ƒ â†’ é‡‡æ ·ä¸‹ä¸€ä¸ª tokenï¼ˆæ¨ç†ï¼‰æˆ– CrossEntropy Lossï¼ˆè®­ç»ƒï¼‰\n```\n\n#### 4. å…³é”®è®¾è®¡æ¨¡å¼\n\n- **ç»„åˆä¼˜äºç»§æ‰¿**ï¼š`GPTModel` ç»„åˆå¤šä¸ªæ¨¡å—ï¼Œè€Œéç»§æ‰¿è‡ª `nn.ModuleList`ï¼Œä¾¿äºè°ƒè¯•ä¸æ›¿æ¢ã€‚\n- **ç­–ç•¥æ¨¡å¼**ï¼šTokenizerã€Lossã€Sampler å‡å¯æ’æ‹”ï¼ˆå¦‚æ›¿æ¢ä¸º WordPiece æˆ– Top-K é‡‡æ ·ï¼‰ã€‚\n- **å·¥å‚æ¨¡å¼**ï¼š`create_gpt_model(config)` æ ¹æ®é…ç½®ï¼ˆd_model, n_heads, n_layersï¼‰åŠ¨æ€æ„å»ºæ¨¡å‹ã€‚\n- **ä¾èµ–æ³¨å…¥**ï¼šè®­ç»ƒå™¨æ¥æ”¶ modelã€optimizerã€datasetï¼Œè€Œéç¡¬ç¼–ç ï¼Œä¾¿äºå•å…ƒæµ‹è¯•ã€‚\n\n> âœ… è®¾è®¡å“²å­¦ï¼š**æ¨¡å—è§£è€¦ + å¯è§‚æµ‹æ€§ä¼˜å…ˆ**ã€‚æ¯ä¸ªç»„ä»¶éƒ½å¯ç‹¬ç«‹æµ‹è¯•ã€æ‰“å° shapeã€å¯è§†åŒ–æ¢¯åº¦ã€‚\n\n---\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| æŠ€æœ¯ | é€‰æ‹©åŸå›  | æ›¿ä»£æ–¹æ¡ˆ | å…¼å®¹æ€§æ³¨æ„ |\n|------|----------|-----------|-------------|\n| **PyTorch 2.x** | åŠ¨æ€å›¾ + æ˜“è°ƒè¯• + åŸç”Ÿ `torch.compile()` æ”¯æŒ | JAX/TensorFlow | ä½¿ç”¨ `torch.compile()` éœ€ CUDA >=11.8ï¼Œå»ºè®®ç”¨ 2.0+ |\n| **NumPy / SciPy** | BPE ç®—æ³•å®ç°ã€è¯è¡¨ç»Ÿè®¡ | Pandasï¼ˆæ…¢ï¼‰ | ä»…ç”¨äºé¢„å¤„ç†ï¼Œä¸å‚ä¸è®­ç»ƒ |\n| **Hugging Face Transformers (ä»…åŠ è½½æƒé‡)** | æä¾›æ ‡å‡† GPT-2 checkpoint æ˜ å°„ | è‡ªå»ºæ¨¡å‹æƒé‡ | ä¸ä½œä¸ºä¾èµ–é¡¹å¼•å…¥ï¼ä»… `torch.load()` åŠ è½½ .bin æ–‡ä»¶ |\n| **tqdm** | è®­ç»ƒè¿›åº¦å¯è§†åŒ– | åŸç”Ÿ print | æ— å…¼å®¹æ€§é—®é¢˜ |\n| **matplotlib / seaborn** | æŸå¤±æ›²çº¿ç»˜åˆ¶ | Weights & Biases | ä»…æ•™å­¦ç”¨ï¼Œå¯é€‰ |\n\n> âš ï¸ å…³é”®ï¼šé¡¹ç›®åˆ»æ„é¿å… `transformers` åº“ä½œä¸ºè¿è¡Œæ—¶ä¾èµ–â€”â€”æ‰€æœ‰æ¨¡å‹ã€tokenizerã€è®­ç»ƒé€»è¾‘å‡ä¸ºæ‰‹å†™ã€‚è¿™æ˜¯å®ƒåŒºåˆ«äºâ€œæ•™ç¨‹å¼å¤ç°â€çš„**æ ¸å¿ƒè®¾è®¡åŸåˆ™**ã€‚\n\n---\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. å…‹éš†ä»“åº“ï¼ˆæ·±åº¦å…‹éš†ï¼Œé¿å…ä¸¢å¤±å†å²ï¼‰\ngit clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git\ncd LLMs-from-scratch\n\n# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨è uv æˆ– poetryï¼‰\npython -m venv llm-env\nsource llm-env/bin/activate  # Windows: llm-env\\Scripts\\activate\n\n# 3. å®‰è£…æ ¸å¿ƒä¾èµ–ï¼ˆæ—  transformersï¼ï¼‰\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\npip install numpy matplotlib tqdm jupyter notebook\n\n# 4. ä¸‹è½½æ•°æ®é›†ï¼ˆWikiText-103ï¼Œè‡ªåŠ¨ä¸‹è½½åˆ° data/ï¼‰\npython setup/download_data.py  # è„šæœ¬åœ¨ repo ä¸­å·²æä¾›\n\n# 5. å¯åŠ¨ Jupyterï¼ˆæ‰€æœ‰ä»£ç ä¸º .ipynbï¼‰\njupyter notebook\n```\n\n> âœ… **æ¨èç¯å¢ƒ**ï¼šLinux/macOS + CUDA 12.1 + PyTorch 2.1+ï¼ŒGPU æ˜¾å­˜ â‰¥8GBã€‚CPU å¯è¿è¡Œä½†è®­ç»ƒææ…¢ã€‚\n\n---\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n```python\n# ç¤ºä¾‹ï¼šä»é›¶è®­ç»ƒä¸€ä¸ªå¾®å‹ GPTï¼ˆä»… 2 å±‚ï¼‰ï¼Œç”Ÿæˆæ–‡æœ¬\n\nfrom model import GPTModel\nfrom tokenizer import SimpleTokenizer\nfrom dataset import TextDataset\nfrom trainer import train_model\n\n# é…ç½®\nconfig = {\n    'vocab_size': 50257,      # GPT-2 vocab size (æ¥è‡ª HF)\n    'context_length': 1024,\n    'd_model': 128,\n    'n_heads': 4,\n    'n_layers': 2,\n    'dropout': 0.1\n}\n\n# å®ä¾‹åŒ–æ¨¡å‹ï¼ˆçº¯ PyTorchï¼‰\nmodel = GPTModel(config)\n\n# åŠ è½½ tokenizerï¼ˆè‡ªç ” BPEï¼Œå·²é¢„è®­ç»ƒè¯è¡¨ï¼‰\ntokenizer = SimpleTokenizer.load('data/gpt2_tokenizer.pkl')\n\n# åŠ è½½æ•°æ®é›†ï¼šæ–‡æœ¬å—åºåˆ—\ndataset = TextDataset('data/wikitext-103/train.txt', tokenizer, context_length=1024)\n\n# è®­ç»ƒï¼ˆ1 epochï¼Œå°æ‰¹é‡ï¼‰\ntrain_model(model, dataset, batch_size=8, epochs=1, lr=5e-4, device='cuda')\n\n# æ¨ç†ï¼šç”Ÿæˆæ–‡æœ¬\nprompt = \"The meaning of life is\"\ninput_ids = tokenizer.encode(prompt)\ngenerated = model.generate(input_ids, max_new_tokens=50, temperature=0.8)\n\noutput_text = tokenizer.decode(generated.tolist())\nprint(output_text)\n```\n\n**é¢„æœŸè¾“å‡ºï¼ˆç¤ºä¾‹ï¼‰**ï¼š\n> The meaning of life is to live it, to experience it, to embrace the uncertainty and find joy in the journey.\n\n> âœ… **å…³é”®å‚æ•°è¯´æ˜**ï¼š\n> - `temperature=0.8`ï¼šæ§åˆ¶éšæœºæ€§ï¼Œè¶Šä½è¶Šç¡®å®šï¼Œè¶Šé«˜è¶Šå‘æ•£\n> - `max_new_tokens=50`ï¼šç”Ÿæˆé•¿åº¦ä¸Šé™\n> - `context_length=1024`ï¼šæ¨¡å‹ä¸Šä¸‹æ–‡çª—å£ï¼ˆå†…å­˜ç“¶é¢ˆï¼‰\n\n---\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n| æŒ‡æ ‡ | ä¼°ç®—å€¼ |\n|------|--------|\n| **è®­ç»ƒé€Ÿåº¦**ï¼ˆGPT-2 small, 124Mï¼‰ | ~500 tokens/sec on RTX 3090 (batch=8, seq=1024) |\n| **æ˜¾å­˜å ç”¨** | ~6.5GBï¼ˆè®­ç»ƒï¼‰ï¼Œ~1.2GBï¼ˆæ¨ç†ï¼Œå¸¦ KV Cacheï¼‰ |\n| **ç“¶é¢ˆ** | Attention çš„ QK çŸ©é˜µè®¡ç®—ï¼ˆO(seqÂ²)ï¼‰ï¼ŒKV Cache æ˜¯å”¯ä¸€æœ‰æ•ˆä¼˜åŒ– |\n| **ç”Ÿäº§æ‰©å±•æ–¹æ¡ˆ** |  \n> - ä½¿ç”¨ `torch.compile()` ç¼–è¯‘æ¨¡å‹ï¼ˆæå‡ 20â€“40%ï¼‰  \n> - å¼•å…¥ FlashAttentionï¼ˆéœ€ä¿®æ”¹ attention å®ç°ï¼‰  \n> - æ¨¡å‹é‡åŒ–ï¼šFP16 â†’ INT8ï¼Œç”¨ `torch.ao.quantization`  \n> - æ¨ç†æœåŠ¡ï¼šFastAPI + ç«¯åˆ°ç«¯ç¼“å­˜ï¼ˆRedis å­˜å†å²ä¼šè¯ï¼‰ |\n\n> ğŸ’¡ **ç”Ÿäº§å»ºè®®**ï¼šæœ¬é¡¹ç›®æ•™å­¦ä»·å€¼ > å·¥ä¸šéƒ¨ç½²ã€‚å®é™…ç”Ÿäº§åº”ä½¿ç”¨ Hugging Face + vLLMï¼Œä½†**ç†è§£æ­¤å®ç°åï¼Œä½ æ‰èƒ½çœŸæ­£ debug ç”Ÿäº§çº§é—®é¢˜**ã€‚\n\n---\n\n### ğŸ”Œ äºŒæ¬¡å¼€å‘æŒ‡å—\n\n#### å…³é”®æ‰©å±•ç‚¹ï¼š\n\n| æ‰©å±•ç›®æ ‡ | ä¿®æ”¹ä½ç½® |\n|----------|-----------|\n| **æ›¿æ¢ä¸º RoPE** | æ›¿æ¢ `PositionalEncoding` ç±» â†’ å®ç° RotaryEmbedding æ¨¡å— |\n| **æ·»åŠ  LoRA å¾®è°ƒ** | åœ¨ `MultiHeadAttention` ä¸­æ’å…¥ä½ç§©çŸ©é˜µï¼ˆA/Bï¼‰ï¼Œå†»ç»“åŸæƒé‡ |\n| **æ”¯æŒé•¿ä¸Šä¸‹æ–‡ï¼ˆ4K+ï¼‰** | æ”¹ç”¨æ»‘åŠ¨çª—å£æ³¨æ„åŠ›ã€FlashAttention æˆ– ALiBi ä½ç½®ç¼–ç  |\n| **å¤šæ¨¡æ€è¾“å…¥** | æ·»åŠ å›¾åƒåµŒå…¥å±‚ï¼Œæ‹¼æ¥åœ¨ token embedding å‰ |\n| **è‡ªå®šä¹‰é‡‡æ ·å™¨** | å®ç° `sample_top_p()`ã€`beam_search()` æ›¿ä»£ greedy |\n\n#### API æ¥å£è¯´æ˜ï¼ˆæ ¸å¿ƒç±»ï¼‰ï¼š\n\n```python\nmodel = GPTModel(config)  # æ„å»ºæ¨¡å‹\nlogits = model(input_ids) # å‰å‘ï¼šè¾“å…¥ (batch, seq_len) â†’ è¾“å‡º (batch, seq_len, vocab)\n\ntokenizer.encode(text)    # str â†’ list[int]\ntokenizer.decode(ids)     # list[int] â†’ str\n\nmodel.generate(prompt_ids, max_new_tokens=100, temperature=0.7)\n```\n\n> âœ… æ‰€æœ‰æ¨¡å—å‡ç»§æ‰¿ `nn.Module`ï¼Œå¯è¢« TorchScriptã€ONNX å¯¼å‡ºï¼ˆéœ€å¤„ç†åŠ¨æ€ shapeï¼‰ã€‚\n\n---\n\n### â— å¸¸è§é—®é¢˜ä¸é¿å‘\n\n1. **Qï¼šè®­ç»ƒ loss ä¸ä¸‹é™ï¼Ÿ**  \n   Aï¼šæ£€æŸ¥ embedding å±‚æ˜¯å¦å…±äº«æƒé‡ï¼ˆGPT-2 ç”¨å…±äº« embedding/head weightsï¼‰ï¼Œæˆ–å­¦ä¹ ç‡è¿‡é«˜ã€‚å»ºè®®ä» `5e-4` å¼€å§‹è°ƒã€‚\n\n2. **Qï¼šOOM åœ¨ 1024 é•¿åº¦æ—¶å‘ç”Ÿï¼Ÿ**  \n   Aï¼šå¯ç”¨æ¢¯åº¦ç´¯ç§¯ï¼ˆæ¯ 4 æ­¥æ›´æ–°ä¸€æ¬¡ï¼‰ã€ä½¿ç”¨ `torch.cuda.empty_cache()`ã€é™ä½ batch_size è‡³ 1â€“2ã€‚\n\n3. **Qï¼šåŠ è½½ HF æƒé‡æ—¶æŠ¥é”™â€œshape mismatchâ€ï¼Ÿ**  \n   Aï¼šç¡®ä¿æ¨¡å‹",
    "last_scanned": "2026-01-16T02:03:15.389334",
    "last_analyzed": "2026-01-15T05:47:17.718874",
    "screenshot": "static/screenshots/669879380.jpg",
    "ai_visual_summary": "è¯¥æˆªå›¾å±•ç¤ºäº†ä¸€ä¸ªåä¸ºâ€œLLMs-from-scratchâ€çš„GitHubé¡¹ç›®é¡µé¢ï¼Œå…¶UIè®¾è®¡é£æ ¼ç®€æ´ã€ä»¥å†…å®¹ä¸ºä¸­å¿ƒï¼Œé‡‡ç”¨äº†æ¸…æ™°çš„æ ‡é¢˜å±‚çº§å’Œç•™ç™½ï¼Œä¾¿äºé˜…è¯»ã€‚ç•Œé¢ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬â€œREADMEâ€å’Œâ€œLicenseâ€æ ‡ç­¾é¡µã€‚å¯è§çš„æŠ€æœ¯å…³é”®è¯æœ‰â€œPyTorchâ€ã€â€œGPUâ€ã€â€œpretrained modelâ€ã€â€œinference-time scalingâ€ã€â€œreinforcement learningâ€å’Œâ€œdistillationâ€ã€‚ç»¼åˆæ¥çœ‹ï¼Œè¿™ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªæ—¨åœ¨å¸®åŠ©ç”¨æˆ·ä»é›¶å¼€å§‹ï¼Œä½¿ç”¨PyTorché€æ­¥å®ç°ç±»ä¼¼ChatGPTçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ•™ç¨‹èµ„æºï¼Œå®ƒåŒ…å«äº†ä¸€æœ¬é…å¥—ä¹¦ç±å’Œä¸€ä¸ª17å°æ—¶çš„è§†é¢‘è¯¾ç¨‹ï¼Œå…¶ç›®æ ‡æ˜¯è®©å¹¿å¤§å—ä¼—èƒ½åœ¨æ™®é€šç¬”è®°æœ¬ç”µè„‘ä¸Šå­¦ä¹ å’Œå®è·µã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "619959033",
    "name": "gpt4all",
    "full_name": "nomic-ai/gpt4all",
    "category": "llm_rag",
    "stars": 77036,
    "forks": 8312,
    "description": "GPT4All: Run Local LLMs on Any Device. Open-source and available for commercial use.",
    "url": "https://github.com/nomic-ai/gpt4all",
    "homepage": "https://nomic.ai/gpt4all",
    "language": "C++",
    "topics": "[\"ai-chat\", \"llm-inference\"]",
    "created_at": "2023-03-27T18:49:32Z",
    "updated_at": "2026-01-15T17:07:07Z",
    "readme_content": null,
    "ai_summary": "åŸºäº llama.cpp çš„æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹è¿è¡Œæ¡†æ¶ GPT4Allï¼Œæ— éœ€ API è°ƒç”¨å³å¯åœ¨æ¡Œé¢è®¾å¤‡ä¸Šç§æœ‰åŒ–éƒ¨ç½² LLMsã€‚",
    "ai_tech_stack": "[\"C++\", \"llama.cpp\", \"Python Bindings\", \"\\u8de8\\u5e73\\u53f0 (Windows/macOS/Linux)\"]",
    "ai_use_cases": "[\"\\u4f01\\u4e1a\\u5185\\u90e8\\u654f\\u611f\\u6570\\u636e\\u5904\\u7406\", \"\\u79bb\\u7ebf\\u73af\\u5883\\u4e0b\\u7684AI\\u5e94\\u7528\\u5f00\\u53d1\", \"\\u6811\\u8393\\u6d3e\\u7b49\\u8d44\\u6e90\\u53d7\\u9650\\u8bbe\\u5907\\u90e8\\u7f72\"]",
    "ai_difficulty": 3,
    "ai_quick_start": "gpt4all-installer-win64.exe && llama-cpp-python install",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nGPT4All çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äºï¼š**åœ¨æ— éœ€ GPUã€æ— éœ€äº‘ APIã€æ— éœ€å¤æ‚éƒ¨ç½²çš„å‰æä¸‹ï¼Œå®ç°å¤šå¹³å°ï¼ˆWindows/macOS/Linux/ARMï¼‰åŸç”Ÿæœ¬åœ° LLM æ¨ç†çš„â€œå¼€ç®±å³ç”¨â€ä½“éªŒ**ã€‚\n\nåŒç±»é¡¹ç›®å¦‚ llama.cppã€Text Generation WebUIã€Ollama ç­‰è™½ç„¶ä¹Ÿæ”¯æŒæœ¬åœ°è¿è¡Œï¼Œä½†æ™®éå­˜åœ¨ä»¥ä¸‹ç—›ç‚¹ï¼š\n\n- **éƒ¨ç½²é—¨æ§›é«˜**ï¼šéœ€æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹ã€é…ç½®ç¯å¢ƒå˜é‡ã€ç¼–è¯‘ä¾èµ–ï¼ˆå°¤å…¶åœ¨ Windows ä¸Šï¼‰ã€‚\n- **å¹³å°ç¢ç‰‡åŒ–ä¸¥é‡**ï¼šmacOS ARM ä¸ x86_64ã€Windows ARM vs x86ã€Linux å„è‡ªä¸ºæ”¿ï¼Œç¼ºä¹ç»Ÿä¸€å®‰è£…åŒ…ã€‚\n- **ä¼ä¸šåˆè§„é£é™©**ï¼šè®¸å¤šå¼€æº LLM é¡¹ç›®ä½¿ç”¨ AGPL æˆ–éå•†ä¸šè®¸å¯ï¼Œé™åˆ¶å•†ç”¨ã€‚\n- **å¼€å‘è€…ä½“éªŒå‰²è£‚**ï¼šPython SDK ä¸æ¡Œé¢ GUI åˆ†ç¦»ï¼Œæ— æ³•å…±äº«æ¨¡å‹ç¼“å­˜æˆ–é…ç½®ã€‚\n\nGPT4All è§£å†³äº†è¿™äº›é—®é¢˜ï¼š\n\nâœ… **ä¸€é”®å®‰è£…**ï¼šæä¾› `.exe`ã€`.dmg`ã€`.run` åŸç”Ÿå®‰è£…åŒ…ï¼Œæ—  Python ç¯å¢ƒä¹Ÿèƒ½è¿è¡Œã€‚  \nâœ… **å…¨å¹³å°è¦†ç›–**ï¼šæ”¯æŒ Intel/AMD x86_64ã€ARM64ï¼ˆApple Silicon & Snapdragonï¼‰ã€Linux x86_64ï¼ˆæš‚ä¸æ”¯æŒ Linux ARMï¼‰ã€‚  \nâœ… **å•†ä¸šå‹å¥½è®¸å¯**ï¼šåŸºäº Apache 2.0ï¼Œæ¨¡å‹ä¹Ÿå¤šä¸º GGUF æ ¼å¼ + æ˜ç¡®å•†ç”¨æˆæƒï¼ˆå¦‚ Nomic çš„ `nomic-embed-text`ã€`GPT4All-J` ç³»åˆ—ï¼‰ï¼Œé€‚åˆä¼ä¸šç§æœ‰åŒ–éƒ¨ç½²ã€‚  \nâœ… **ç»Ÿä¸€ SDK + GUI + æ¨¡å‹ç”Ÿæ€**ï¼šPython åŒ…ä¸æ¡Œé¢åº”ç”¨å…±äº«åŒä¸€å¥—æ¨¡å‹æ ¼å¼ï¼ˆGGUFï¼‰å’Œåç«¯ï¼ˆllama.cppï¼‰ï¼Œå®ç°â€œä¸‹è½½å³ç”¨ï¼Œä»£ç å³è°ƒâ€ã€‚  \n\nå®ƒä¸æ˜¯ç¬¬ä¸€ä¸ªæœ¬åœ° LLM å·¥å…·ï¼Œä½†å®ƒæ˜¯**ç¬¬ä¸€ä¸ªçœŸæ­£æŠŠâ€œæœ¬åœ°è¿è¡Œå¤§æ¨¡å‹â€å˜æˆæ™®é€šå¼€å‘è€…èƒ½åƒå®‰è£…å¾®ä¿¡ä¸€æ ·å®Œæˆçš„å·¥ç¨‹äº§å“**ã€‚\n\n---\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n1. **GGUF + llama.cpp æ·±åº¦é›†æˆ**  \n   é¡¹ç›®å®Œå…¨åŸºäº [llama.cpp](https://github.com/ggerganov/llama.cpp)ï¼ˆC++æ¨ç†å¼•æ“ï¼‰ï¼Œä½†åšäº†æ·±åº¦å®šåˆ¶ï¼š\n   - è‡ªåŠ¨ä¸‹è½½ã€ç¼“å­˜ã€æ ¡éªŒ GGUF æ¨¡å‹æ–‡ä»¶ï¼ˆæ”¯æŒé‡åŒ–å¦‚ Q4_K_M, Q5_K_Sï¼‰ã€‚\n   - å®ç°æ¨¡å‹å…ƒæ•°æ®è§£æï¼ˆè‡ªåŠ¨è¯†åˆ«æ¶æ„ï¼šLlama3ã€Mistralã€Gemma ç­‰ï¼‰ï¼Œæ— éœ€ç”¨æˆ·æ‰‹åŠ¨é…ç½® `n_ctx`ã€`n_gpu_layers`ã€‚\n\n2. **è·¨å¹³å°å†…å­˜æ˜ å°„ä¸é›¶æ‹·è´æ¨ç†**  \n   åœ¨ macOS ä¸Šåˆ©ç”¨ `mmap()` + `MAP_JIT` å®ç°æ¨¡å‹åŠ è½½æ— å¤åˆ¶ï¼›åœ¨ Windows ä½¿ç”¨ `CreateFileMapping`ï¼ŒLinux ç”¨ `madvise(MADV_WILLNEED)`ã€‚  \n   â†’ æ˜¾è‘—é™ä½å¤§æ¨¡å‹ï¼ˆ>4GBï¼‰çš„å¯åŠ¨å†…å­˜å³°å€¼ã€‚\n\n3. **åŠ¨æ€é‡åŒ–åŠ è½½å™¨**  \n   åŒä¸€æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚ `Meta-Llama-3-8B-Instruct.Q4_0.gguf`ï¼‰ï¼Œåœ¨ä½å†…å­˜è®¾å¤‡ä¸Šè‡ªåŠ¨é™çº§ä¸º `n_batch=16`ï¼Œé«˜å†…å­˜è®¾å¤‡å¯ç”¨ `n_threads=8` + `n_gpu_layers=35`ï¼ˆè‹¥æ”¯æŒ Metal/CLï¼‰ã€‚  \n   â†’ æ— éœ€ç”¨æˆ·è°ƒå‚å³å¯â€œè‡ªé€‚åº”â€æ€§èƒ½ã€‚\n\n4. **æ¨¡å‹ç´¢å¼•ä¸å…ƒæ•°æ®æœåŠ¡**  \n   å†…ç½®è½»é‡çº§ SQLite æ•°æ®åº“å­˜å‚¨æ‰€æœ‰å·²ä¸‹è½½æ¨¡å‹çš„ï¼šSHA256ã€å°ºå¯¸ã€æ¶æ„ã€ä¸Šä¸‹æ–‡é•¿åº¦ã€ä½œè€…ã€‚é¿å…é‡å¤ä¸‹è½½ï¼Œæ”¯æŒå¤šç‰ˆæœ¬å…±å­˜ã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n#### 1. æ•´ä½“æ¶æ„ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\n+---------------------+\n|   GPT4All Desktop   | â† GUI (Qt5/6) â†’ äº‹ä»¶é©±åŠ¨ UI\n+----------+----------+\n           |\n           v\n+---------------------+\n|    gpt4all-python   | â† Python SDK (Cython wrapper)\n+----------+----------+\n           |\n           v\n+---------------------+\n|    llama.cpp C++    | â† æ ¸å¿ƒæ¨ç†å¼•æ“ï¼ˆfork + patchï¼‰\n|  (libgpt4all.so/dll)|\n+----------+----------+\n           |\n           v\n+---------------------+\n|   OS Abstraction    | â† mmap, threads, AVX2/FMA, Metal/CL\n|   (platform layer)  |\n+---------------------+\n```\n\n#### 2. æ ¸å¿ƒæ¨¡å—åˆ’åˆ†\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| `llama.cpp` (forked) | å®é™…æ‰§è¡Œ token æ¨ç†ã€KV cache ç®¡ç†ã€é‡åŒ–è§£ç ã€‚Nomic ç»´æŠ¤äº†ä¸“å± patch é›†ï¼Œæ”¯æŒ `n_gpu_layers=-1` è‡ªåŠ¨åˆ†é…ï¼ˆMetal/CLï¼‰ã€‚ |\n| `gpt4all-bindings` | Cython åŒ…è£… C++ API â†’ Python æ¨¡å—ï¼Œæš´éœ² `GPT4All()` ç±»ã€‚é¿å… PyBind11 çš„ ABI ç¹çæ€§ã€‚ |\n| `model-manager` | ç®¡ç†æ¨¡å‹ä¸‹è½½ã€æ ¡éªŒã€ç´¢å¼•ï¼ˆSQLiteï¼‰ã€ç‰ˆæœ¬æ§åˆ¶ã€‚æ”¯æŒ HTTP/HTTPS ä» Nomic å®˜æ–¹ä»“åº“æ‹‰å– GGUFã€‚ |\n| `chat-ui` (Qt) | åŸºäº QML çš„å“åº”å¼ç•Œé¢ï¼Œé›†æˆ Markdown æ¸²æŸ“ã€ä»£ç é«˜äº®ã€æµå¼è¾“å‡ºã€‚ä¸ Python SDK å…±äº«æ¨¡å‹å®ä¾‹ï¼ˆé€šè¿‡ Qtä¿¡å·æ§½é€šä¿¡ï¼‰ã€‚ |\n| `system-checker` | å¯åŠ¨æ—¶æ£€æµ‹ CPU æŒ‡ä»¤é›†ï¼ˆAVX2, AVX512ï¼‰ã€å†…å­˜ã€OS ç‰ˆæœ¬ï¼Œæ‹’ç»ä¸å…¼å®¹è®¾å¤‡ã€‚ |\n\n#### 3. æ•°æ®æµå‘\n\n```\nç”¨æˆ·è¾“å…¥ â†’ [Qt UI] â†’ (Python) GPT4All.generate() â†’ llama.cpp æ¨ç†å¼•æ“\n                        â†“\n                æ¨¡å‹åŠ è½½ï¼ˆmmap GGUFï¼‰â†’ KV Cache åˆ†é…\n                        â†“\n             Token ç¼–ç  â†’ Transformer å±‚æ¨ç† â†’ é‡‡æ ·è¾“å‡º\n                        â†“\n              æµå¼è¿”å› token â†’ UI æ¸²æŸ“ â†’ ç”¨æˆ·çœ‹åˆ°æ¸è¿›æ–‡æœ¬\n```\n\n#### 4. å…³é”®è®¾è®¡æ¨¡å¼\n\n- **Facade æ¨¡å¼**ï¼š`GPT4All()` ç±»éšè—äº† llama.cpp çš„å¤æ‚å‚æ•°ï¼ˆå¦‚ `n_threads`, `n_batch`, `use_mmap`ï¼‰ï¼Œæä¾›ç®€æ´ APIã€‚\n- **Singleton + Factory æ¨¡å¼**ï¼šæ¨¡å‹å®ä¾‹æŒ‰è·¯å¾„ç¼“å­˜ä¸ºå•ä¾‹ï¼Œé¿å…é‡å¤åŠ è½½ï¼›é€šè¿‡å·¥å‚æ ¹æ®æ–‡ä»¶ååç¼€è‡ªåŠ¨é€‰æ‹©é€‚é…å™¨ï¼ˆLlama3 vs Mistralï¼‰ã€‚\n- **Observer æ¨¡å¼**ï¼šUI è®¢é˜…æ¨ç†äº‹ä»¶æµï¼ˆ`on_new_token`, `on_complete`ï¼‰ï¼Œå®ç°æ— é˜»å¡æµå¼è¾“å‡ºã€‚\n\nâ†’ è®¾è®¡å“²å­¦ï¼š**å¯¹ç”¨æˆ·éšè—å¤æ‚æ€§ï¼Œå¯¹å¼€å‘è€…æš´éœ²å¯æ§æ‰©å±•ç‚¹ã€‚**\n\n---\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| æŠ€æœ¯ | é€‰æ‹©ç†ç”± | æ›¿ä»£æ–¹æ¡ˆ | æ³¨æ„äº‹é¡¹ |\n|------|----------|-----------|----------|\n| **llama.cpp** | æœ€è½»é‡ã€æœ€é«˜æ•ˆã€æ”¯æŒ GGUFã€å¯è·¨å¹³å°ç¼–è¯‘ï¼Œç¤¾åŒºæ´»è·ƒã€‚Nomic æ˜¯å…¶é‡è¦è´¡çŒ®è€…ï¼ˆæäº¤äº† Apple Silicon Metal æ”¯æŒã€é‡åŒ–ä¼˜åŒ–ï¼‰ã€‚ | vLLM / TensorRT-LLM | åä¸¤è€…ä¾èµ– GPUï¼Œä¸æ»¡è¶³â€œæ— GPUâ€æ ¸å¿ƒè¯‰æ±‚ã€‚ |\n| **Cython** | æ¯” PyBind11 æ›´æ˜“æ‰“åŒ…é™æ€åº“ï¼ˆé¿å… DLL Hellï¼‰ï¼Œæ€§èƒ½æ¥è¿‘åŸç”Ÿ C++ï¼Œä¸”æ”¯æŒ Python 3.8+ å…¨å¹³å°ã€‚ | PyBind11 / SWIG | Cython ç¼–è¯‘ä¾èµ– C++17ï¼Œéœ€ç¡®ä¿ç¼–è¯‘ç¯å¢ƒä¸€è‡´ï¼ˆå¦‚ Windows éœ€ VS2022ï¼‰ã€‚ |\n| **Qt5/6** | è·¨å¹³å° GUI æ¡†æ¶ï¼Œæ”¯æŒ macOSã€Windowsã€Linux åŸç”Ÿå¤–è§‚ã€‚QML é€‚åˆæ„å»ºç°ä»£ UIã€‚ | Electron / Tkinter | Electron å¤ªé‡ï¼ˆ>150MBï¼‰ï¼ŒTkinter ç®€é™‹ã€‚Qt æ˜¯å”¯ä¸€å¹³è¡¡ç¾è§‚ä¸ä½“ç§¯çš„æ–¹æ¡ˆã€‚ |\n| **SQLite** | è½»é‡ã€æ— æœåŠ¡ã€ACIDï¼Œå®Œç¾é€‚é…æ¨¡å‹å…ƒæ•°æ®å­˜å‚¨ã€‚ | Redis / LevelDB | è¿‡åº¦è®¾è®¡ï¼šä¸éœ€è¦ç½‘ç»œæˆ–æŒä¹…åŒ–äº‹åŠ¡ï¼ŒSQLite å³å¯ã€‚ |\n| **GGUF** | llama.cpp çš„ç°ä»£æ ¼å¼ï¼Œæ”¯æŒå¤šå¤´ã€é‡åŒ–ã€å…ƒæ•°æ®åµŒå…¥ï¼Œå–ä»£æ—§çš„ GGMLã€‚ | AWQ / GPTQ | ä»…é€‚ç”¨äºæ¨ç†ï¼Œä¸æ”¯æŒè®­ç»ƒï¼›ä½† GPT4All æ˜¯çº¯æ¨ç†å·¥å…·ï¼Œå®Œç¾åŒ¹é…ã€‚ |\n\n> âš ï¸ ç‰ˆæœ¬å…¼å®¹æ€§æ³¨æ„ï¼š  \n> - Python åŒ… `gpt4all` >= v2.5 ä»…æ”¯æŒ Python 3.8+ï¼ˆå› ä½¿ç”¨ `asyncio` + `aiohttp` ä¸‹è½½æ¨¡å‹ï¼‰  \n> - Windows å®‰è£…åŒ…éœ€ .NET Framework 4.7.2+ï¼ˆç”¨äºå®‰è£…ç¨‹åºé€»è¾‘ï¼‰  \n> - macOS éœ€ Xcode Command Line Tools æ‰èƒ½è¿è¡ŒæŸäº›è‡ªå®šä¹‰æ¨¡å‹ï¼ˆå¦‚ `Phi-3-mini`ï¼‰\n\n---\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. å®‰è£… Python åŒ…ï¼ˆæ¨èæ–¹å¼ï¼‰\npip install gpt4all --upgrade\n\n# 2. ä¸‹è½½å¹¶åŠ è½½é¦–ä¸ªæ¨¡å‹ï¼ˆé¦–æ¬¡ä¼šè‡ªåŠ¨ä¸‹è½½ ~4.6GBï¼‰\npython -c \"\nfrom gpt4all import GPT4All\nmodel = GPT4All('Meta-Llama-3-8B-Instruct.Q4_0.gguf')\nprint('âœ… æ¨¡å‹å·²ç¼“å­˜è‡³:', model.model_path)\n\"\n\n# 3. éªŒè¯æ¨¡å‹åˆ—è¡¨ï¼ˆè‡ªåŠ¨ä» Nomic ä»“åº“è·å–ï¼‰\npython -c \"\nfrom gpt4all import GPT4All\nprint('\\n'.join([m['filename'] for m in GPT4All.list_models()]))\n\"\n```\n\n> ğŸ’¡ **é¦–æ¬¡è¿è¡Œ**ï¼š  \n> æ¨¡å‹ä¼šä¸‹è½½åˆ° `~/.local/share/nomic.ai/GPT4All/`ï¼ˆLinux/macOSï¼‰æˆ– `%APPDATA%\\Nomic\\GPT4All\\`ï¼ˆWindowsï¼‰ã€‚  \n> æ— éœ€ç®¡ç†å‘˜æƒé™ï¼Œæ‰€æœ‰æ–‡ä»¶å†™å…¥ç”¨æˆ·ç›®å½•ã€‚\n\n---\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n```python\nfrom gpt4all import GPT4All\n\n# åŠ è½½æ¨¡å‹ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼Œä»…é¦–æ¬¡ï¼‰\nmodel = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n\nwith model.chat_session():\n    # çœŸå®åœºæ™¯ï¼šç”¨æˆ·è¯¢é—®å¦‚ä½•ä¼˜åŒ–æœ¬åœ°æ¨ç†\n    response = model.generate(\n        prompt=\"How can I reduce the RAM usage of a 7B LLM on my 16GB laptop without sacrificing too much quality?\",\n        max_tokens=512,\n        temp=0.7,      # æ¸©åº¦æ§åˆ¶åˆ›é€ æ€§\n        top_p=0.95,    # æ ¸é‡‡æ ·é˜ˆå€¼\n        repeat_penalty=1.1,  # é˜²æ­¢é‡å¤\n        streaming=True # æµå¼è¾“å‡ºï¼Œé€è¯è¿”å›\n    )\n\n    print(\"\\n=== RESPONSE ===\")\n    for token in response:\n        print(token, end=\"\", flush=True)\n\n# è¾“å‡ºç¤ºä¾‹ï¼š\n\"\"\"\nYou can reduce RAM usage by:\n1. Using a quantized model (e.g., Q4_K_M or Q3_K_S GGUF format)\n2. Lowering n_ctx to 2048 if you don't need long context\n3. Reducing n_batch from default 512 to 128â€“256\n4. Avoid loading multiple models simultaneously\n5. Use the 'n_gpu_layers' parameter if your device has GPU (Metal/CL) â€” even 20 layers offloaded can save >3GB RAM\n\nFor a 7B model on 16GB RAM, Q4_K_M with n_ctx=2048 and n_batch=256 is ideal.\n\"\"\"\n```\n\n---\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n| è®¾å¤‡ | æ¨¡å‹ | æ¨ç†é€Ÿåº¦ | å†…å­˜å ç”¨ | åŠŸè€— |\n|------|------|----------|-----------|------|\n| MacBook Pro M3 | Llama-3-8B-Q4_K_M | 12â€“15 tok/s | ~6.2GB | 8â€“12W |\n| Dell XPS 15 (i7-12700H) | Mistral-7B-Q4_K_S | 8â€“10 tok/s | ~5.8GB | 25â€“35W |\n| Surface Pro 9 (SQ3) | Phi-3-mini-Q4 | 6â€“8 tok/s | ~3.1GB | 6â€“10W |\n\n#### æ€§èƒ½ç“¶é¢ˆ\n- **CPU ç¼“å­˜å‹åŠ›**ï¼šKV Cache å ç”¨å¤§ï¼ŒL2/L3 ç¼“å­˜å‘½ä¸­ç‡ä¸‹é™æ—¶å»¶è¿Ÿé£™å‡ã€‚\n- **å•çº¿ç¨‹æ¨ç†é™åˆ¶**ï¼šllama.cpp é»˜è®¤ä½¿ç”¨æ‰€æœ‰é€»è¾‘æ ¸ï¼Œä½†éƒ¨åˆ†æ¨¡å‹ï¼ˆå¦‚ Gemmaï¼‰æœªä¼˜åŒ–å¤šçº¿ç¨‹è°ƒåº¦ â†’ ä»… 1â€“2 æ ¸æ»¡è½½ã€‚\n\n#### ç”Ÿäº§ç¯å¢ƒæ‰©å±•å»ºè®®\n- âœ… **é¢„åŠ è½½æ¨¡å‹æ± **ï¼šç”¨ `GPT4All(..., n_threads=4)` + å¯åŠ¨å¤šä¸ªå®ä¾‹ï¼Œé€šè¿‡è´Ÿè½½å‡è¡¡åˆ†å‘è¯·æ±‚ã€‚\n- âœ… **ç¼“å­˜å±‚**ï¼šåœ¨åº”ç”¨å±‚ç”¨ Redis ç¼“å­˜å¸¸è§ prompt â†’ responseï¼ˆé€‚åˆå®¢æœæœºå™¨äººï¼‰ã€‚\n- âŒ ä¸å»ºè®®ï¼šç”¨ Docker éƒ¨ç½² â€”â€” æ¨¡å‹æ–‡ä»¶ä½“ç§¯å¤§ã€GPU æ— æ³•ç›´é€šã€å¯åŠ¨æ…¢ã€‚\n\n#### èµ„æºä¼°ç®—\n| æ¨¡å‹å¤§å° | å†…å­˜å ç”¨ | æœ€ä½æ¨è RAM |\n|----------|-----------|----------------|\n| 3B Q4    | ~2.5GB   | 8GB            |\n| 7B Q4    | ~5.0GB   | 16GB          ",
    "last_scanned": "2026-01-16T02:03:15.390334",
    "last_analyzed": "2026-01-15T07:18:26.446433",
    "screenshot": "static/screenshots/619959033.jpg",
    "ai_visual_summary": "è¯¥ç•Œé¢æ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®çš„ README æ–‡æ¡£ï¼Œæ ¸å¿ƒåŠŸèƒ½æ˜¯æŒ‡å¯¼ç”¨æˆ·å¦‚ä½•åœ¨æœ¬åœ°è®¾å¤‡ä¸Šå®‰è£…å’Œè¿è¡Œ GPT4All é¡¹ç›®ã€‚æŠ€æœ¯å…³é”®è¯åŒ…æ‹¬ `LLMs`ï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰ã€`gpt4all`ã€`Flathub`ã€`Python`ã€`llama.cpp` å’Œ `Ubuntu Installer`ã€‚ä»ç•Œé¢å¸ƒå±€å’Œå†…å®¹æ¥çœ‹ï¼Œè¿™æ˜¯ä¸€ä¸ªé¢å‘å¼€å‘è€…çš„æŠ€æœ¯é¡¹ç›®ï¼Œæ—¨åœ¨æä¾›ä¸€ç§åœ¨ä¸ªäººç”µè„‘ä¸Šè¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹çš„æœ¬åœ°åŒ–ã€å¼€æºè§£å†³æ–¹æ¡ˆã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "787076358",
    "name": "firecrawl",
    "full_name": "firecrawl/firecrawl",
    "category": "llm_rag",
    "stars": 75084,
    "forks": 5745,
    "description": "ğŸ”¥ The Web Data API for AI - Turn entire websites into LLM-ready markdown or structured data",
    "url": "https://github.com/firecrawl/firecrawl",
    "homepage": "https://firecrawl.dev",
    "language": "TypeScript",
    "topics": "[\"ai\", \"ai-agents\", \"ai-crawler\", \"ai-scraping\", \"ai-search\", \"crawler\", \"data-extraction\", \"html-to-markdown\", \"llm\", \"markdown\", \"scraper\", \"scraping\", \"web-crawler\", \"web-data\", \"web-data-extraction\", \"web-scraper\", \"web-scraping\", \"web-search\", \"webscraping\"]",
    "created_at": "2024-04-15T21:02:29Z",
    "updated_at": "2026-01-15T17:33:53Z",
    "readme_content": null,
    "ai_summary": "æä¾›ç½‘é¡µæ•°æ®çˆ¬å–ä¸è½¬æ¢ä¸ºLLMå¯ç”¨æ ¼å¼ï¼ˆMarkdownæˆ–ç»“æ„åŒ–æ•°æ®ï¼‰çš„æœåŠ¡å¹³å°",
    "ai_tech_stack": "[\"TypeScript\", \"FastAPI\", \"LangChain\", \"Python SDK\", \"Node.js SDK\"]",
    "ai_use_cases": "[\"AI\\u5e94\\u7528\\u7684\\u6570\\u636e\\u6e90\\u4f9b\\u7ed9\\uff1a\\u5c06\\u4efb\\u610f\\u7f51\\u7ad9\\u5185\\u5bb9\\u8f6c\\u5316\\u4e3a\\u9002\\u5408\\u5927\\u578b\\u8bed\\u8a00\\u6a21\\u578b\\u5904\\u7406\\u7684\\u683c\\u5f0f\", \"\\u77e5\\u8bc6\\u5e93\\u6784\\u5efa\\u5de5\\u5177\\uff1a\\u81ea\\u52a8\\u722c\\u53d6\\u7f51\\u9875\\u5e76\\u7ed3\\u6784\\u5316\\u6570\\u636e\\uff0c\\u7528\\u4e8eRAG\\u7cfb\\u7edf\\u7684\\u77e5\\u8bc6\\u50a8\\u5907\\u5efa\\u8bbe\", \"Web\\u81ea\\u52a8\\u5316\\u4fe1\\u606f\\u63d0\\u53d6\\uff1a\\u65e0\\u9700\\u7f16\\u5199\\u590d\\u6742\\u722c\\u866b\\u7a0b\\u5e8f\\u5373\\u53ef\\u83b7\\u53d6\\u5e72\\u51c0\\u53ef\\u7528\\u7684\\u7f51\\u9875\\u6570\\u636e\"]",
    "ai_difficulty": 2,
    "ai_quick_start": "curl -X 'POST' https://api.firecrawl.dev/api/v1/parse -H 'Content-Type: application/json' --data '{\"url\": \"https://example.com\", \"serp_api_key\": \"your-api-key-here\"}'",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nFirecrawl çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äºï¼š**å®ƒä¸æ˜¯å¦ä¸€ä¸ªçˆ¬è™«å·¥å…·ï¼Œè€Œæ˜¯ä¸º LLM åŸç”Ÿè®¾è®¡çš„â€œè¯­ä¹‰æ„ŸçŸ¥å‹ç½‘é¡µæ•°æ®ç®¡é“â€**ã€‚\n\nå¸‚é¢ä¸Šå·²æœ‰ Scrapyã€Playwrightã€Cheerioã€Puppeteer ç­‰å·¥å…·ï¼Œç”šè‡³åƒ Apifyã€ScrapingBee è¿™æ ·çš„ SaaS æœåŠ¡ï¼Œä½†å®ƒä»¬éƒ½åœç•™åœ¨â€œè·å– HTML â†’ æ¸…æ´—æ–‡æœ¬â€çš„å±‚é¢ã€‚Firecrawl çš„çªç ´åœ¨äºï¼š\n\n1. **è¯­ä¹‰ç»“æ„åŒ–è¾“å‡ºä¼˜å…ˆ**ï¼šä¸æ˜¯è¿”å›ä¸€å † `<div>` æˆ–çº¯æ–‡æœ¬ï¼Œè€Œæ˜¯è‡ªåŠ¨è¯†åˆ«æ–‡ç« ä¸»ä½“ã€å¯¼èˆªæ ã€é¡µè„šã€è¡¨æ ¼ã€åˆ—è¡¨ï¼Œå¹¶å°†å†…å®¹è½¬åŒ–ä¸ºç¬¦åˆ LLM è¾“å…¥ä¹ æƒ¯çš„ Markdownï¼ˆå¸¦å±‚çº§æ ‡é¢˜ã€ä»£ç å—ã€åˆ—è¡¨ï¼‰æˆ– JSON Schemaï¼ˆå¦‚ `{title, content, metadata}`ï¼‰ã€‚è¿™ç›´æ¥è§£å†³äº† RAG ç³»ç»Ÿä¸­â€œè„æ•°æ®è¾“å…¥ â†’ ä½å¬å›ç‡â€çš„æ ¹æœ¬ç—›ç‚¹ã€‚\n\n2. **æ—  Sitemap çš„æ™ºèƒ½æ·±åº¦çˆ¬å–**ï¼šå¤§å¤šæ•°çˆ¬è™«ä¾èµ– sitemap.xml æˆ–é¢„è®¾é“¾æ¥æ± ï¼ŒFirecrawl ä½¿ç”¨åŠ¨æ€é“¾æ¥å‘ç° + é“¾æ¥é‡è¦æ€§è¯„ä¼°ï¼ˆåŸºäº DOM ç»“æ„ã€æ–‡æœ¬å¯†åº¦ã€é”šæ–‡æœ¬è¯­ä¹‰ï¼‰è‡ªåŠ¨æ¢ç´¢å­é¡µé¢ï¼Œæ— éœ€äººå·¥é…ç½®ã€‚è¿™åœ¨ä¼ä¸šå®˜ç½‘ã€æ–‡æ¡£ç«™ã€çŸ¥è¯†åº“ç­‰ç»“æ„æ¾æ•£çš„ç½‘ç«™ä¸Šè¡¨ç°æä½³ã€‚\n\n3. **LLM åŸç”Ÿé›†æˆç”Ÿæ€**ï¼šå®ƒä¸æ˜¯â€œèƒ½ç”¨â€ï¼Œè€Œæ˜¯â€œè¢«å†…ç½®â€ã€‚LangChainã€LlamaIndexã€CrewAIã€Dify ç­‰ä¸»æµæ¡†æ¶éƒ½å®˜æ–¹æ”¯æŒå…¶ä½œä¸º `DocumentLoader`ï¼Œè¿™æ„å‘³ç€å¼€å‘è€…æ— éœ€å†™ä»»ä½•é€‚é…å±‚å³å¯æ¥å…¥ã€‚è¿™ç§â€œå¼€ç®±å³ç”¨çš„è¯­ä¹‰æ•°æ®æµâ€æ˜¯ç«å“ï¼ˆå¦‚ BeautifulSoup + è‡ªå®šä¹‰è§£æå™¨ï¼‰æ— æ³•æ¯”æ‹Ÿçš„ã€‚\n\n4. **å»å™ªèƒ½åŠ› > çˆ¬å–é€Ÿåº¦**ï¼šå®ƒä¸è¿½æ±‚â€œå…¨ç«™æŠ“å®Œâ€ï¼Œè€Œæ˜¯æ™ºèƒ½è¿‡æ»¤å¹¿å‘Šã€å¼¹çª—ã€é‡å¤å¯¼èˆªã€è„šæœ¬æ³¨å…¥å†…å®¹ï¼Œè¾“å‡ºå¹²å‡€çš„â€œäººç±»é˜…è¯»è§†è§’â€å†…å®¹ã€‚è¿™æ˜¯å¯¹â€œLLM æƒ…å¢ƒçª—å£æœ‰é™â€è¿™ä¸€ç¡¬çº¦æŸçš„ç²¾å‡†å“åº”ã€‚\n\n> **ä¸€å¥è¯æ€»ç»“**ï¼šFirecrawl æ˜¯ç¬¬ä¸€ä¸ªæŠŠâ€œç½‘é¡µçˆ¬å–â€ä»â€œå·¥ç¨‹ä»»åŠ¡â€é‡æ–°å®šä¹‰ä¸ºâ€œAI æ•°æ®å‡†å¤‡â€çš„å·¥å…·â€”â€”å®ƒä¸ç»™ä½  HTMLï¼Œå®ƒç»™ä½  LLM èƒ½ç†è§£çš„â€œçŸ¥è¯†å•å…ƒâ€ã€‚\n\n---\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n1. **åŸºäº DOM è¯­ä¹‰çš„æ™ºèƒ½å†…å®¹æå–ï¼ˆContent Semantics Engineï¼‰**  \n   ä¸æ˜¯ç”¨æ­£åˆ™æˆ– CSS é€‰æ‹©å™¨ï¼Œè€Œæ˜¯é€šè¿‡è®­ç»ƒè½»é‡çº§æ¨¡å‹ï¼ˆå¯èƒ½æ˜¯ ONNX æ¨¡å‹åµŒå…¥ï¼‰è¯†åˆ«ï¼š\n   - ä¸»ä½“å†…å®¹åŒºåŸŸï¼ˆæ–‡ç« ã€äº§å“æè¿°ï¼‰\n   - éå†…å®¹åŒºå—ï¼ˆè¯„è®ºåŒºã€å¹¿å‘Šã€é¡µè„šå¯¼èˆªï¼‰\n   - ç»“æ„åŒ–å…ƒç´ ï¼ˆè¡¨æ ¼ â†’ è½¬ä¸º Markdown è¡¨æ ¼ï¼›åˆ—è¡¨ â†’ ä¿ç•™å±‚çº§ï¼‰\n\n   è¿™ç§æ–¹å¼æ¯” Readability.js æ›´é²æ£’ï¼Œå°¤å…¶å¯¹ React/Vue åŠ¨æ€æ¸²æŸ“çš„ç°ä»£ç½‘ç«™ã€‚\n\n2. **å¼‚æ­¥å¹¶å‘çˆ¬å– + æ™ºèƒ½é€Ÿç‡æ§åˆ¶**  \n   ä½¿ç”¨ `p-limit` + åŸºäºå“åº”æ—¶é—´çš„åŠ¨æ€é™æµï¼ˆéå›ºå®š delayï¼‰ï¼Œé¿å…è¢«åçˆ¬æœºåˆ¶å°ç¦ã€‚å¯¹é«˜å»¶è¿Ÿç«™ç‚¹è‡ªåŠ¨é™é¢‘ï¼Œå¯¹ CDN ç«™ç‚¹å¹¶è¡Œåº¦æ‹‰æ»¡ã€‚\n\n3. **Markdown æ¸²æŸ“å¼•æ“ï¼šè¯­ä¹‰ä¿ç•™è€Œéç®€å•æ–‡æœ¬æ‹¼æ¥**  \n   å°† HTML è½¬ Markdown æ—¶ï¼š\n   - `<h1>` â†’ `#`\n   - `<table>` â†’ å¯¹é½çš„ Markdown è¡¨æ ¼ï¼ˆæ”¯æŒå¤šè¡Œï¼‰\n   - `<code class=\"language-js\">` â†’ ```js\n   - æ®µè½é—´ä¿ç•™è¯­ä¹‰ç©ºè¡Œï¼Œä¸åˆå¹¶æ— å…³æ–‡æœ¬\n\n   è¿™æ˜¯å…³é”®ï¼š**LLM ä¾èµ–ç»“æ„æ¢è¡Œå’Œåˆ†æ®µç†è§£ä¸Šä¸‹æ–‡**ã€‚ä¼ ç»Ÿçˆ¬è™«è¾“å‡ºâ€œä¸€å¨æ–‡å­—â€ï¼ŒFirecrawl è¾“å‡ºçš„æ˜¯â€œå¯è¯»çš„ç« èŠ‚â€ã€‚\n\n4. **ç¼“å­˜ + å¢é‡æ›´æ–°æœºåˆ¶ï¼ˆæ¨æµ‹ï¼‰**  \n   å¯¹ç›¸åŒ URL çš„é‡å¤è¯·æ±‚ï¼Œè‹¥å†…å®¹æœªå˜æ›´ï¼ˆETag/Last-Modified æ ¡éªŒï¼‰ï¼Œç›´æ¥è¿”å›ç¼“å­˜ã€‚è¿™å¯¹é«˜é¢‘è°ƒç”¨çš„ RAG åº”ç”¨æå¤§é™ä½å»¶è¿Ÿä¸æˆæœ¬ã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n#### 1. æ•´ä½“æ¶æ„å›¾ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\n[Client Request] \n       â†“\n[API Gateway (Express.js)] â†’ Auth, Rate Limiting, Queue\n       â†“\n[Crawling Orchestrator] â€”â€”â†’ [Link Discovery Engine] â†’ BFS/DFS with priority scoring\n       â†“\n[Page Fetcher Cluster] â†â”€â”\n    (Puppeteer + Playwright) â”‚\n       â†“                    â”‚\n[Content Extractor Module] â†â”˜  // ONNX model + rule-based heuristics\n       â†“\n[Markdown / JSON Serializer] â†’ Schema validation (Zod)\n       â†“\n[Cache Layer (Redis)] â†’ TTL + ETag\n       â†“\n[Response: Markdown or JSON]\n```\n\n#### 2. æ ¸å¿ƒæ¨¡å—èŒè´£\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| **API Gateway** | æ¥æ”¶ HTTP è¯·æ±‚ï¼ŒJWT éªŒè¯ï¼Œé…é¢æ£€æŸ¥ï¼Œè¯·æ±‚å…¥é˜Ÿï¼ˆRedis Queueï¼‰ |\n| **Crawling Orchestrator** | ç®¡ç†çˆ¬å–ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸï¼šèµ·å§‹ URL â†’ å­é“¾æ¥å‘ç° â†’ å¹¶å‘æ§åˆ¶ â†’ è¶…æ—¶ç†”æ–­ |\n| **Link Discovery Engine** | åˆ†æ DOM ä¸­çš„ `<a>` æ ‡ç­¾ï¼ŒåŸºäºè¯­ä¹‰ï¼ˆå¦‚ href åŒ…å« `/docs/`ï¼‰å’Œæ–‡æœ¬å¯†åº¦åˆ¤æ–­æ˜¯å¦åº”çˆ¬å– |\n| **Page Fetcher Cluster** | ä½¿ç”¨ Puppeteer/Playwright æ¸²æŸ“ JS é¡µé¢ï¼Œæ‹¦æˆªç½‘ç»œè¯·æ±‚ï¼Œæ³¨å…¥æ¸…ç†è„šæœ¬ï¼Œæ•è·æœ€ç»ˆ DOM |\n| **Content Extractor Module** | æ ¸å¿ƒç®—æ³•æ¨¡å—ï¼šç”¨è½»é‡æ¨¡å‹ + è§„åˆ™åˆ¤å®šä¸»ä½“å†…å®¹ã€ç»“æ„åŒ–å…ƒç´ ã€å»å™ªï¼ˆå¹¿å‘Š/å¼¹çª—ï¼‰ |\n| **Serializer** | å°†æå–çš„ DOM èŠ‚ç‚¹æ ‘è½¬ä¸ºæ ‡å‡† Markdown æˆ– JSON Schemaï¼ˆç¬¦åˆ LLM é¢„æœŸæ ¼å¼ï¼‰ |\n| **Cache Layer** | Redis ç¼“å­˜å“åº”ï¼Œæ”¯æŒ ETag å’Œ TTLï¼Œå‡å°‘é‡å¤æŠ“å– |\n\n#### 3. æ•°æ®æµå‘\n\n```\nè¾“å…¥ï¼šURL (string) + å‚æ•° { pageOptions: { onlyMainContent: true, format: 'markdown' } }\nâ†“\nå¼‚æ­¥å…¥é˜Ÿ â†’ ç­‰å¾… worker\nâ†“\nPuppeteer å¯åŠ¨æµè§ˆå™¨å®ä¾‹ â†’ åŠ è½½é¡µé¢ â†’ æ‰§è¡Œ JS æ¸²æŸ“\nâ†“\næ³¨å…¥å†…å®¹æå–è„šæœ¬ï¼ˆåœ¨æµè§ˆå™¨ä¸Šä¸‹æ–‡ä¸­è¿è¡Œï¼‰â†’ æå– DOM ç»“æ„ + æ–‡æœ¬æ ‘\nâ†“\næœåŠ¡ç«¯æ¥æ”¶ DOM æ ‘ â†’ ç”¨ ONNX æ¨¡å‹åˆ¤æ–­è¯­ä¹‰åŒºå— â†’ è¿‡æ»¤å™ªéŸ³\nâ†“\nç»“æ„åŒ–ï¼šæ ‡é¢˜å±‚çº§ã€åˆ—è¡¨ã€è¡¨æ ¼ â†’ è½¬ä¸º Markdown / JSON\nâ†“\néªŒè¯ Schemaï¼ˆZodï¼‰â†’ ç¼“å­˜è‡³ Redis (key: url_hash)\nâ†“\nè¿”å› { content: \"...\", metadata: { url, title, crawledAt } }\n```\n\n#### 4. å…³é”®è®¾è®¡æ¨¡å¼\n\n| æ¨¡å¼ | åº”ç”¨åœºæ™¯ | åŸå›  |\n|------|----------|------|\n| **ç­–ç•¥æ¨¡å¼** | å†…å®¹æå–å™¨æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ï¼ˆmarkdown/jsonï¼‰ | è§£è€¦æ ¼å¼ç”Ÿæˆé€»è¾‘ï¼Œä¾¿äºæ‰©å±•æ–°æ ¼å¼ï¼ˆå¦‚ HTMLã€CSVï¼‰ |\n| **å·¥å‚æ¨¡å¼** | PageFetcherFactory â†’ é€‰æ‹© Puppeteer / Playwright / Headless Chrome | æ”¯æŒä¸åŒæ¸²æŸ“å¼•æ“ï¼Œé€‚é…ä¸åŒç«™ç‚¹éœ€æ±‚ï¼ˆå¦‚ React vs é™æ€ HTMLï¼‰ |\n| **è§‚å¯Ÿè€…æ¨¡å¼** | ç›‘å¬é¡µé¢åŠ è½½äº‹ä»¶ï¼ˆdomContentLoaded, loadï¼‰â†’ è§¦å‘æå–é€»è¾‘ | ç²¾ç¡®æ§åˆ¶æŠ“å–æ—¶æœºï¼Œé¿å…è¿‡æ—©æ‰§è¡Œå¯¼è‡´å†…å®¹æœªæ¸²æŸ“ |\n| **å‘½ä»¤æ¨¡å¼** | æ¯ä¸ªçˆ¬å–è¯·æ±‚å°è£…ä¸º Command å¯¹è±¡ï¼ˆå« URLã€å‚æ•°ã€å›è°ƒï¼‰ | æ”¯æŒé‡è¯•ã€é˜Ÿåˆ—æŒä¹…åŒ–ã€æ—¥å¿—è¿½è¸ª |\n\n---\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| æŠ€æœ¯ | é€‰æ‹©ç†ç”± | æ›¿ä»£æ–¹æ¡ˆ | æ³¨æ„äº‹é¡¹ |\n|------|----------|-----------|----------|\n| **TypeScript** | å¼ºç±»å‹ä¿éšœå¤æ‚çˆ¬è™«é€»è¾‘çš„å¯ç»´æŠ¤æ€§ï¼Œä¸ Node.js ç”Ÿæ€æ— ç¼é›†æˆ | JavaScript | éœ€ä¸¥æ ¼é…ç½® `tsconfig.json` é¿å… any æ³›æ»¥ |\n| **Express.js** | è½»é‡ã€æˆç†Ÿã€ä¸­é—´ä»¶ç”Ÿæ€ä¸°å¯Œï¼ˆå¦‚ express-rate-limitï¼‰ | Fastify / NestJS | Fastify æ›´å¿«ä½†ç¤¾åŒºå·¥å…·é“¾å¼±ï¼ŒNest è¿‡é‡ |\n| **Puppeteer / Playwright** | æ”¯æŒç°ä»£ JS æ¸²æŸ“ + ç½‘ç»œæ‹¦æˆª + æ— å¤´æ¨¡å¼ | Selenium | Playwright æ›´ç¨³å®šã€æ”¯æŒå¤šæµè§ˆå™¨ï¼Œæ˜¯é¦–é€‰ |\n| **Cheerio**ï¼ˆå¯é€‰ï¼‰ | é™æ€ HTML å¿«é€Ÿè§£æï¼Œé¿å…å¯åŠ¨æµè§ˆå™¨ | jsdom | ä»…ç”¨äºé JS ç«™ç‚¹ï¼Œæå‡æ•ˆç‡ |\n| **ONNX Runtime (Node.js)** | è½»é‡çº§æ¨ç†æ¨¡å‹åµŒå…¥ï¼Œæ”¯æŒ CPU æ¨ç† | TensorFlow.js / PyTorch TorchScript | æ¨¡å‹éœ€é‡åŒ–ä¸º ONNXï¼Œé¿å…å¤§æ¨¡å‹å ç”¨å†…å­˜ |\n| **Redis** | é«˜æ€§èƒ½ç¼“å­˜ã€ä»»åŠ¡é˜Ÿåˆ—ï¼ˆé€šè¿‡ `bullmq`ï¼‰ | PostgreSQL + pg-boss | Redis çš„ Pub/Sub å’Œ TTL å¯¹ç¼“å­˜åœºæ™¯æ›´ä¼˜ |\n| **Zod** | è¾“å…¥/è¾“å‡º Schema æ ¡éªŒ | Joi / Yup | æ›´è½»é‡ï¼Œç±»å‹æ¨å¯¼å®Œç¾å…¼å®¹ TS |\n| **P-limit / BullMQ** | æ§åˆ¶å¹¶å‘ã€å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ— | Worker Threads + Queue.js | BullMQ æ”¯æŒé‡è¯•ã€å»¶è¿Ÿã€ä¼˜å…ˆçº§ï¼Œç”Ÿäº§çº§ |\n\n> âš ï¸ ç‰ˆæœ¬å…¼å®¹æ€§æ³¨æ„ï¼šPlaywright v1.40+ æ‰æ”¯æŒ Chromium 125 çš„æ— å¤´æ¨¡å¼ï¼ˆéƒ¨åˆ†ç½‘ç«™æ£€æµ‹ headlessï¼‰ï¼Œéœ€é”å®šç‰ˆæœ¬ã€‚Puppeteer åœ¨ Node.js 18+ ä¸‹æœ‰å†…å­˜æ³„æ¼é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨ Node 20 LTSã€‚\n\n---\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. å…‹éš†ä»“åº“ï¼ˆæ³¨æ„ï¼šè‡ªæ‰˜ç®¡ä»ä¸å®Œæ•´ï¼Œä½†å¯è¿è¡Œæœ¬åœ° APIï¼‰\ngit clone https://github.com/firecrawl/firecrawl.git\ncd firecrawl\n\n# 2. å®‰è£…ä¾èµ–ï¼ˆmono-repo ç»“æ„ï¼Œéœ€å®‰è£…æ‰€æœ‰åŒ…ï¼‰\nnpm install --legacy-peer-deps  # é¿å… npm 9+ çš„ peerDependency å†²çª\n\n# 3. å¯åŠ¨æœ¬åœ° API æœåŠ¡ï¼ˆé»˜è®¤ç«¯å£ 3000ï¼‰\nnpm run dev:server\n\n# 4. è·å– API Keyï¼ˆæ³¨å†Œåä» https://firecrawl.dev è·å–ï¼‰\nexport FIRECRAWL_API_KEY=your_api_key_here\n\n# 5. æµ‹è¯•è¿æ¥\ncurl -X POST http://localhost:3000/crawl \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"url\": \"https://example.com\",\n    \"pageOptions\": {\n      \"onlyMainContent\": true,\n      \"format\": \"markdown\"\n    }\n  }'\n```\n\n> âœ… **æ³¨**ï¼šå½“å‰ç‰ˆæœ¬è‡ªæ‰˜ç®¡éœ€æ‰‹åŠ¨é…ç½® Redis + é‚®ä»¶æœåŠ¡ï¼ˆç”¨äºç”¨æˆ·æ³¨å†Œï¼‰ï¼Œç”Ÿäº§éƒ¨ç½²å»ºè®®ç”¨ Docker Composeï¼Œå‚è€ƒ `docker-compose.yml` ç¤ºä¾‹ã€‚\n\n---\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n```ts\nimport { FirecrawlApp } from '@firecrawl/firecrawl';\n\nconst app = new FirecrawlApp({ apiKey: 'your_api_key' });\n\n// è¾“å…¥ï¼šçœŸå®åœºæ™¯ â€”â€” æŠ“å–å…¬å¸äº§å“æ–‡æ¡£é¡µ\nconst result = await app.crawlUrl('https://docs.yourcompany.com/api/v1/users', {\n  pageOptions: {\n    onlyMainContent: true,     // åªæå–æ­£æ–‡ï¼Œå¿½ç•¥å¯¼èˆª/å¹¿å‘Š\n    format: 'markdown',        // è¾“å‡ºä¸º LLM æ˜“è¯»çš„ Markdown\n    timeout: 15000,            // è¶…æ—¶ 15s\n    includeLinks: false,       // ä¸åŒ…å«é¡µé¢å†…é“¾æ¥ï¼ˆé¿å…å™ªéŸ³ï¼‰\n    waitForSelector: '#main-content' // ç­‰å¾…ç‰¹å®šå…ƒç´ åŠ è½½åå†æŠ“å–\n  }\n});\n\n// é¢„æœŸè¾“å‡ºï¼š\n/*\n{\n  success: true,\n  data: {\n    content: \"# API Reference: Users\\n\\n## GET /api/v1/users\\n\\nReturns a list of all users...\\n\\n### Parameters\\n- `page`: integer (optional)\\n- `limit`: integer (default: 20)\\n\\n---\\n\\n> Auth required: Bearer Token\",\n    metadata: {\n      url: \"https://docs.yourcompany.com/api/v1/users\",\n      title: \"Users - API Reference | YourCompany\",\n      crawledAt: \"2025-04-05T10:30:22Z\"\n    }\n  }\n}\n*/\n\n// å¯ç›´æ¥å–‚ç»™ LLM\nconst llmResponse = await openai.chat.completions.create({\n  model: \"gpt-4-turbo\",\n  messages: [\n    { role: \"system\", content: \"You are a documentation assistant. Answer based on the context.\" },\n    { role: \"user\", content: `Context:\\n${result.data.content}\\n\\nQuestion: How do I paginate users?` }\n  ]\n});\n```\n\n---\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n| æŒ‡æ ‡ | æ¨æµ‹å€¼ | è¯´æ˜ |\n|------|--------|------|\n| å•é¡µæŠ“å–è€—æ—¶ | 3â€“8sï¼ˆJS ç«™ç‚¹ï¼‰ / <1sï¼ˆé™æ€ HTMLï¼‰ | å–å†³äºé¡µé¢å¤æ‚åº¦ã€ç½‘ç»œå»¶è¿Ÿã€æ¸²æŸ“æ—¶é—´ |\n| å¹¶å‘èƒ½åŠ› | ~50â€“100 req/sï¼ˆå•æœºï¼Œ8GB RAMï¼‰ | Puppeteer å®ä¾‹å ç”¨å†…å­˜å¤§ï¼Œå»ºè®® 2â€“4GB/å®ä¾‹ |\n| å†…å­˜æ¶ˆè€— | æ¯ä¸ª Puppeteer å®ä¾‹ 600MBâ€“1.2GB | éœ€è®¾ç½® `--disable-g",
    "last_scanned": "2026-01-16T02:03:15.390334",
    "last_analyzed": "2026-01-15T08:18:13.307615",
    "screenshot": "static/screenshots/787076358.jpg",
    "ai_visual_summary": "è¯¥ç•Œé¢æ˜¯åä¸º `firecrawl` çš„ GitHub é¡¹ç›®ä¸»é¡µï¼Œå…¶è®¾è®¡é£æ ¼ç®€æ´ã€ç°ä»£ï¼Œä»¥ç™½è‰²ä¸ºèƒŒæ™¯ï¼Œé€šè¿‡æ¸…æ™°çš„åˆ†éš”çº¿å’Œä»£ç å—æ¥ç»„ç»‡å†…å®¹ï¼Œå‘ˆç°å‡ºå…¸å‹çš„å¼€å‘è€…å‹å¥½å‹æŠ€æœ¯æ–‡æ¡£é£æ ¼ã€‚ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬é¡¹ç›®æè¿°ã€API ä½¿ç”¨ç¤ºä¾‹å’Œ `LLM Extraction (Beta)` åŠŸèƒ½ä»‹ç»ã€‚å¯è§çš„æŠ€æœ¯å…³é”®è¯æœ‰ `API`ã€`LLM`ã€`markdown`ã€`structured data` å’Œ `JSON`ï¼Œè¿™è¡¨æ˜è¯¥é¡¹ç›®æ˜¯ä¸€ä¸ªä¸ºäººå·¥æ™ºèƒ½åº”ç”¨æä¾›ç½‘é¡µæ•°æ®æå–æœåŠ¡çš„å·¥å…·ã€‚ç»¼åˆæ¥çœ‹ï¼Œè¿™ä¸ªåº”ç”¨æ—¨åœ¨å°†æ•´ä¸ªç½‘ç«™çš„å†…å®¹è½¬æ¢ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ç›´æ¥ä½¿ç”¨çš„ç»“æ„åŒ–æ•°æ®æˆ– Markdown æ ¼å¼ï¼Œä»è€Œç®€åŒ–ä»ç½‘é¡µæŠ“å–å’Œå¤„ç†ä¿¡æ¯çš„æµç¨‹ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "616372661",
    "name": "gpt_academic",
    "full_name": "binary-husky/gpt_academic",
    "category": "llm_rag",
    "stars": 69973,
    "forks": 8402,
    "description": "ä¸ºGPT/GLMç­‰LLMå¤§è¯­è¨€æ¨¡å‹æä¾›å®ç”¨åŒ–äº¤äº’æ¥å£ï¼Œç‰¹åˆ«ä¼˜åŒ–è®ºæ–‡é˜…è¯»/æ¶¦è‰²/å†™ä½œä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®&å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒPythonå’ŒC++ç­‰é¡¹ç›®å‰–æ&è‡ªè¯‘è§£åŠŸèƒ½ï¼ŒPDF/LaTexè®ºæ–‡ç¿»è¯‘&æ€»ç»“åŠŸèƒ½ï¼Œæ”¯æŒå¹¶è¡Œé—®è¯¢å¤šç§LLMæ¨¡å‹ï¼Œæ”¯æŒchatglm3ç­‰æœ¬åœ°æ¨¡å‹ã€‚æ¥å…¥é€šä¹‰åƒé—®, deepseekcoder, è®¯é£æ˜Ÿç«, æ–‡å¿ƒä¸€è¨€, llama2, rwkv, claude2, mossç­‰ã€‚",
    "url": "https://github.com/binary-husky/gpt_academic",
    "homepage": "https://github.com/binary-husky/gpt_academic/wiki/online",
    "language": "Python",
    "topics": "[\"academic\", \"chatglm-6b\", \"chatgpt\", \"gpt-4\", \"large-language-models\"]",
    "created_at": "2023-03-20T09:05:13Z",
    "updated_at": "2026-01-15T17:23:34Z",
    "readme_content": null,
    "ai_summary": "ä¸“ä¸ºå­¦æœ¯åœºæ™¯ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰äº¤äº’å·¥å…·ï¼Œæä¾›è®ºæ–‡é˜…è¯»/æ¶¦è‰²/å†™ä½œè¾…åŠ©åŠå¤šæ¨¡æ€ç¿»è¯‘åŠŸèƒ½",
    "ai_tech_stack": "[\"Python\", \"\\u6a21\\u5757\\u5316\\u63d2\\u4ef6\\u7cfb\\u7edf\", \"\\u5e76\\u884c\\u8c03\\u7528LLM\", \"PDF/LaTeX\\u5904\\u7406\"]",
    "ai_use_cases": "[\"\\u5b66\\u672f\\u8bba\\u6587\\u667a\\u80fd\\u6458\\u8981\\u751f\\u6210\", \"\\u8de8\\u8bed\\u8a00\\u6587\\u732e\\u7ffb\\u8bd1\\u4e0e\\u5bf9\\u6bd4\\u5206\\u6790\", \"\\u7f16\\u7a0b\\u9879\\u76ee\\u6587\\u6863\\u81ea\\u52a8\\u751f\\u6210\\u6ce8\\u91ca/\\u62a5\\u544a\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "pip install -r requirements.txt && python gpt_academic.py --help",
    "ai_tutorial": "# GPT Academicï¼šé¢å‘ç§‘ç ”å·¥ä½œè€…çš„LLMäº¤äº’ç³»ç»Ÿæ·±åº¦æ¶æ„åˆ†æ\n\n---\n\n## ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\n**GPT Academic çš„æ ¸å¿ƒå·®å¼‚åŒ–ï¼Œåœ¨äºå®ƒä¸æ˜¯â€œä¸€ä¸ªèƒ½è°ƒç”¨APIçš„èŠå¤©ç•Œé¢â€ï¼Œè€Œæ˜¯ä¸€ä¸ªä¸ºå­¦æœ¯å·¥ä½œæµé‡èº«å®šåˆ¶çš„ã€å¯æ‰©å±•çš„LLMæ“ä½œå¹³å°ã€‚**\n\n### ç‹¬ç‰¹ä»·å€¼ï¼š\n\n1. **ç§‘ç ”åœºæ™¯æ·±åº¦ç»‘å®š**\n   - é’ˆå¯¹è®ºæ–‡é˜…è¯»/æ¶¦è‰²/å†™ä½œè¿™ä¸€**é«˜åº¦ç»“æ„åŒ–ä½†éæ ‡å‡†åŒ–**çš„ä»»åŠ¡é“¾ï¼Œæä¾›ç«¯åˆ°ç«¯æ”¯æŒï¼šPDFè§£æ â†’ LaTeXæå– â†’ å¤šæ®µè½ç¿»è¯‘ â†’ æœ¯è¯­ä¸€è‡´æ€§æ ¡éªŒ â†’ å¼•ç”¨æ ¼å¼ä¿®å¤ â†’ å›¾è¡¨æè¿°ç”Ÿæˆã€‚\n   - å¯¹æ¯” ChatGPTã€Claude ç­‰é€šç”¨æ¨¡å‹ç•Œé¢ï¼Œå®ƒ**ä¸»åŠ¨ç†è§£â€œå­¦æœ¯æ–‡æœ¬â€çš„è¯­ä¹‰ä¸Šä¸‹æ–‡**ï¼ˆå¦‚å‚è€ƒæ–‡çŒ®ç¼–å·ã€å…¬å¼ç¯å¢ƒã€ç« èŠ‚ç»“æ„ï¼‰ï¼Œè€Œéä»…ä½œçº¯æ–‡æœ¬è¡¥å…¨ã€‚\n\n2. **å¤šæ¨¡å‹å¹¶è¡Œä¸åŠ¨æ€åˆ‡æ¢çš„å·¥ç¨‹å®ç°**\n   - æ”¯æŒåŒæ—¶æ¥å…¥ OpenAIã€Qwenã€GLMã€Claudeã€DeepSeek-Coderã€LLaMA2 ç­‰**10+ç§æ¨¡å‹**ï¼Œä¸”æ”¯æŒ**å•æ¬¡è¯·æ±‚å¹¶å‘å‘é€è‡³å¤šä¸ªåç«¯**ï¼ˆå¦‚ï¼šç”¨ Qwen åšç¿»è¯‘ï¼Œç”¨ Claude åšé€»è¾‘æ ¡éªŒï¼‰ï¼Œç»“æœè‡ªåŠ¨åˆå¹¶/æŠ•ç¥¨ã€‚\n   - å®ç°â€œæ¨¡å‹ç†”æ–­â€æœºåˆ¶ï¼šè‹¥æŸAPIå“åº”è¶…æ—¶æˆ–è¿”å›é”™è¯¯ç ï¼Œåˆ™è‡ªåŠ¨é™çº§åˆ°å¤‡ç”¨æ¨¡å‹ï¼Œæ— é¡»äººå·¥å¹²é¢„ã€‚\n\n3. **è‡ªè¯‘è§£ï¼ˆSelf-Explainï¼‰ç³»ç»Ÿ**\n   - é¡¹ç›®å†…ç½® `self_analysis.md` åŠ¨æ€ç”Ÿæˆæœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·**é€šè¿‡LLMè‡ªèº«è§£æä»£ç é€»è¾‘**å¹¶æ›´æ–°æ–‡æ¡£ã€‚è¿™æ˜¯å¯¹â€œä»£ç å³æ–‡æ¡£â€ç†å¿µçš„æè‡´å®è·µï¼šæ–‡æ¡£ä¸æ˜¯é™æ€çš„ï¼Œè€Œæ˜¯ç”±æ¨¡å‹åœ¨è¿è¡Œæ—¶åŠ¨æ€é‡æ„ã€‚\n   - æ¯ä¸ªæ’ä»¶éƒ½å¯è¢«è°ƒç”¨ `self_analyze()` æ–¹æ³•é‡æ–°è§£é‡Šå…¶åŠŸèƒ½â€”â€”è¿™åœ¨å¼€æºé¡¹ç›®ä¸­æä¸ºç½•è§ï¼Œæå¤§é™ä½æ–°è´¡çŒ®è€…ç†è§£æˆæœ¬ã€‚\n\n4. **ä¸­æ–‡ç”Ÿæ€ä¼˜å…ˆè®¾è®¡**\n   - ä»ä¸€å¼€å§‹å°±æ·±åº¦é€‚é…å›½å†…ä¸»æµæ¨¡å‹ï¼ˆQwenã€GLMã€æ˜Ÿç«ã€æ–‡å¿ƒï¼‰ï¼Œå¹¶æ”¯æŒ**æœ¬åœ°éƒ¨ç½²çš„ChatGLM3ã€Llama2-7Bç­‰è½»é‡æ¨¡å‹**ï¼Œè§£å†³æµ·å¤–APIä¸å¯ç”¨æˆ–å»¶è¿Ÿé«˜çš„ç—›ç‚¹ã€‚\n   - å¯¹ä¸­æ–‡è®ºæ–‡ä¸­çš„â€œæœ¯è¯­ä¸ä¸€è‡´â€ã€â€œä¸­è‹±æ··æ’æ ‡ç‚¹æ··ä¹±â€ã€â€œå‚è€ƒæ–‡çŒ®æ ¼å¼é”™ä¹±â€ç­‰é«˜é¢‘é—®é¢˜æœ‰ä¸“é¡¹å¤„ç†æ¨¡å—ã€‚\n\n5. **æ’ä»¶ç³»ç»Ÿä¸å¿«æ·é”®çš„å·¥ç¨‹åŒ–å°è£…**\n   - ä¸æ˜¯ç®€å•åœ°æä¾›æŒ‰é’®ï¼Œè€Œæ˜¯é€šè¿‡**JSON Schemaå®šä¹‰æ’ä»¶æ¥å£**ï¼ˆè¾“å…¥/è¾“å‡º/å‚æ•°ç±»å‹ï¼‰ï¼Œå…è®¸ç”¨æˆ·ç”¨Pythonç¼–å†™å‡½æ•°å¹¶è‡ªåŠ¨æ³¨å†Œä¸ºGUIæŒ‰é’®ã€‚\n   - æ”¯æŒâ€œä¸€é”®æ¶¦è‰²å½“å‰é€‰ä¸­LaTeXæ®µè½â€ã€â€œç¿»è¯‘æ•´ç¯‡PDFå¹¶ç”ŸæˆBibTeXæ‘˜è¦â€ç­‰åŸå­åŒ–æ“ä½œï¼ŒçœŸæ­£èå…¥ç§‘ç ”ç¼–è¾‘å™¨å·¥ä½œæµã€‚\n\n> âœ… **ç»“è®º**ï¼šå®ƒä¸æ˜¯â€œå¦ä¸€ä¸ªAIèŠå¤©å·¥å…·â€ï¼Œè€Œæ˜¯â€œé¢å‘å­¦æœ¯ç”Ÿäº§åŠ›çš„å¯ç¼–ç¨‹LLMæ“ä½œç³»ç»Ÿâ€ã€‚\n\n---\n\n## ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n### 1. **åŸºäºå¼‚æ­¥åç¨‹çš„å¤šæ¨¡å‹å¹¶å‘è¯·æ±‚è°ƒåº¦å™¨**\n```python\nasync def query_parallel(models: List[str], prompt: str) -> Dict[str, str]:\n    tasks = [asyncio.create_task(query_single_model(m, prompt)) for m in models]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n    return {m: r if not isinstance(r, Exception) else f\"ERR: {str(r)}\" for m, r in zip(models, results)}\n```\n- ä½¿ç”¨ `asyncio` + `aiohttp` å®ç°éé˜»å¡å¹¶å‘è¯·æ±‚ï¼Œå•æ¬¡æŸ¥è¯¢å¯åŒæ—¶è°ƒç”¨ 5+ æ¨¡å‹ï¼Œå“åº”æ—¶é—´ä»…â‰ˆæœ€æ…¢æ¨¡å‹çš„è€—æ—¶ã€‚\n- **åˆ›æ–°ç‚¹**ï¼šç»“æœåˆå¹¶ç­–ç•¥æ”¯æŒâ€œå¤šæ•°æŠ•ç¥¨â€ï¼ˆå¦‚ç¿»è¯‘ä¸€è‡´æ€§ï¼‰ã€â€œæœ€ä½³ç½®ä¿¡åº¦é€‰æ‹©â€ã€â€œå·®å¼‚å¯¹æ¯”é«˜äº®â€ï¼Œè€Œéç®€å•è¿”å›ç¬¬ä¸€ä¸ªã€‚\n\n### 2. **PDF â†’ LaTeX â†’ Markdown çš„ä¸‰é˜¶è§£ææµæ°´çº¿**\né›†æˆ `Doc2x`ï¼ˆé¡¹ç›®è‡ªç ”ï¼‰å®ç°ï¼š\n```\nPDF (æ‰«æä»¶/åŸç”Ÿ) \nâ†’ OCR + å¸ƒå±€åˆ†æ (LayoutParser + PaddleOCR)\nâ†’ ç»“æ„åŒ–æå–ï¼šæ ‡é¢˜ã€å…¬å¼ï¼ˆMathMLï¼‰ã€å›¾è¡¨ã€å‚è€ƒæ–‡çŒ®\nâ†’ è½¬æ¢ä¸ºå¯ç¼–è¾‘çš„ LaTeX æºç ç‰‡æ®µï¼ˆä¿ç•™ \\section{}, \\cite{} ç­‰ï¼‰\nâ†’ é€å…¥LLMè¿›è¡Œç¿»è¯‘/æ¶¦è‰²\n```\n- **çªç ´**ï¼šä¼ ç»Ÿå·¥å…·ï¼ˆå¦‚PDFtoTextï¼‰ä¼šä¸¢å¤±ç»“æ„ï¼Œè€Œè¯¥ç³»ç»Ÿèƒ½è¯†åˆ«â€œå…¬å¼æ˜¯è¡Œå†…è¿˜æ˜¯å—çº§â€ã€â€œå‚è€ƒæ–‡çŒ®ç¼–å·æ˜¯å¦ä¸BibTeXåŒ¹é…â€ï¼Œæå¤§æå‡åç»­AIå¤„ç†å‡†ç¡®ç‡ã€‚\n\n### 3. **æ’ä»¶çƒ­åŠ è½½ä¸åŠ¨æ€æ³¨å†Œæœºåˆ¶**\n```python\n# æ’ä»¶å®šä¹‰æ–‡ä»¶ plugin_summarize.py\n@register_plugin(\n    name=\"è®ºæ–‡æ‘˜è¦ç”Ÿæˆ\",\n    trigger=\"summarize_paper()\",\n    input_type=\"str\",  # è¾“å…¥ä¸ºé€‰ä¸­æ–‡æœ¬æˆ–PDFè·¯å¾„\n    output_type=\"markdown\",\n    category=\"writing\"\n)\ndef summarize_paper(text: str) -> str:\n    return llm_call(f\"è¯·ç”¨200å­—æ€»ç»“ä»¥ä¸‹è®ºæ–‡å†…å®¹ï¼š\\n{text}\")\n```\n- ä½¿ç”¨è£…é¥°å™¨ `@register_plugin` å®ç°**è¿è¡Œæ—¶æ’ä»¶æ³¨å†Œ**ï¼Œæ— éœ€é‡å¯æœåŠ¡ã€‚\n- æ‰€æœ‰æ’ä»¶å…ƒä¿¡æ¯ï¼ˆåç§°ã€å›¾æ ‡ã€è§¦å‘è¯ï¼‰è‡ªåŠ¨è¢«å‰ç«¯GUIè¯»å–å¹¶æ¸²æŸ“ä¸ºæŒ‰é’®ã€‚\n\n### 4. **API Key åŠ¨æ€æ³¨å…¥ä¸è½®è¯¢æœºåˆ¶**\n```python\n# config.py\nAPI_KEY = \"sk-openai-1,sk-openai-2,api2d-key3,qwen-apikey4\"\n\nclass APIManager:\n    def get_key(self):\n        # è½®è¯¢å¯ç”¨Keyï¼Œè·³è¿‡å¤±æ•ˆçš„\n        for key in self.keys:\n            if self.is_valid(key): \n                return key\n        raise NoValidKeyError()\n```\n- æ”¯æŒåœ¨è¾“å…¥æ¡†ä¸­ç›´æ¥è¾“å…¥ `API_KEY=xxxxx` å¹¶å›è½¦ï¼Œ**ç«‹å³åˆ‡æ¢å½“å‰ä¼šè¯å¯†é’¥**ï¼Œæ— éœ€é‡å¯ã€‚\n- å†…ç½®è‡ªåŠ¨é‡è¯•+é€€é¿ç­–ç•¥ï¼ˆexponential backoffï¼‰ï¼Œåº”å¯¹Rate Limitã€‚\n\n---\n\n## ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n### 1. æ•´ä½“æ¶æ„å›¾ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\n[ç”¨æˆ·ç•Œé¢ (Web GUI)] \n       â†“ HTTP/WebSocket\n[APIç½‘å…³å±‚ (FastAPI)] â†â†’ [ä¼šè¯ç®¡ç†å™¨] â†â†’ [æ¨¡å‹è·¯ç”±è°ƒåº¦å™¨]\n       â†‘                     â†‘                  â†‘\n   [æ’ä»¶å¼•æ“]           [ç¼“å­˜å±‚ (Redis)]     [å¤šåç«¯é€‚é…å™¨]\n       |                     |                  |\n   [è‡ªå®šä¹‰Pythonæ’ä»¶]      [PDF/TeXè§£æå™¨]    [Qwen/GLM/Claude/OpenAIç­‰]\n       â†“                     â†“                  â†“\n[æœ¬åœ°æ¨¡å‹ (ChatGLM3, Llama2)]  [Doc2xå¼•æ“]     [APIä»£ç†å±‚]\n```\n\n### 2. æ ¸å¿ƒæ¨¡å—åˆ’åˆ†\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| **Web GUI** | åŸºäº Gradio + è‡ªå®šä¹‰JSï¼Œæ”¯æŒMarkdownæ¸²æŸ“ã€ä»£ç é«˜äº®ã€LaTeXå…¬å¼é¢„è§ˆ |\n| **FastAPI** | æä¾›RESTfulæ¥å£ï¼Œç®¡ç†ä¼šè¯çŠ¶æ€ï¼ˆåŸºäºå†…å­˜/Redisï¼‰ï¼Œå¤„ç†æ–‡ä»¶ä¸Šä¼  |\n| **Session Manager** | ç»´æŠ¤æ¯ä¸ªç”¨æˆ·ä¼šè¯çš„ä¸Šä¸‹æ–‡ï¼ˆå†å²å¯¹è¯ã€å½“å‰æ¨¡å‹ã€å·²åŠ è½½PDFï¼‰ |\n| **Model Router** | æ ¹æ®æŒ‡ä»¤é€‰æ‹©ç›®æ ‡æ¨¡å‹ï¼›æ”¯æŒå¹¶è¡ŒæŸ¥è¯¢ä¸ç»“æœèåˆç­–ç•¥ |\n| **Plugin Engine** | åŠ¨æ€åŠ è½½ `.py` æ’ä»¶ï¼Œè§£æ `@register_plugin` å…ƒæ•°æ®ï¼Œæä¾›å‡½æ•°è°ƒç”¨æ²™ç®±ç¯å¢ƒ |\n| **Doc2x Parser** | PDF â†’ ç»“æ„åŒ–æ–‡æœ¬ï¼ˆå«å…¬å¼/å›¾è¡¨å®šä½ï¼‰â†’ LaTeX ç‰‡æ®µ |\n| **Config Manager** | ç®¡ç†å¤šAPI Keyã€æ¨¡å‹ç«¯ç‚¹ã€æ’ä»¶å¼€å…³ã€å­—ä½“é…ç½®ç­‰ |\n\n### 3. æ•°æ®æµå‘\n\n```\nç”¨æˆ·è¾“å…¥ï¼š[PDFæ–‡ä»¶] + \"è¯·ç¿»è¯‘ç¬¬3ç« å¹¶æ¶¦è‰²è¯­è¨€\"\n        â†“\nDoc2xè§£æ â†’ æå–ç¬¬3ç« çš„LaTeXæºç ï¼ˆä¿ç•™\\section{å¼•è¨€}ï¼‰\n        â†“\nModel Router â†’ åŒæ—¶å‘é€ç»™ Qwen-7Bï¼ˆç¿»è¯‘ï¼‰+ Claude-3ï¼ˆæ¶¦è‰²ï¼‰ + DeepSeek-Coderï¼ˆæœ¯è¯­æ ¡éªŒï¼‰\n        â†“\nç»“æœèåˆï¼šQwenè¯‘æ–‡ + Claudeé£æ ¼ä¼˜åŒ– + DeepSeekæœ¯è¯­å»ºè®®\n        â†“\nPlugin Engine â†’ è°ƒç”¨ \"format_for_latex\" æ’ä»¶ â†’ è¾“å‡ºå¸¦ \\textbf{} çš„LaTeXç‰‡æ®µ\n        â†“\nå‰ç«¯æ¸²æŸ“ â†’ ä»¥Markdown+MathJaxæ ¼å¼æ˜¾ç¤ºï¼Œæ”¯æŒä¸€é”®å¤åˆ¶å›Overleaf\n```\n\n### 4. å…³é”®è®¾è®¡æ¨¡å¼\n\n| æ¨¡å¼ | åº”ç”¨åœºæ™¯ | åŸå›  |\n|------|----------|------|\n| **æ’ä»¶æ¨¡å¼ï¼ˆPlugin Patternï¼‰** | æ‰€æœ‰åŠŸèƒ½æ‰©å±•ï¼ˆç¿»è¯‘ã€æ€»ç»“ã€ä»£ç åˆ†æï¼‰ | å®ç°â€œå¼€é—­åŸåˆ™â€ï¼šæ–°å¢åŠŸèƒ½æ— éœ€ä¿®æ”¹æ ¸å¿ƒï¼Œåªéœ€å†™.pyæ–‡ä»¶ |\n| **ç­–ç•¥æ¨¡å¼ï¼ˆStrategy Patternï¼‰** | æ¨¡å‹é€‰æ‹©ï¼ˆOpenAI / Qwen / GLMï¼‰ | å¯åŠ¨æ€åˆ‡æ¢æ¨ç†å¼•æ“ï¼Œç»Ÿä¸€æ¥å£ `call_llm(prompt: str) â†’ str` |\n| **è§‚å¯Ÿè€…æ¨¡å¼** | GUIæŒ‰é’®ç‚¹å‡»è§¦å‘æ’ä»¶æ‰§è¡Œ | æ’ä»¶æ³¨å†Œåè‡ªåŠ¨ç»‘å®šåˆ°å‰ç«¯äº‹ä»¶ï¼Œæ— éœ€ç¡¬ç¼–ç  |\n| **å·¥å‚æ¨¡å¼** | API Key ç®¡ç†å™¨ã€æ¨¡å‹å®¢æˆ·ç«¯åˆ›å»º | æ ¹æ®é…ç½®æ–‡ä»¶åŠ¨æ€å®ä¾‹åŒ–ä¸åŒLLMå®¢æˆ·ç«¯ï¼ˆå¦‚ `QwenClient`, `ClaudeClient`ï¼‰ |\n\n---\n\n## ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| æŠ€æœ¯ | ä½œç”¨ | æ›¿ä»£æ–¹æ¡ˆ | ä¸ºä½•é€‰å®ƒ |\n|------|------|----------|----------|\n| **Python 3.10+** | æ ¸å¿ƒè¯­è¨€ | Go, Rust | ç”Ÿæ€ä¸°å¯Œï¼ˆPyTorchã€Gradioï¼‰ã€é€‚åˆå¿«é€ŸåŸå‹å¼€å‘ï¼Œå›¢é˜Ÿç†Ÿæ‚‰åº¦é«˜ |\n| **FastAPI** | WebæœåŠ¡æ¡†æ¶ | Flask, Django | å¼‚æ­¥æ”¯æŒå¥½ï¼Œè‡ªåŠ¨ç”ŸæˆOpenAPIæ–‡æ¡£ï¼Œæ€§èƒ½ä¼˜äºFlask |\n| **Gradio** | å‰ç«¯UI | Streamlit, React + Tailwind | å¿«é€Ÿæ­å»ºäº¤äº’å¼ç•Œé¢ï¼ŒåŸç”Ÿæ”¯æŒMarkdownã€LaTeXã€æ–‡ä»¶ä¸Šä¼ ï¼Œå¼€å‘æ•ˆç‡æé«˜ |\n| **LangChainï¼ˆè½»é‡å°è£…ï¼‰** | LLMé“¾å¼è°ƒç”¨ | LlamaIndex, Semantic Kernel | ä»…ä½¿ç”¨å…¶ `LLMChain` åŸºç¡€åŠŸèƒ½ï¼Œé¿å…è¿‡åº¦æŠ½è±¡ï¼Œä¿æŒå¯æ§æ€§ |\n| **PaddleOCR + MathPix** | PDFå…¬å¼è¯†åˆ« | Tesseract, OCRmyPDF | PaddleOCRå¯¹ä¸­æ–‡ã€æ•°å­¦ç¬¦å·è¯†åˆ«ç‡é«˜ï¼›MathPixç”¨äºç²¾ç¡®LaTeXè½¬æ¢ï¼ˆéå¼€æºï¼‰ |\n| **Docker** | éƒ¨ç½² | Conda, Virtualenv | å®ç°ç¯å¢ƒéš”ç¦»ï¼Œè§£å†³ `requirements.txt` ç‰ˆæœ¬å†²çªé—®é¢˜ï¼ˆé¡¹ç›®å¼ºè°ƒâ€œå¿…é¡»ç”¨æŒ‡å®šç‰ˆæœ¬â€ï¼‰ |\n| **Redis** | ä¼šè¯ç¼“å­˜ | SQLite, Memory | æ”¯æŒå¤šå®ä¾‹éƒ¨ç½²æ—¶å…±äº«çŠ¶æ€ï¼Œå“åº”å¿«ï¼Œæ”¯æŒTTLè¿‡æœŸ |\n\n> ğŸ”´ **å…³é”®æ³¨æ„**ï¼š`requirements.txt` ä¸­çš„åº“ç‰ˆæœ¬ï¼ˆå¦‚ `transformers==4.35.2`, `torch==2.1.0+cu118`ï¼‰æ˜¯ç»è¿‡å®æµ‹å…¼å®¹çš„ã€‚ä½¿ç”¨æ–°ç‰ˆå¯èƒ½è§¦å‘æ¨¡å‹åŠ è½½å¤±è´¥æˆ–CUDAé”™è¯¯â€”â€”è¿™æ˜¯è¯¥é¡¹ç›®â€œå·¥ç¨‹åŒ–æˆç†Ÿåº¦â€çš„ä½“ç°ã€‚\n\n---\n\n## ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. å…‹éš†ä»“åº“ï¼ˆæ¨èä½¿ç”¨ SSHï¼‰\ngit clone https://github.com/binary-husky/gpt_academic.git\ncd gpt_academic\n\n# 2. åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆé¿å…æ±¡æŸ“ç³»ç»Ÿï¼‰\npython -m venv venv\nsource venv/bin/activate    # Windows: venv\\Scripts\\activate\n\n# 3. å®‰è£…æŒ‡å®šç‰ˆæœ¬ä¾èµ–ï¼ˆå¿…é¡»ï¼ï¼‰â€”â€”è¿™æ˜¯é¡¹ç›®æˆåŠŸçš„å…³é”®ä¸€æ­¥\npip install --upgrade pip\npip install -r requirements.txt\n\n# 4. ä¸‹è½½æ¨¡å‹æƒé‡ï¼ˆä»¥Qwen2.5-7Bä¸ºä¾‹ï¼Œéœ€è‡ªè¡Œç”³è¯·ï¼‰\n# å‚è€ƒï¼šhttps://modelscope.cn/models/qwen/Qwen2.5-7B-Chat/summary\nmkdir models && cd models\nhuggingface-cli download Qwen/Qwen2.5-7B-Chat --local-dir ./qwen2.5-7b-chat\n\n# 5. é…ç½® API Keyï¼ˆç¼–è¾‘ config.pyï¼‰\nnano config.py\n# ä¿®æ”¹ï¼š\nAPI_KEY = \"your-openai-key, your-qwen-key, your-xinghuo-key\"\nMODEL_PATH = \"./models/qwen2.5-7b-chat\"  # æœ¬åœ°æ¨¡å‹è·¯å¾„\n\n# 6. å¯åŠ¨æœåŠ¡\npython main.py --port 8080\n\n# è®¿é—®ï¼šhttp://localhost:8080\n```\n\n> ğŸ’¡ **æç¤º**ï¼šå¦‚é‡ `CUDA out of memory`ï¼Œåœ¨ `config.py` ä¸­è®¾ç½® `MAX_TOKENS=2048` å’Œ `GPU_ID=0`ã€‚\n\n---\n\n## ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n### åœºæ™¯ï¼šç¿»è¯‘ä¸€ç¯‡ LaTeX è®ºæ–‡æ‘˜è¦å¹¶æ¶¦è‰²ä¸ºè‹±æ–‡\n\n#### è¾“å…¥ï¼ˆç”¨æˆ·ç²˜è´´ï¼‰ï¼š\n```latex\n\\begin{abstract}\næœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å¤šæ— äººæœºååŒè·¯å¾„è§„åˆ’æ–¹æ³•ï¼Œé€šè¿‡æ„å»ºåŠ¨æ€å¥–åŠ±å‡½æ•°ï¼Œå®ç°äº†åœ¨å¤æ‚éšœç¢ç¯å¢ƒä¸‹çš„é«˜æ•ˆé¿éšœä¸ç›®æ ‡è¦†ç›–ã€‚\n\\end{abstract}\n```\n\n#### ç”¨æˆ·æ“ä½œï¼š\n1. é€‰ä¸­æ–‡æœ¬ â†’ ç‚¹å‡»æŒ‰é’® **â€œç¿»è¯‘å¹¶æ¶¦è‰²â€**ï¼ˆè‡ªå®šä¹‰æ’ä»¶ï¼‰\n2. æ¨¡å‹é€‰æ‹©ï¼š`Qwen2.5-7B` + `Claude3`\n3. è®¾ç½®å‚æ•°ï¼š`style=academic`, `target_lang=en`\n\n#### è¾“å‡ºï¼š\n```latex\n\\",
    "last_scanned": "2026-01-16T02:03:15.393344",
    "last_analyzed": "2026-01-15T08:55:25.284752",
    "screenshot": "static/screenshots/616372661.jpg",
    "ai_visual_summary": "æ ¹æ®æˆªå›¾å†…å®¹åˆ†æï¼Œè¯¥åº”ç”¨æ˜¯ä¸€ä¸ªä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æä¾›å®ç”¨åŒ–äº¤äº’æ¥å£çš„å¼€æºé¡¹ç›®ï¼Œå…¶æ ¸å¿ƒåŠŸèƒ½æ˜¯**ä¼˜åŒ–è®ºæ–‡é˜…è¯»ã€æ¶¦è‰²ä¸å†™ä½œä½“éªŒ**ã€‚ç•Œé¢è®¾è®¡é£æ ¼ä¸ºå…¸å‹çš„**æŠ€æœ¯æ–‡æ¡£/å¼€å‘è€…æ–‡æ¡£**ï¼Œä»¥æ¸…æ™°çš„Markdownæ ¼å¼å‘ˆç°ï¼ŒåŒ…å«å®‰è£…æ­¥éª¤ã€æŠ€æœ¯å…³é”®è¯ï¼ˆå¦‚Dockerã€LLMã€Pythonã€C++ã€PDFã€LaTeXï¼‰å’Œæ¨¡å—åŒ–åŠŸèƒ½è¯´æ˜ã€‚é¡¹ç›®æ”¯æŒæ¥å…¥å¤šç§ä¸»æµå¤§æ¨¡å‹ï¼ˆå¦‚ChatGPTã€é€šä¹‰åƒé—®ã€Claudeç­‰ï¼‰ï¼Œå¹¶æä¾›æœ¬åœ°æ¨¡å‹éƒ¨ç½²ã€å¤šæ¨¡å‹å¹¶è¡Œé—®è¯¢ã€ä»£ç æ’ä»¶ã€è‡ªå®šä¹‰å¿«æ·æŒ‰é’®ã€è®ºæ–‡ç¿»è¯‘ä¸æ€»ç»“ç­‰é«˜çº§åŠŸèƒ½ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "262296122",
    "name": "PaddleOCR",
    "full_name": "PaddlePaddle/PaddleOCR",
    "category": "llm_rag",
    "stars": 68102,
    "forks": 9655,
    "description": "Turn any PDF or image document into structured data for your AI. A powerful, lightweight OCR toolkit that bridges the gap between images/PDFs and LLMs. Supports 100+ languages.",
    "url": "https://github.com/PaddlePaddle/PaddleOCR",
    "homepage": "https://www.paddleocr.ai",
    "language": "Python",
    "topics": "[\"ai4science\", \"chineseocr\", \"document-parsing\", \"document-translation\", \"kie\", \"ocr\", \"paddleocr-vl\", \"pdf-extractor-rag\", \"pdf-parser\", \"pdf2markdown\", \"pp-ocr\", \"pp-structure\", \"rag\"]",
    "created_at": "2020-05-08T10:38:16Z",
    "updated_at": "2026-01-15T17:46:44Z",
    "readme_content": null,
    "ai_summary": "åŸºäºPaddlePaddleæ¡†æ¶å¼€å‘çš„OCRå·¥å…·åŒ…ï¼Œä¸“æ³¨äºå°†å›¾åƒ/PDFæ–‡æ¡£è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®å¹¶é›†æˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œæ”¯æŒå¤šè¯­è¨€è¯†åˆ«å’Œè½»é‡åŒ–éƒ¨ç½²ã€‚",
    "ai_tech_stack": "[\"PaddlePaddle\", \"Python\", \"Flask/FastAPI\", \"OpenCV\", \"OCR\\u6280\\u672f\"]",
    "ai_use_cases": "[\"PDF/\\u56fe\\u50cf\\u6587\\u6863\\u8f6c\\u6587\\u672c\", \"AI\\u5bf9\\u8bdd\\u7cfb\\u7edf\\u8f93\\u5165\\u89e3\\u6790\\u5de5\\u5177\", \"\\u591a\\u8bed\\u8a00\\u573a\\u666f\\u4e0b\\u7684\\u6587\\u5b57\\u8bc6\\u522b\\u4e0e\\u5904\\u7406\"]",
    "ai_difficulty": 3,
    "ai_quick_start": "pip install paddleocr && python -m paddleocr --version",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nPaddleOCR çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äº**ç«¯åˆ°ç«¯ã€å¤šè¯­è¨€ã€è½»é‡åŒ–ä¸å·¥ä¸šçº§æ¨ç†çš„æ— ç¼æ•´åˆ**ï¼Œè§£å†³äº†ä¸‰å¤§è¡Œä¸šç—›ç‚¹ï¼š\n\n1. **å¤šè¯­è¨€ OCR + è¯­ä¹‰ç»“æ„ç†è§£ä¸€ä½“åŒ–**ï¼šå¤šæ•°å¼€æºæ–¹æ¡ˆï¼ˆå¦‚ Tesseractã€EasyOCRï¼‰ä»…æä¾›æ–‡æœ¬è¯†åˆ«ï¼Œè€Œ PaddleOCR-VL æ¨¡å—ç›´æ¥è¾“å‡ºå¸¦è¯­ä¹‰æ ‡ç­¾çš„ç»“æ„åŒ–æ•°æ®ï¼ˆæ ‡é¢˜ã€æ®µè½ã€è¡¨æ ¼ã€å…¬å¼ã€é”®å€¼å¯¹ï¼‰ï¼Œä¸º LLM æä¾›å¯ç›´æ¥è§£æçš„è¾“å…¥ï¼Œæ— éœ€åå¤„ç†è§„åˆ™å¼•æ“ã€‚  \n2. **æ¨ç†æ€§èƒ½ç¢¾å‹çº§ä¼˜åŒ–**ï¼šåœ¨åŒç­‰ç²¾åº¦ä¸‹ï¼ŒPaddleOCR çš„ CPU æ¨ç†é€Ÿåº¦æ¯” Tesseract å¿« 3â€“5 å€ï¼Œä¸”æ”¯æŒ Paddle Inferenceã€ONNX Runtimeã€TensorRTã€OpenVINOã€Ascend NPU ç­‰å…¨æ ˆéƒ¨ç½²ï¼Œæ˜¯å”¯ä¸€ä¸€ä¸ªåœ¨å›½äº§èŠ¯ç‰‡ï¼ˆå¦‚ Kunlunxinï¼‰ä¸Šå®ç°é‡äº§çº§ä¼˜åŒ–çš„ OCR å·¥å…·åŒ…ã€‚  \n3. **PDF-to-Structure æ— ä¾èµ–é—­ç¯**ï¼šæ— éœ€ä¾èµ– Adobe Acrobat æˆ– Ghostscriptï¼Œé€šè¿‡ PDF é¡µé¢æ¸²æŸ“ + å¸ƒå±€åˆ†æï¼ˆPP-StructureV3ï¼‰ï¼Œç›´æ¥ä» PDF å­—èŠ‚æµè¾“å‡º Markdown/JSON ç»“æ„ï¼Œè§£å†³ä¼ä¸šæ–‡æ¡£æ•°å­—åŒ–ä¸­â€œæ— æ³•è„±ç¦»å•†ä¸šè½¯ä»¶â€çš„ç¡¬çº¦æŸã€‚\n\nç›¸æ¯” DocTRã€LayoutLMv3ã€Kraken ç­‰æ–¹æ¡ˆï¼ŒPaddleOCR åœ¨**éƒ¨ç½²æˆæœ¬ã€å¤šç¡¬ä»¶æ”¯æŒå¹¿åº¦ã€ä¸­æ–‡/å°è¯­ç§ç²¾åº¦ï¼ˆå°¤å…¶æ‰‹å†™ä½“ä¸å°åˆ·æ··æ’ï¼‰** ä¸Šå½¢æˆå‹å€’æ€§ä¼˜åŠ¿ã€‚\n\n---\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n1. **åŠ¨æ€æ–‡æœ¬æ–¹å‘æ£€æµ‹ + å¤šå°ºåº¦ç‰¹å¾èåˆ**ï¼š  \n   ä½¿ç”¨æ”¹è¿›çš„ DBNet++ æ£€æµ‹å™¨ï¼Œå¼•å…¥å¯å˜å½¢å·ç§¯ï¼ˆDeformable Convï¼‰å’Œ FPN é‡‘å­—å¡”å¢å¼ºï¼Œå¯¹å€¾æ–œã€å¼¯æ›²ã€ä½å¯¹æ¯”åº¦æ–‡æœ¬ï¼ˆå¦‚å‘ç¥¨ã€è¯ä»¶ï¼‰å¬å›ç‡æå‡ 18%+ã€‚\n\n2. **è¯­è¨€è‡ªé€‚åº”è¯†åˆ«å¤´ï¼ˆLanguage-Aware CRNNï¼‰**ï¼š  \n   åœ¨ CRNN æ¶æ„ä¸­åµŒå…¥è¯­è¨€åµŒå…¥å‘é‡ï¼ˆLanguage Embeddingï¼‰ï¼ŒåŠ¨æ€åˆ‡æ¢å­—ç¬¦é›†ä¸è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒ 100+ è¯­è¨€å…±äº«åŒä¸€æ¨¡å‹æƒé‡ï¼Œé¿å…â€œä¸€è¯­ä¸€æ¨¡å‹â€çš„èµ„æºæµªè´¹ã€‚\n\n3. **è½»é‡åŒ–æ¨¡å‹è’¸é¦ + æ··åˆç²¾åº¦é‡åŒ–**ï¼š  \n   ä½¿ç”¨çŸ¥è¯†è’¸é¦å°†å¤§å‹æ¨¡å‹ï¼ˆå¦‚ SVTR-Lï¼‰å‹ç¼©è‡³ <20MBï¼ŒINT8 é‡åŒ–åç²¾åº¦æŸå¤± <1%ï¼Œæ¨ç†å»¶è¿Ÿé™ä½ 65%ã€‚æ”¯æŒ Paddle Lite ç§»åŠ¨ç«¯éƒ¨ç½²ã€‚\n\n4. **PDF æ¸²æŸ“å¼•æ“åµŒå…¥å¼é›†æˆ**ï¼š  \n   å†…ç½®è½»é‡çº§ PDF è§£æå™¨ï¼ˆåŸºäº Poppler çš„è£å‰ªç‰ˆï¼‰ï¼Œç›´æ¥å°† PDF é¡µé¢è½¬ä¸ºé«˜ä¿çœŸå›¾åƒæµï¼Œè§„é¿äº†ä¾èµ–å¤–éƒ¨è¿›ç¨‹æˆ– GUI ç¯å¢ƒçš„è„†å¼±æ€§ã€‚\n\n5. **å¼‚æ„æ¨ç†æµæ°´çº¿è°ƒåº¦**ï¼š  \n   æ£€æµ‹ â†’ è¯†åˆ« â†’ ç»“æ„åŒ–ä¸‰é˜¶æ®µæ”¯æŒå¼‚æ­¥å¹¶è¡Œï¼ˆAsync Pipelineï¼‰ï¼Œåœ¨å¤š GPU / NPU åœºæ™¯ä¸‹å®ç°ååé‡ç¿»å€ï¼Œå»¶è¿Ÿä½äº 200ms/é¡µï¼ˆ1080pï¼‰ã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n#### 1. æ•´ä½“æ¶æ„å›¾ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\n[Input: PDF/Image] \n       â†“\n[Preprocessing] â†’ è‰²å½©æ ¡æ­£ã€äºŒå€¼åŒ–ã€å»å™ªï¼ˆå¯é€‰ OpenCV/CLIPï¼‰  \n       â†“\n[Text Detection] â†’ DBNet++ (åŠ¨æ€å·ç§¯ + FPN) â†’ ç”Ÿæˆæ–‡æœ¬æ¡†åæ ‡  \n       â†“\n[Text Recognition] â†’ SVTR/LCRNN (è¯­è¨€åµŒå…¥+Transformer) â†’ æ–‡æœ¬ä¸²  \n       â†“\n[Layout Analysis] â†’ PP-StructureV3 (åŸºäºYOLOv8çš„è¯­ä¹‰åˆ†å‰²) â†’ æ ‡ç­¾ï¼šæ ‡é¢˜/æ®µè½/è¡¨æ ¼/å…¬å¼/K-Vå¯¹  \n       â†“\n[Post-processing & Structured Output] â†’ JSON/MARKDOWN/HTMLï¼ˆå«åæ ‡ã€å±‚çº§ã€ç½®ä¿¡åº¦ï¼‰  \n       â†“\n[Output: LLM-ready Structure]\n```\n\n#### 2. æ ¸å¿ƒæ¨¡å—åˆ’åˆ†\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| `PaddleOCR` ä¸»å…¥å£ | ç»Ÿä¸€è°ƒåº¦æ£€æµ‹/è¯†åˆ«/ç»“æ„åŒ–ï¼Œæ”¯æŒæ¨¡å‹çƒ­åˆ‡æ¢ |\n| `DBNet++` | é«˜ç²¾åº¦æ–‡æœ¬æ¡†æ£€æµ‹ï¼Œè¾“å‡ºå¤šè¾¹å½¢åæ ‡ |\n| `SVTR/LCRNN` | æ–‡æœ¬è¯†åˆ«ï¼Œæ”¯æŒè¯­è¨€åµŒå…¥ã€é•¿åºåˆ—å»ºæ¨¡ |\n| `PP-StructureV3` | å¸ƒå±€åˆ†ææ¨¡å—ï¼ˆç‹¬ç«‹æ¨¡å‹ï¼‰ï¼Œè¾“å‡ºè¯­ä¹‰åŒºåŸŸæ ‡ç­¾ |\n| `PDF2Image` | æ— ä¾èµ– PDF æ¸²æŸ“å™¨ï¼Œæ”¯æŒåˆ†é¡µã€DPI æ§åˆ¶ |\n| `Paddle Inference Engine` | å¤šåç«¯æ¨ç†æ ¸å¿ƒï¼ˆCPU/GPU/XPU/NPUï¼‰ |\n| `Converter` | JSON/Markdown/HTML è¾“å‡ºé€‚é…å±‚ |\n\n#### 3. æ•°æ®æµå‘\n\n```\nPDF/Image â†’ (Preprocess) â†’ Detection Boxes â†’ Crop Regions â†’ Recognition â†’ Layout Tagging â†’ Structured Output\n                              â†“                    â†“                   â†“\n                       [DBNet++]             [SVTR]            [YOLOv8-Layout]\n```\n\n#### 4. å…³é”®è®¾è®¡æ¨¡å¼\n\n- **ç­–ç•¥æ¨¡å¼ï¼ˆStrategy Patternï¼‰**ï¼šæ£€æµ‹/è¯†åˆ«æ¨¡å‹å¯åŠ¨æ€åˆ‡æ¢ï¼ˆå¦‚ DB++ã€EASTã€CRNNã€SVTRï¼‰ï¼Œé€šè¿‡ `--det_model_name` å‚æ•°å®ç°è¿è¡Œæ—¶æ’æ‹”ã€‚\n- **å·¥å‚æ¨¡å¼ï¼ˆFactory Patternï¼‰**ï¼š`OCRSystem` ç±»æ ¹æ®é…ç½®å®ä¾‹åŒ–ä¸åŒåç«¯å¼•æ“ï¼ˆONNX / TensorRT / Paddle Inferenceï¼‰ã€‚\n- **ç®¡é“æ¨¡å¼ï¼ˆPipeline Patternï¼‰**ï¼šä¸‰é˜¶æ®µä¸²è¡Œå¤„ç†ï¼Œæ¯é˜¶æ®µå¯ç‹¬ç«‹å¹¶è¡Œæˆ–å¼‚æ­¥ï¼Œæ”¯æŒè‡ªå®šä¹‰ä¸­é—´ç¼“å­˜ã€‚\n- **é€‚é…å™¨æ¨¡å¼ï¼ˆAdapter Patternï¼‰**ï¼šç»Ÿä¸€è¾“å‡ºæ¥å£ `OCRResult`ï¼Œå…¼å®¹ JSONã€Markdownã€HTML ä¸‰ç§æ ¼å¼ï¼Œä¾¿äºå¯¹æ¥ LLM APIã€‚\n\n> è®¾è®¡å“²å­¦ï¼š**â€œæ¨¡å—è§£è€¦ + æ¨ç†å¯æ’æ‹”â€** â€”â€” ä¸ç»‘å®šç‰¹å®šæ¨¡å‹ï¼Œè€Œæ˜¯ç»‘å®šæ ‡å‡†æ¥å£ï¼Œæå¤§æå‡çµæ´»æ€§ä¸æ¼”è¿›èƒ½åŠ›ã€‚\n\n---\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| æŠ€æœ¯ | é€‰å‹ç†ç”± | æ›¿ä»£æ–¹æ¡ˆ | æ³¨æ„äº‹é¡¹ |\n|------|----------|----------|----------|\n| **PaddlePaddle** | å›½äº§æ¡†æ¶ï¼Œå¯¹ NPU/XPU åŸç”Ÿæ”¯æŒæä½³ï¼›æ¨ç†å¼•æ“è½»é‡ï¼ˆ<100MBï¼‰ï¼›åŠ¨æ€å›¾/é™æ€å›¾è‡ªç”±åˆ‡æ¢ | TensorFlow Lite, ONNX Runtime | éœ€å®‰è£… `paddlepaddle-gpu` æˆ– `paddlepaddle`ï¼Œé¿å…ä½¿ç”¨ç³»ç»Ÿ pip çš„æ—§ç‰ˆ |\n| **SVTR** | Transformer æ¶æ„åœ¨é•¿æ–‡æœ¬ã€ä½è´¨é‡å›¾åƒä¸Šè¡¨ç°è¿œè¶… CRNNï¼›æ”¯æŒå¤šè¯­è¨€å­—ç¬¦é›†ï¼ˆ100+ï¼‰ | RARE, ABINet | æ¨¡å‹ä½“ç§¯å¤§ï¼ˆ~40MBï¼‰ï¼Œå»ºè®®é‡åŒ–åéƒ¨ç½² |\n| **DBNet++** | åœ¨ ICDAR2015 ä¸Š mAP è¾¾ 87.6%ï¼Œä¼˜äº EASTã€CRAFTï¼›æ”¯æŒä»»æ„å››è¾¹å½¢æ£€æµ‹ | CRAFT (æ›´å‡†ä½†æ…¢), TextBoxes++ | å¯¹å°å­—ï¼ˆ<12ptï¼‰æ•æ„Ÿï¼Œéœ€é¢„æ”¾å¤§æˆ–è°ƒæ•´ `det_db_box_thresh` |\n| **ONNX / TensorRT / OpenVINO** | æ”¯æŒå¯¼å‡ºåéƒ¨ç½²åˆ°è¾¹ç¼˜è®¾å¤‡ï¼›PaddleOCR æä¾›ä¸€é”®è½¬æ¢è„šæœ¬ | CoreML (ä»… macOS), TFLite | ONNX å¯¼å‡ºæ—¶æ³¨æ„ `input_shape` å¿…é¡»å›ºå®šï¼ˆä¸èƒ½åŠ¨æ€ batchï¼‰ |\n| **OpenCV** | é¢„å¤„ç†ç®¡çº¿ä¾èµ–ï¼ˆå›¾åƒç¼©æ”¾ã€ç°åº¦åŒ–ï¼‰ï¼Œè½»é‡å¯é  | scikit-image, PIL | ä¸ Paddle çš„ CUDA å†…å­˜ä¸å…±ç”¨ï¼Œéœ€ `cv2.cvtColor()` æ˜¾å¼è½¬æ¢ BGRâ†’RGB |\n\n> ğŸ’¡ å…³é”®å»ºè®®ï¼šç”Ÿäº§ç¯å¢ƒåŠ¡å¿…ä½¿ç”¨ **Paddle Inference** è€Œé Python APIï¼ˆ`ocr.ocr()`ï¼‰ï¼Œæ€§èƒ½æå‡ 3â€“5xã€‚\n\n---\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# âœ… æ¨èå®‰è£…ï¼ˆå« GPU æ”¯æŒï¼‰\npip install \"paddlepaddle-gpu>=2.6.0\" -i https://pypi.tuna.tsinghua.edu.cn/simple\n\n# å®‰è£… PaddleOCR åŒ…ï¼ˆè‡ªåŠ¨ä¾èµ–æ¨¡å‹ä¸‹è½½ï¼‰\npip install paddleocr --upgrade\n\n# âœ… éªŒè¯å®‰è£…\npython -c \"from paddleocr import PaddleOCR; ocr = PaddleOCR(); print('OK')\"\n```\n\n> ğŸš« é¿å‘ï¼šä¸è¦ç”¨ `pip install paddleocr` + `paddlepaddle`ï¼ˆCPU ç‰ˆï¼‰åœ¨ GPU ç¯å¢ƒä¸‹è·‘ï¼Œä¼šæ…¢ 10 å€ã€‚\n\n**é…ç½®æ–‡ä»¶**ï¼ˆå¯é€‰ï¼‰ï¼š\n```yaml\n# ~/.paddleocr/config.yaml\nglobal:\n  use_gpu: true\n  gpu_mem: 4096    # åˆ†é…æ˜¾å­˜ï¼ˆMBï¼‰\n  lang: \"ch\"\n  det_model_dir: \"./inference/det_db/\"   # è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„\n  rec_model_dir: \"./inference/rec_crnn/\"\n```\n\n---\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n```python\nfrom paddleocr import PaddleOCR, draw_ocr\n\n# åˆå§‹åŒ–ï¼šæ”¯æŒä¸­æ–‡+è‹±æ–‡ï¼Œä½¿ç”¨è½»é‡çº§æ£€æµ‹+è¯†åˆ«æ¨¡å‹\nocr = PaddleOCR(\n    use_angle_cls=True,      # è‡ªåŠ¨æ—‹è½¬æ ¡æ­£ï¼ˆæ¨èå¼€å¯ï¼‰\n    lang=\"ch\",               # æ”¯æŒ ch, en, fr, ar, ja, ko ç­‰ 100+\n    det_model_name=\"db_mv3\",\n    rec_model_name=\"crnn\",\n    use_gpu=True,\n    show_log=False\n)\n\n# è¾“å…¥ï¼šæ‰«æç‰ˆå‘ç¥¨ PDFï¼ˆè½¬ä¸º PNGï¼‰\nimage_path = \"invoice.png\"\n\n# æ‰§è¡Œ OCR\nresult = ocr.ocr(image_path, cls=True)\n\n# è¾“å‡ºç»“æ„ï¼š\nfor line in result[0]:\n    bbox, (text, conf) = line  # bbox: [[x1,y1], [x2,y2], ...] å››ç‚¹åæ ‡\n    print(f\"Text: '{text}' | Confidence: {conf:.3f} | BBox: {bbox}\")\n\n# é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼š\n# Text: 'å‘ç¥¨å·ç ï¼šF2024-0891' | Confidence: 0.987 | BBox: [[102, 56], [310, 58], [310, 78], [102, 76]]\n# Text: 'é‡‘é¢ï¼šÂ¥1,245.50'     | Confidence: 0.991 | BBox: [[105, 90], [280, 92], [280, 110], [105, 108]]\n```\n\n> âœ… **çœŸå®åœºæ™¯ä»·å€¼**ï¼šè¯¥è¾“å‡ºå¯ç›´æ¥å–‚å…¥ LLMï¼ˆå¦‚ Qwenï¼‰åšç»“æ„åŒ–æŠ½å–ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚\n\n---\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n| æ¨¡å‹ | è¾“å…¥åˆ†è¾¨ç‡ | GPU (RTX 4090) | CPU (i7-13700K) | å†…å­˜å ç”¨ |\n|------|------------|----------------|------------------|----------|\n| DB+CRNN | 1920Ã—1080 | **28 FPS** | 6.5 FPS | ~1.2 GB |\n| PP-StructureV3 (ç«¯åˆ°ç«¯) | A4 PDF | 12 FPS | 2.8 FPS | ~2.1 GB |\n\n**æ€§èƒ½ç“¶é¢ˆ**ï¼š\n- æ–‡æœ¬æ£€æµ‹ï¼ˆDBï¼‰æ˜¯ CPU ä¸Šçš„ä¸»ç“¶é¢ˆ â†’ ä½¿ç”¨ `db_mv3` æ›¿ä»£ `resnet50_vd` å¯æé€Ÿ 3xã€‚\n- å¤šè¯­è¨€è¯†åˆ«æ¨¡å‹ä½“ç§¯å¤§ â†’ æŒ‰éœ€åŠ è½½ï¼ˆå¦‚åªç”¨ä¸­æ–‡ï¼Œç¦ç”¨è‹±æ–‡æ¨¡å‹ï¼‰ã€‚\n\n**ç”Ÿäº§éƒ¨ç½²å»ºè®®**ï¼š\n1. **å¹¶å‘ä¼˜åŒ–**ï¼šä½¿ç”¨ `paddle.inference` + å¤šè¿›ç¨‹ï¼ˆæ¯ä¸ªè¿›ç¨‹ä¸€ä¸ª OCR å®ä¾‹ï¼‰\n2. **åŠ é€Ÿæ–¹æ¡ˆ**ï¼šå¯¼å‡º ONNX â†’ TensorRT é‡åŒ–ï¼ˆINT8ï¼‰ï¼Œå¯æé€Ÿ 40â€“60%\n3. **ç¼“å­˜ç­–ç•¥**ï¼šå¯¹åŒä¸€ PDF çš„ç›¸åŒé¡µé¢åšå“ˆå¸Œç¼“å­˜ï¼Œé¿å…é‡å¤ OCR\n\n---\n\n### ğŸ”Œ äºŒæ¬¡å¼€å‘æŒ‡å—\n\n#### æ‰©å±•ç‚¹ï¼š\n1. **è‡ªå®šä¹‰æ£€æµ‹å™¨**ï¼šæ›¿æ¢ `db_mv3` â†’ è‡ªå·±è®­ç»ƒçš„ DBNetï¼ˆåŸºäº PaddleDetectionï¼‰\n2. **åå¤„ç†**ï¼šé‡å†™ `rec_postprocess.py` å®ç°ä¼ä¸šä¸“æœ‰å­—ç¬¦é›†ï¼ˆå¦‚è´¢åŠ¡ç¼–ç ï¼‰\n3. **ç»“æ„åŒ–æŠ½å–**ï¼šé›†æˆ LayoutLMv3ï¼Œè¾“å‡º HTML è¡¨æ ¼/JSON Schema\n\n#### API å…³é”®æ¥å£ï¼š\n```python\nocr = PaddleOCR(...)\nresult = ocr.ocr(img, cls=True)          # è¿”å› [[bbox], [text, score]]\n# result ç»“æ„: List[List[ [bbox], (text, confidence) ]]\n\n# è·å–æ£€æµ‹æ¡†ï¼ˆä¸è¯†åˆ«ï¼‰\ndet_only = ocr.ocr(img, rec=False)\n\n# è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„\nocr = PaddleOCR(det_model_dir=\"./my_det\", rec_model_dir=\"./my_rec\")\n```\n\n#### æ·»åŠ æ–°è¯­è¨€ï¼š\n1. ä¸‹è½½å¯¹åº” `rec` æ¨¡å‹æƒé‡ï¼ˆ[å®˜æ–¹æ¨¡å‹åº“](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_en/models_list.md)ï¼‰\n2. è®¾ç½® `lang=\"your_lang\"`ï¼Œç¡®ä¿å­—å…¸æ–‡ä»¶ `.txt` åœ¨ `ppocr/utils/dict/`\n\n---\n\n### â— å¸¸è§é—®é¢˜ä¸é¿å‘\n\n1. **Qï¼šå®‰è£…æŠ¥é”™ `paddlepaddle not found`ï¼Ÿ**  \n   Aï¼šä½¿ç”¨ `pip install paddlepaddle-gpu -f https://www.paddlepaddle.org.cn/install/quick",
    "last_scanned": "2026-01-16T02:03:15.395635",
    "last_analyzed": "2026-01-15T09:21:23.475416",
    "screenshot": "static/screenshots/262296122.jpg",
    "ai_visual_summary": "è¯¥æˆªå›¾å±•ç¤ºäº†ä¸€ä¸ªåä¸º PaddleOCR çš„å¼€æºé¡¹ç›®æ–‡æ¡£ï¼Œå…¶ç•Œé¢é£æ ¼ç®€æ´ã€åŠŸèƒ½å¯¼å‘ï¼Œå±äºå…¸å‹çš„å¼€å‘è€…æ–‡æ¡£ï¼ˆå¦‚ GitHub READMEï¼‰ã€‚ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬ä»£ç ç¤ºä¾‹ï¼ˆå¦‚ PP-StructureV3ã€PaddleOCR-VLï¼‰ã€æ¨¡å‹åŠ é€Ÿï¼ˆæ”¯æŒåä¸º Ascendã€KUNLUNXINï¼‰å’Œé«˜çº§æ•™ç¨‹ã€‚å…³é”®æŠ€æœ¯å…³é”®è¯åŒ…æ‹¬ PaddleOCRã€ONNXã€OpenVINOã€TensorRTã€å¤š GPU/å¤šè¿›ç¨‹æ¨ç†ç­‰ã€‚è¯¥åº”ç”¨æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ã€è½»é‡çº§çš„å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰å·¥å…·åŒ…ï¼Œæ—¨åœ¨å°†PDFå’Œå›¾åƒæ–‡æ¡£è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®ï¼Œä»¥ä¾›äººå·¥æ™ºèƒ½ï¼ˆç‰¹åˆ«æ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼‰ä½¿ç”¨ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "599547518",
    "name": "vllm",
    "full_name": "vllm-project/vllm",
    "category": "llm_rag",
    "stars": 67599,
    "forks": 12617,
    "description": "A high-throughput and memory-efficient inference and serving engine for LLMs",
    "url": "https://github.com/vllm-project/vllm",
    "homepage": "https://vllm.ai",
    "language": "Python",
    "topics": "[\"amd\", \"blackwell\", \"cuda\", \"deepseek\", \"deepseek-v3\", \"gpt\", \"gpt-oss\", \"inference\", \"kimi\", \"llama\", \"llm\", \"llm-serving\", \"model-serving\", \"moe\", \"openai\", \"pytorch\", \"qwen\", \"qwen3\", \"tpu\", \"transformer\"]",
    "created_at": "2023-02-09T11:23:20Z",
    "updated_at": "2026-01-15T17:28:31Z",
    "readme_content": null,
    "ai_summary": "ä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹è®¾è®¡çš„é«˜æ€§èƒ½æ¨ç†å¼•æ“ï¼Œé‡‡ç”¨PagedAttentionç­‰åˆ›æ–°æŠ€æœ¯å®ç°è¶…é«˜ååé‡ä¸ä½å»¶è¿Ÿå¹¶ä¼˜åŒ–ç¡¬ä»¶å…¼å®¹æ€§",
    "ai_tech_stack": "[\"Python\", \"CUDA/HIP kernels\", \"FastAPI\", \"PyTorch\", \"\\u5206\\u5e03\\u5f0f\\u8ba1\\u7b97\\u6846\\u67b6\\uff08tensor/pipeline/expert parallelism\\uff09\"]",
    "ai_use_cases": "[\"\\u4f01\\u4e1a\\u7ea7AI API\\u90e8\\u7f72\\u4e0e\\u8c03\\u7528\", \"\\u5b9e\\u65f6\\u804a\\u5929\\u673a\\u5668\\u4eba\\u670d\\u52a1\\u7aef\\u5b9e\\u73b0\", \"\\u5927\\u89c4\\u6a21RAG\\u7cfb\\u7edf\\u63a8\\u7406\\u52a0\\u901f\", \"\\u591a\\u6a21\\u6001\\u5927\\u8bed\\u8a00\\u6a21\\u578b\\u5e94\\u7528\\u5f00\\u53d1\", \"\\u8fb9\\u7f18\\u8ba1\\u7b97\\u573a\\u666f\\u4e0b\\u7684\\u9ad8\\u6548\\u63a8\\u7406\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "pip install vllm && python -m vllm.serve.api --model /path/to/model --tokenizer /path/to/tokenizer --port 8000",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nvLLM çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äº**å½»åº•é‡æ„äº† LLM æ¨ç†çš„å†…å­˜ç®¡ç†èŒƒå¼**ï¼Œé€šè¿‡ PagedAttention è§£å†³äº†ä¼ ç»Ÿæ³¨æ„åŠ›æœºåˆ¶åœ¨åŠ¨æ€æ‰¹å¤„ç†ï¼ˆcontinuous batchingï¼‰åœºæ™¯ä¸‹å› éè¿ç»­ KV ç¼“å­˜å¯¼è‡´çš„ä¸¥é‡å†…å­˜ç¢ç‰‡ä¸ä½åˆ©ç”¨ç‡é—®é¢˜ã€‚ç›¸æ¯” Hugging Face Transformers + Text Generation Inference (TGI)ã€TensorRT-LLM æˆ– FasterTransformer ç­‰æ–¹æ¡ˆï¼š\n\n- **æ— ç¢ç‰‡åŒ– KV ç¼“å­˜**ï¼šä¼ ç»Ÿç³»ç»Ÿä¸ºæ¯ä¸ªè¯·æ±‚åˆ†é…ç‹¬ç«‹è¿ç»­å†…å­˜å—ï¼Œå½“åºåˆ—é•¿åº¦ä¸å‡æˆ–åŠ¨æ€ç”Ÿæˆæ—¶ï¼Œå¤§é‡å†…å­˜è¢«â€œç©ºæ´â€æµªè´¹ï¼ˆå¦‚ 80% çš„ block åªç”¨äº† 20%ï¼‰ã€‚vLLM å°† KV ç¼“å­˜åˆ‡åˆ†ä¸ºå›ºå®šå¤§å°çš„é¡µï¼ˆpageï¼‰ï¼Œåƒæ“ä½œç³»ç»Ÿè™šæ‹Ÿå†…å­˜ä¸€æ ·è¿›è¡Œéè¿ç»­åˆ†é…ä¸é€»è¾‘æ‹¼æ¥ã€‚\n- **çœŸæ­£çš„åŠ¨æ€æ‰¹å¤„ç†**ï¼šæ”¯æŒä»»æ„é•¿åº¦ã€ä»»æ„é‡‡æ ·æ­¥æ•°çš„è¯·æ±‚åœ¨åŒä¸€ä¸ª batch ä¸­å¹¶å‘æ‰§è¡Œï¼Œæ— éœ€ç­‰å¾…æœ€æ…¢è¯·æ±‚å®Œæˆã€‚TGI ç­‰æ–¹æ¡ˆä»å—é™äºâ€œbatch å†…æœ€é•¿åºåˆ—å†³å®šæ‰€æœ‰è¯·æ±‚çš„ padding é•¿åº¦â€ã€‚\n- **ååé‡ç¢¾å‹çº§ä¼˜åŠ¿**ï¼šåœ¨ç›¸åŒç¡¬ä»¶ä¸‹ï¼ŒvLLM çš„ååé‡æ¯” Hugging Face Transformers é«˜ 24xï¼ˆè®ºæ–‡æ•°æ®ï¼‰ï¼Œæ¯” TGI é«˜ 3â€“5xï¼Œä¸”å»¶è¿Ÿæ›´ä½ã€‚\n\nå®ƒä¸æ˜¯â€œåˆä¸€ä¸ªåŠ é€Ÿæ¨ç†çš„åº“â€ï¼Œè€Œæ˜¯é‡æ–°å®šä¹‰äº† LLM Serving çš„å†…å­˜åº•å±‚ç»“æ„â€”â€”**å°† GPU æ˜¾å­˜ä»â€œé™æ€åˆ†é…çš„æ•°ç»„â€å˜ä¸ºâ€œåŠ¨æ€ç®¡ç†çš„ç¼“å­˜æ± â€**ï¼Œè¿™æ˜¯å·¥ç¨‹ä¸Šçš„ä¸€æ¬¡èŒƒå¼è¿ç§»ã€‚\n\n---\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n1. **PagedAttention**  \n   - å°†æ¯ä¸ªè¯·æ±‚çš„ KV ç¼“å­˜åˆ’åˆ†ä¸ºå¤§å°å›ºå®šçš„ `page`ï¼ˆé»˜è®¤ 16 tokensï¼‰ï¼Œæ¯é¡µç‹¬ç«‹åˆ†é…åœ¨æ˜¾å­˜ä¸­ã€‚\n   - æ¯ä¸ªåºåˆ—ç»´æŠ¤ä¸€ä¸ªâ€œé€»è¾‘é¡µè¡¨â€ï¼Œæ˜ å°„åˆ°ç‰©ç†é¡µåœ°å€ï¼Œå®ç°éè¿ç»­å†…å­˜çš„è¿ç»­è¯­ä¹‰è®¿é—®ã€‚\n   - æ”¯æŒ**å…±äº«å‰ç¼€ç¼“å­˜**ï¼šå¤šä¸ªè¯·æ±‚è‹¥å…·æœ‰ç›¸åŒ prompt å‰ç¼€ï¼ˆå¦‚ç³»ç»Ÿæç¤ºè¯ï¼‰ï¼Œåˆ™å…±äº«å…¶ KV é¡µï¼ŒèŠ‚çœ 30â€“70% æ˜¾å­˜ã€‚\n   - **åŠ¨æ€æ‰©å±•**ï¼šç”Ÿæˆæ—¶æŒ‰éœ€åˆ†é…æ–°é¡µï¼Œæ— éœ€é¢„åˆ†é…æœ€å¤§é•¿åº¦ã€‚\n\n2. **è¿ç»­æ‰¹å¤„ç†ï¼ˆContinuous Batchingï¼‰ + Chunked Prefill**  \n   - ä¸åŒäºä¼ ç»Ÿâ€œé™æ€ batchâ€ï¼ˆå¦‚ TGIï¼‰ï¼ŒvLLM çš„è°ƒåº¦å™¨å…è®¸æ–°è¯·æ±‚éšæ—¶æ’å…¥æ­£åœ¨è¿è¡Œçš„ batch ä¸­ã€‚\n   - Chunked Prefillï¼šé•¿ prompt æ‹†åˆ†ä¸ºå¤šä¸ª chunk åˆ†æ‰¹é¢„å¡«å……ï¼Œé¿å… OOM ä¸”æå‡ GPU åˆ©ç”¨ç‡ã€‚å°¤å…¶é€‚ç”¨äº 32K+ ä¸Šä¸‹æ–‡åœºæ™¯ã€‚\n\n3. **CUDA/HIP Graph + Tensor Core ä¼˜åŒ–**  \n   - ä½¿ç”¨ CUDA Graph æ•è·æ•´ä¸ªæ¨ç†å‰å‘ä¼ æ’­æµç¨‹ï¼ˆåŒ…æ‹¬æ³¨æ„åŠ›ã€FFNã€é‡‡æ ·ï¼‰ï¼Œæ¶ˆé™¤å†…æ ¸å¯åŠ¨å¼€é”€ã€‚\n   - é›†æˆ FlashAttention-2 å’Œ FlashInferï¼Œå®ç°é«˜æ•ˆ softmax + attention è®¡ç®—ï¼Œåˆ©ç”¨ Tensor Core åŠ é€Ÿ FP16/BF16 çŸ©é˜µä¹˜ã€‚\n\n4. **å¤š LoRA æ”¯æŒ**  \n   - åœ¨åŒä¸€æ¨¡å‹å®ä¾‹ä¸­å¹¶è¡ŒåŠ è½½å¤šä¸ª LoRA é€‚é…å™¨ï¼ˆå¦‚ä¸åŒå®¢æˆ·å¾®è°ƒç‰ˆæœ¬ï¼‰ï¼Œé€šè¿‡åŠ¨æ€æƒé‡èåˆå®ç°æ¯«ç§’çº§åˆ‡æ¢ï¼Œæ— éœ€é‡å¯æœåŠ¡ã€‚\n\n5. **Speculative Decoding é›†æˆ**  \n   - åŸç”Ÿæ”¯æŒå°æ¨¡å‹ï¼ˆdraft modelï¼‰åŠ é€Ÿå¤§æ¨¡å‹ç”Ÿæˆï¼Œæ˜¾è‘—é™ä½å»¶è¿Ÿï¼ˆå°¤å…¶åœ¨é•¿æ–‡æœ¬åœºæ™¯ä¸‹æå‡ 2â€“4xï¼‰ã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n#### æ•´ä½“æ¶æ„ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\nClient â†’ [HTTP/gRPC Server] â†’ [Request Scheduler]\n                              â†“\n                   [PagedAttention KV Cache Manager]\n                              â†“\n               [Worker (CUDA/HIP Kernel Executor)]\n                 /        |         \\\n       [Model Loader]  [Sampler]   [Prefill/Decode Engine]\n            |             |\n      [HuggingFace Model] [FlashInfer/FlashAttn]\n```\n\n#### æ ¸å¿ƒæ¨¡å—èŒè´£\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| **LLMEngine** | ä¸»æ§å¼•æ“ï¼Œåè°ƒè°ƒåº¦å™¨ã€æ‰§è¡Œå™¨å’Œç¼“å­˜ç®¡ç†å™¨ï¼Œæš´éœ² OpenAI API æ¥å£ |\n| **Request Scheduler** | åŠ¨æ€å†³å®šå“ªäº›è¯·æ±‚è¿›å…¥å½“å‰ batchï¼Œå¤„ç†ä¼˜å…ˆçº§ã€ä¸­æ–­ã€ç»­ä¼ ï¼ˆå¦‚ streamingï¼‰ |\n| **PagedAttention KV Cache Manager** | æ ¸å¿ƒï¼šåˆ†é…/é‡Šæ”¾/æ˜ å°„é€»è¾‘é¡µ â†’ ç‰©ç†é¡µï¼›ç»´æŠ¤æ¯ä¸ªåºåˆ—çš„é¡µè¡¨ï¼›æ”¯æŒå…±äº«å‰ç¼€ |\n| **Worker** | å®é™…æ‰§è¡Œæ¨¡å‹æ¨ç†ï¼Œè°ƒç”¨ CUDA å›¾ + æ³¨æ„åŠ›æ ¸ + é‡åŒ–å†…æ ¸ |\n| **Model Loader** | æŒ‰éœ€åŠ è½½ Hugging Face æ¨¡å‹æƒé‡ï¼ˆæ”¯æŒ GGUFã€GPTQã€AWQã€FP8ï¼‰ |\n| **Sampler** | å¤„ç†é‡‡æ ·é€»è¾‘ï¼štop-p, top-k, beam search, parallel samplingï¼Œè¾“å‡º token + logprobs |\n\n#### æ•°æ®æµå‘\n\n```\nHTTP POST /v1/completions\n        â†“ (JSON: prompt, max_tokens, temperature...)\n[Request Scheduler] â†’ åˆ†é…è¯·æ±‚ IDï¼Œåˆ›å»ºç©º KV é¡µè¡¨\n        â†“\n[Chunked Prefill]ï¼ˆè‹¥ prompt > é˜ˆå€¼ï¼‰â†’ å°† prompt åˆ‡ä¸º chunkï¼Œé€å—æ‰§è¡Œæ¨¡å‹å‰å‘\n        â†“\n[Decode Engine] â†’ æ¯è½®ç”Ÿæˆä¸€ä¸ª tokenï¼š\n    - å–å‡ºå½“å‰åºåˆ—çš„æœ€æ–° token\n    - æŸ¥æ‰¾å…¶å¯¹åº” KV é¡µï¼ˆé€»è¾‘é¡µè¡¨ â†’ ç‰©ç†åœ°å€ï¼‰\n    - è¾“å…¥æ¨¡å‹ï¼š[token_id, position_ids, page_table]\n    - æ‰§è¡Œ FlashInfer + MLP + LayerNorm\n    - é‡‡æ · â†’ æ–° token\n    - åˆ†é…æ–° KV é¡µå¹¶æ›´æ–°é¡µè¡¨\n        â†“\n[Streaming] â†’ æŒç»­è¿”å›ç”Ÿæˆçš„ tokenï¼ˆJSON Streamï¼‰\n```\n\n#### å…³é”®è®¾è®¡æ¨¡å¼\n\n- **ç­–ç•¥æ¨¡å¼**ï¼šé‡‡æ ·ç®—æ³•ï¼ˆtop-p, beam, parallelï¼‰å°è£…ä¸ºç‹¬ç«‹ç±»ï¼Œå¯æ’æ‹”ã€‚\n- **å·¥å‚æ¨¡å¼**ï¼šæ¨¡å‹åŠ è½½å™¨æ ¹æ®æ–‡ä»¶æ ¼å¼ï¼ˆsafetensors, GPTQ, AWQï¼‰åŠ¨æ€åˆ›å»ºå¯¹åº”é‡åŒ–è§£ç å™¨ã€‚\n- **å‘å¸ƒ-è®¢é˜…**ï¼šè°ƒåº¦å™¨ä¸ worker é€šè¿‡å¼‚æ­¥é˜Ÿåˆ—é€šä¿¡ï¼Œå®ç°é«˜å¹¶å‘è§£è€¦ã€‚\n- **äº«å…ƒæ¨¡å¼**ï¼šå…±äº«å‰ç¼€ç¼“å­˜ â€”â€” å¤šä¸ªè¯·æ±‚å¤ç”¨åŒä¸€ç»„ KV é¡µï¼Œå‡å°‘å†…å­˜å ç”¨ã€‚\n\n> è®¾è®¡å“²å­¦ï¼š**å°†â€œçŠ¶æ€â€ï¼ˆKV ç¼“å­˜ï¼‰ä»æ¨¡å‹è®¡ç®—ä¸­å½»åº•åˆ†ç¦»ç®¡ç†**ï¼Œæ˜¯ç³»ç»Ÿå¯æ‰©å±•ã€é«˜ååçš„æ ¹æœ¬åŸå› ã€‚\n\n---\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| ç»„ä»¶ | ä½œç”¨ | æ›¿ä»£æ–¹æ¡ˆ | é€‰æ‹©ç†ç”± |\n|------|------|----------|----------|\n| **PyTorch + CUDA/HIP** | æ ¸å¿ƒè®¡ç®—æ¡†æ¶ | TensorFlow, JAX | PyTorch ç”Ÿæ€æˆç†Ÿï¼Œæ”¯æŒåŠ¨æ€å›¾ï¼ˆé€‚åˆè¿ç»­æ‰¹å¤„ç†ï¼‰ï¼ŒHIP å…¼å®¹ AMD GPU |\n| **FlashAttention-2 / FlashInfer** | é«˜æ•ˆæ³¨æ„åŠ›æ ¸ | Triton è‡ªå®ç°ã€CUTLASS | ä¸“ä¸ºå˜é•¿åºåˆ—ä¼˜åŒ–ï¼Œæ˜¾å­˜è®¿é—®æ¨¡å¼æœ€ä¼˜ï¼Œå·²é’ˆå¯¹ A100/H100 æ·±åº¦è°ƒä¼˜ |\n| **Hugging Face Transformers** | æ¨¡å‹åŠ è½½ä¸é…ç½® | Custom model loader | å…¼å®¹æ€§ä¼˜å…ˆï¼šæ”¯æŒ 2000+ æ¨¡å‹æ— éœ€é‡å†™æ¶æ„ |\n| **FastAPI + Uvicorn** | HTTP Server | Tornado, gRPC | è½»é‡ã€å¼‚æ­¥ã€åŸç”Ÿæ”¯æŒ OpenAI API åè®® |\n| **PyTorch Quantization (GPTQ/AWQ)** | æƒé‡é‡åŒ– | TensorRT-LLM é‡åŒ– | å¼€æºå¯å¤ç°ï¼Œæ— éœ€ç¼–è¯‘ï¼Œæ”¯æŒ Hugging Face æ¥å£æ— ç¼åˆ‡æ¢ |\n| **vLLM Custom Kernels** | KV ç¼“å­˜ç®¡ç†ã€é‡‡æ ·å™¨ã€é¡µè¡¨æ“ä½œ | C++/CUDA åŸç”Ÿå®ç° | Python èƒ½åŠ›è¶³å¤Ÿï¼ŒNumba/Cython æ— æ³•è¦†ç›–å…¨éƒ¨è°ƒåº¦é€»è¾‘ï¼Œä¸” Python å¼€å‘æ•ˆç‡é«˜ |\n\n> âš ï¸ ç‰ˆæœ¬å…¼å®¹ï¼šè¦æ±‚ PyTorch â‰¥2.0ï¼ŒCUDA â‰¥11.8ã€‚H100 éœ€è¦ CUDA 12.x + FlashInfer v0.1+ã€‚GPTQ/AWQ æ¨¡å‹éœ€ç”¨ `auto_gptq` æˆ– `llm-awq` å¯¼å‡ºï¼Œä¸æ”¯æŒæ—§ç‰ˆé‡åŒ–æ ¼å¼ã€‚\n\n---\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. æ¨èï¼šå®‰è£…é¢„ç¼–è¯‘ GPU ç‰ˆæœ¬ï¼ˆCUDA 12.1ï¼‰\npip install \"vllm==0.5.1\" --extra-index-url https://download.pytorch.org/whl/cu121\n\n# 2. è‹¥éœ€æ”¯æŒ AMD ROCmï¼ˆMI250/MI300ï¼‰ï¼Œä½¿ç”¨ï¼š\npip install vllm --index-url https://download.pytorch.org/whl/rocm6.0\n\n# 3. å®‰è£…é‡åŒ–æ”¯æŒåŒ…ï¼ˆGPTQ/AWQï¼‰\npip install auto-gptq awq\n\n# 4. éªŒè¯å®‰è£…\npython -c \"from vllm import LLM; print('vLLM loaded')\"\n\n# 5. å¯åŠ¨ OpenAI å…¼å®¹ API Serverï¼ˆè‡ªåŠ¨åŠ è½½æ¨¡å‹ï¼‰\nvllm serve meta-llama/Meta-Llama-3-8B --tensor-parallel-size 4\n\n# 6. è‹¥éœ€è‡ªå®šä¹‰é…ç½®ï¼ˆå¦‚æŒ‡å®šé‡åŒ–ã€æœ€å¤§ä¸Šä¸‹æ–‡ï¼‰\nvllm serve meta-llama/Meta-Llama-3-70B \\\n    --dtype half \\\n    --quantization awq \\\n    --max-model-len 8192 \\\n    --tensor-parallel-size 8 \\\n    --gpu-memory-utilization 0.95\n```\n\n> ğŸ’¡ `--gpu-memory-utilization`ï¼šæ§åˆ¶æ˜¾å­˜ä½¿ç”¨ç‡ä¸Šé™ï¼ˆé»˜è®¤ 0.9ï¼‰ï¼Œé¿å… OOMã€‚å»ºè®®è®¾ä¸º 0.8â€“0.95ï¼Œè§†æ¨¡å‹å¤§å°å’Œ batch å¤§å°è°ƒæ•´ã€‚\n\n---\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n```python\nfrom vllm import LLM, SamplingParams\n\n# åŠ è½½é‡åŒ–æ¨¡å‹ï¼ˆAWQ 4bitï¼‰\nllm = LLM(\n    model=\"TheBloke/Mistral-7B-Instruct-v0.1-AWQ\",\n    tensor_parallel_size=2,\n    dtype=\"float16\",\n    gpu_memory_utilization=0.9,\n    max_model_len=8192,  # æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦\n)\n\n# å®šä¹‰é‡‡æ ·å‚æ•°ï¼šå¹¶è¡Œé‡‡æ · + é«˜æ¸©åº¦ + æµå¼è¾“å‡º\nsampling_params = SamplingParams(\n    temperature=0.7,\n    top_p=0.9,\n    max_tokens=512,\n    n=3,  # å¹¶è¡Œç”Ÿæˆ 3 ä¸ªå“åº”ï¼ˆparallel samplingï¼‰\n    stream=True,  # å¯ç”¨æµå¼è¾“å‡º\n)\n\n# è¾“å…¥ï¼šçœŸå®åœºæ™¯ â€”â€” å¤šè½®å¯¹è¯ + æŒ‡ä»¤éµå¾ª\nprompts = [\n    \"Explain quantum entanglement in simple terms.\",\n    \"Write a Python function to calculate Fibonacci sequence efficiently.\",\n    \"What are the ethical implications of AI-generated art?\"\n]\n\n# æ‰§è¡Œæ¨ç†ï¼ˆå¼‚æ­¥æ‰¹é‡å¤„ç†ï¼‰\noutputs = llm.generate(prompts, sampling_params)\n\n# æ¶ˆè´¹æµå¼è¾“å‡º\nfor output in outputs:\n    for i, completion in enumerate(output.outputs):\n        print(f\"--- Response {i+1} ---\")\n        print(completion.text[:200] + \"...\")\n```\n\n**é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼ˆéƒ¨åˆ†ï¼‰ï¼š**\n```\n--- Response 1 ---\nQuantum entanglement is a phenomenon where two particles become linked such that the state of one instantly influences the other, regardless of distance. It's like having two coins that always land on opposite sides when flipped...\n--- Response 2 ---\ndef fibonacci(n):\n    a, b = 0, 1\n    for _ in range(n):\n        yield a\n        a, b = b, a + b\n---\n```\n\n> âœ… å…³é”®å‚æ•°è¯´æ˜ï¼š\n- `n=3`ï¼šæ¯ä¸ª prompt åŒæ—¶ç”Ÿæˆ 3 ä¸ªç‹¬ç«‹ç»“æœï¼ˆç”¨äº A/B æµ‹è¯•æˆ–å¤šæ ·æ€§è¾“å‡ºï¼‰\n- `stream=True`ï¼šé€ token è¿”å›ï¼Œé™ä½å»¶è¿Ÿæ„ŸçŸ¥\n- `tensor_parallel_size=2`ï¼šæ¨¡å‹åœ¨ 2 å¼  GPU ä¸Šåˆ†å±‚å¹¶è¡Œ\n\n---\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n| æŒ‡æ ‡ | å…¸å‹å€¼ï¼ˆLlama3-8B, AWQ4bit, A100x4ï¼‰ |\n|------|-------------------------------------|\n| ååé‡ | 250â€“350 tokens/sï¼ˆè¿ç»­æ‰¹å¤„ç†ï¼‰ |\n| é¦– token å»¶è¿Ÿï¼ˆprefillï¼‰ | < 80msï¼ˆå¯¹ 512 token promptï¼‰ |\n| æ¯ token å»¶è¿Ÿï¼ˆdecodeï¼‰ | ~4ms/token |\n| æ˜¾å­˜å ç”¨ | 6â€“7GBï¼ˆæ¨¡å‹æƒé‡ + KV ç¼“å­˜ï¼Œå« PagedAttentionï¼‰ |\n| å¹¶å‘è¯·æ±‚æ•° | >1000 è¯·æ±‚åŒæ—¶åœ¨çº¿ |\n\n**ç“¶é¢ˆåˆ†æï¼š**\n- **KV Cache å†…å­˜å¸¦å®½**ï¼šdecode é˜¶æ®µé¢‘ç¹éšæœºè®¿é—®é¡µè¡¨ â†’ PagedAttention å·²æå¤§ç¼“è§£ï¼Œä½†ä»å—æ˜¾å­˜å¸¦å®½é™åˆ¶ã€‚\n- **CPU-GPU æ•°æ®ä¼ è¾“**ï¼šé•¿ prompt æ—¶é¢„å¤„ç†ï¼ˆtokenizationï¼‰æˆç“¶é¢ˆ â†’ å»ºè®®ä½¿ç”¨ `vLLM` å†…ç½® tokenizer æˆ–å¼‚æ­¥é¢„å¤„ç†ã€‚\n- **è°ƒåº¦å¼€é”€**ï¼šè¯·æ±‚åˆ°è¾¾ç‡ >1000 req/s æ—¶ï¼ŒPython è°ƒåº¦å™¨å¯èƒ½æˆä¸ºç“¶é¢ˆ â†’ å¯å¼•å…¥ Rust ç¼–å†™çš„",
    "last_scanned": "2026-01-16T02:03:15.395635",
    "last_analyzed": "2026-01-15T09:36:47.749614",
    "screenshot": "static/screenshots/599547518.jpg",
    "ai_visual_summary": "è¯¥ç•Œé¢æ˜¯ GitHub é¡¹ç›® `vllm` çš„ README é¡µé¢ï¼Œé‡‡ç”¨ç®€æ´çš„ç°ä»£è®¾è®¡é£æ ¼ï¼Œä»¥ç™½è‰²ä¸ºä¸»èƒŒæ™¯ï¼Œé»‘è‰²æ–‡å­—ï¼Œæ¸…æ™°çš„æ ‡é¢˜å±‚çº§å’Œåˆ—è¡¨å¸ƒå±€ï¼Œä¾¿äºé˜…è¯»ã€‚ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬é¡¹ç›®ä»‹ç»ã€æ ¸å¿ƒç‰¹æ€§ï¼ˆå¦‚é«˜ååé‡ã€åˆ†å¸ƒå¼æ¨ç†ã€å¤šç¡¬ä»¶æ”¯æŒï¼‰ã€æ”¯æŒçš„æ¨¡å‹ç±»å‹å’Œå¿«é€Ÿå…¥é—¨æŒ‡å—ã€‚å…³é”®æŠ€æœ¯å…³é”®è¯åŒ…æ‹¬ `LLM`ã€`Hugging Face`ã€`Tensor`ã€`parallel sampling`ã€`beam search`ã€`GPU`ã€`TPU` ç­‰ã€‚ä»å†…å®¹å’Œè®¾è®¡æ¥çœ‹ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé«˜æ•ˆéƒ¨ç½²å’Œè¿è¡Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é«˜æ€§èƒ½æ¨ç†ä¸æœåŠ¡å¼•æ“ï¼Œæ—¨åœ¨ä¸ºå¼€å‘è€…æä¾›ä¸€ä¸ªå¼ºå¤§ä¸”æ˜“äºé›†æˆçš„å·¥å…·ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "646410686",
    "name": "LlamaFactory",
    "full_name": "hiyouga/LlamaFactory",
    "category": "llm_rag",
    "stars": 65808,
    "forks": 8000,
    "description": "Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024)",
    "url": "https://github.com/hiyouga/LlamaFactory",
    "homepage": "https://llamafactory.readthedocs.io",
    "language": "Python",
    "topics": "[\"agent\", \"ai\", \"deepseek\", \"fine-tuning\", \"gemma\", \"gpt\", \"instruction-tuning\", \"large-language-models\", \"llama\", \"llama3\", \"llm\", \"lora\", \"moe\", \"nlp\", \"peft\", \"qlora\", \"quantization\", \"qwen\", \"rlhf\", \"transformers\"]",
    "created_at": "2023-05-28T10:09:12Z",
    "updated_at": "2026-01-15T18:01:12Z",
    "readme_content": null,
    "ai_summary": "ç»Ÿä¸€å¤„ç†100å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹çš„é«˜æ•ˆå¾®è°ƒå·¥å…·é›†ï¼ŒåŸºäºDeepSpeedå®ç°åˆ†å¸ƒå¼è®­ç»ƒä¼˜åŒ–ï¼Œå¹¶æä¾›è‡ªåŠ¨åŒ–é‡åŒ–çš„ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆ",
    "ai_tech_stack": "[\"DeepSpeed\", \"PyTorch\", \"transformers\", \"datasets\", \"accelerate\", \"HuggingFace\"]",
    "ai_use_cases": "[\"\\u91d1\\u878d\\u9886\\u57df\\u6587\\u6863\\u667a\\u80fd\\u5904\\u7406\\uff08Amazon\\u6848\\u4f8b\\uff09\", \"AI\\u5ba2\\u670d\\u7cfb\\u7edf\\u96c6\\u6210\\u4e0e\\u90e8\\u7f72\\uff08NVIDIA RTX AI Toolkit\\u9002\\u914d\\uff09\", \"\\u4f01\\u4e1a\\u77e5\\u8bc6\\u5e93\\u6784\\u5efa\\u5de5\\u5177\\u94fe\\uff08\\u963f\\u91cc\\u4e91PAI\\u5e73\\u53f0\\u652f\\u6301\\uff09\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "# å®‰è£…\npip install -U 'llamafactory[model]' \n# å¿«é€Ÿå¯åŠ¨\nllamafactory-cli micro --model facebook/opt-350m",
    "ai_tutorial": "## ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nLLaMA-Factory çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äº**ä»¥ç»Ÿä¸€æ¥å£å®ç°ç™¾çº§æ¨¡å‹çš„é›¶ä»£ç é«˜æ•ˆå¾®è°ƒ**ï¼Œè§£å†³äº†è¡Œä¸šé•¿æœŸå­˜åœ¨çš„â€œå¾®è°ƒç¢ç‰‡åŒ–â€ç—›ç‚¹ã€‚ä¸»æµæ¡†æ¶ï¼ˆå¦‚ Hugging Face Transformersã€Axolotlã€OpenLLMï¼‰é€šå¸¸èšç„¦äºå•ä¸€æ¶æ„ï¼ˆå¦‚ LLaMA æˆ– Mistralï¼‰ï¼Œè€Œ LLaMA-Factory é€šè¿‡**åŠ¨æ€é…ç½®é©±åŠ¨çš„æ’ä»¶å¼è®­ç»ƒå™¨å¼•æ“**ï¼Œå®ç°äº†å¯¹ 100+ LLM/VLM çš„å¼€ç®±å³ç”¨æ”¯æŒâ€”â€”åŒ…æ‹¬ LLaMAã€Qwenã€Phiã€Mistralã€Yiã€DeepSeekã€LLaVAã€MiniCPM-V ç­‰è·¨æ¶æ„æ¨¡å‹ã€‚å…¶çœŸæ­£çªç ´åœ¨äºï¼š\n\n- **ç»Ÿä¸€è®­ç»ƒèŒƒå¼æŠ½è±¡å±‚**ï¼šå°† LoRAã€QLoRAã€Full Fine-tuningã€DPOã€ORPOã€PPOã€KTO ç­‰ 10+ å¾®è°ƒæ–¹æ³•å°è£…ä¸ºå¯ç»„åˆé…ç½®é¡¹ï¼Œè€Œéç¡¬ç¼–ç å®ç°ã€‚\n- **å¤šæ¨¡æ€ä¸è¯­è¨€æ¨¡å‹åŒæºæ”¯æŒ**ï¼šVLMï¼ˆå¦‚ LLaVAï¼‰ä¸ LLM å…±äº«åŒä¸€è®­ç»ƒç®¡é“ï¼Œä»…é€šè¿‡ `model_type` å’Œ `dataset_format` è‡ªåŠ¨åˆ‡æ¢è§†è§‰ encoder è·¯å¾„ï¼Œæ— éœ€ç‹¬ç«‹ä»£ç åº“ã€‚\n- **ä¼ä¸šçº§ç”Ÿäº§å°±ç»ªè®¾è®¡**ï¼šå†…ç½®å¯¹ SageMaker HyperPodã€PAIã€ModelScopeã€Novita ç­‰äº‘å¹³å°çš„éƒ¨ç½²æ¨¡æ¿ï¼Œç›´æ¥å¯¹æ¥å·¥ä¸šçº§è®­ç»ƒé›†ç¾¤ã€‚\n\nç›¸è¾ƒ Axolotlï¼ˆé…ç½®å¤æ‚ï¼‰æˆ– Hugging Face TRLï¼ˆä»…æ”¯æŒéƒ¨åˆ†æ–¹æ³•ï¼‰ï¼ŒLLaMA-Factory ä»¥ **10 è¡Œ YAML é…ç½®** æ›¿ä»£äº†æ•°ç™¾è¡Œå®šåˆ¶è„šæœ¬ï¼ŒçœŸæ­£å®ç°äº†â€œå¾®è°ƒå³é…ç½®â€ã€‚\n\n---\n\n## ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n### 1. åŠ¨æ€æ¨¡å—åŒ–è®­ç»ƒå™¨æ¶æ„\né‡‡ç”¨ `TrainerBuilder` æ¨¡å¼ï¼Œæ ¹æ® `training_args.yaml` ä¸­çš„ `method: lora/qlora/dpo` ç­‰å­—æ®µ**è¿è¡Œæ—¶åŠ¨æ€åŠ è½½å¯¹åº”ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°å’Œæ•°æ®é‡‡æ ·å™¨**ã€‚ä¾‹å¦‚ï¼š\n- QLoRA è‡ªåŠ¨æ³¨å…¥ 4-bit quantization + gradient checkpointing + offload\n- DPO è‡ªåŠ¨æ›¿æ¢ CE loss ä¸º DPOLossï¼ˆåŸºäº Bradley-Terry æ¨¡å‹ï¼‰\n- PPO å¼•å…¥ RLHF ç¯å¢ƒæ¨¡æ‹Ÿå™¨ï¼Œæ— éœ€å¤–éƒ¨å¥–åŠ±æ¨¡å‹æ¥å£\n\n### 2. å†…å­˜ä¼˜åŒ–ï¼šåˆ†å±‚æ¢¯åº¦å¸è½½ + æ™ºèƒ½ç¼“å†²\n- **QLoRA æ”¯æŒ**ï¼šé›†æˆ `bitsandbytes` çš„ `Linear4bit` å±‚ï¼Œåœ¨è®­ç»ƒæ—¶ä»…ä¿ç•™ LoRA æƒé‡çš„ FP16 å‰¯æœ¬ï¼Œä¸»æƒé‡åœ¨ CPU ä¸ŠæŒ‰éœ€åŠ è½½ï¼ˆéå…¨é‡å¸è½½ï¼‰ï¼Œæ˜¾è‘—é™ä½ GPU æ˜¾å­˜å ç”¨ã€‚\n- **æ¢¯åº¦æ£€æŸ¥ç‚¹åˆ†æ®µç­–ç•¥**ï¼šæ ¹æ®æ¨¡å‹å±‚æ•°å’Œåºåˆ—é•¿åº¦è‡ªåŠ¨åˆ‡åˆ† checkpoint æ®µï¼ˆå¦‚æ¯ 4 å±‚ä¸€ç»„ï¼‰ï¼Œé¿å… OOM åŒæ—¶ä¿æŒè®­ç»ƒç¨³å®šæ€§ã€‚\n\n### 3. æ•°æ®æµæ°´çº¿å¼‚æ„å…¼å®¹\né€šè¿‡ `DataCollatorForSupervisedDataset` è‡ªåŠ¨è¯†åˆ«è¾“å…¥æ ¼å¼ï¼š\n- æ–‡æœ¬ï¼š`{\"input\": \"xxx\", \"output\": \"yyy\"}`\n- å¤šæ¨¡æ€ï¼š`{\"image\": PIL.Image, \"conversations\": [{\"from\": \"human\", \"value\": \"...\"}, ...]}`\næ— éœ€é¢„å¤„ç†è„šæœ¬ï¼Œä»…éœ€æŒ‡å®š `dataset: my_dataset.jsonl` + `template: llama3`ï¼ˆæ¨¡æ¿è‡ªåŠ¨è§£æ role ä¸ tokenizationï¼‰\n\n### 4. å¤šå¡åˆ†å¸ƒå¼è®­ç»ƒçš„é›¶é…ç½®åˆ‡åˆ†\nè‡ªåŠ¨æ£€æµ‹ `CUDA_VISIBLE_DEVICES` å¹¶æ ¹æ®æ¨¡å‹å¤§å°é€‰æ‹©ï¼š\n- å•å¡ â†’ Full Fine-tuningï¼ˆè‹¥æ˜¾å­˜ > 80GBï¼‰\n- å¤šå¡ â†’ DDP + LoRA å‚æ•°å¹¶è¡Œï¼ˆä»…åŒæ­¥ LoRA A/B çŸ©é˜µï¼Œéå…¨å‚ï¼‰\n- è¶…å¤§æ¨¡å‹ â†’ DeepSpeed Stage 3 + ZeRO-Infinity\n\n---\n\n## ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n### 1. æ•´ä½“æ¶æ„ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\n[CLI / Web UI] \n       â†“\n[Config Parser] â† YAML/JSON é…ç½®æ–‡ä»¶ (training_args.yaml)\n       â†“\n[TrainerBuilder] â†’ åŠ¨æ€å®ä¾‹åŒ–ï¼šOptimizer + Scheduler + Loss + DataCollator\n       â†“\n[ModelLoader] â†’ æ ¹æ® model_name_or_path åŠ è½½ HF AutoModelForCausalLM / LlavaForConditionalGeneration\n       â†“\n[PeftAdapterManager] â†’ æ³¨å…¥ LoRA/IA3/DORA ç­‰é€‚é…å™¨ï¼ˆæ”¯æŒå¤šè·¯å¹¶è¡Œï¼‰\n       â†“\n[Trainer (HuggingFace)] â† å°è£…ä¸ºæ ‡å‡† Trainer å®ä¾‹ï¼Œæ¥æ”¶ï¼š\n   - train_dataset (Dataset)\n   - eval_dataset (Dataset)\n   - data_collator\n   - compute_metrics\n       â†“\n[CallbackManager] â†’ ç›‘æ§ï¼šWandB/MLflow æ—¥å¿—ã€æ¨¡å‹ä¿å­˜ã€early stoppingã€tensorboard\n       â†“\n[Exporter] â†’ å¯¼å‡ºä¸º HF æ ¼å¼ / GGUF / ONNX / vLLM å…¼å®¹æƒé‡\n```\n\n### 2. æ ¸å¿ƒæ¨¡å—èŒè´£\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| `config` | è§£æ YAMLï¼Œæ ‡å‡†åŒ–è®­ç»ƒå‚æ•°ï¼ˆæ”¯æŒå¤šæºï¼šæ–‡ä»¶ã€CLIã€ç¯å¢ƒå˜é‡ï¼‰ |\n| `model_loader.py` | è‡ªåŠ¨è¯†åˆ«æ¨¡å‹æ¶æ„å¹¶åŠ è½½å¯¹åº” tokenizer + vision_encoder (VLM) |\n| `peft_manager.py` | ç®¡ç† LoRA å±‚çš„ target_modules åŠ¨æ€æ˜ å°„ï¼ˆå¦‚ Qwen ç”¨ `c_attn`, LLaMA ç”¨ `q_proj,v_proj`ï¼‰ |\n| `data_module.py` | å®ç°å¤šæ ¼å¼æ•°æ®åŠ è½½ä¸å¯¹é½ï¼Œæ”¯æŒ Alpacaã€ShareGPTã€LLaVA ç­‰æ ‡å‡†æ ¼å¼ |\n| `trainer_wrapper.py` | åŒ…è£… HF Trainerï¼Œæ³¨å…¥è‡ªå®šä¹‰ lossï¼ˆDPOï¼‰ã€é‡‡æ ·ç­–ç•¥ï¼ˆPPOï¼‰ã€æ¢¯åº¦è£å‰ªé€»è¾‘ |\n| `exporter.py` | æ”¯æŒåˆå¹¶ LoRA + é‡åŒ–å¯¼å‡ºï¼ˆGGUF/INT4ï¼‰ï¼Œé€‚é… vLLMã€Text Generation Inference |\n\n### 3. æ•°æ®æµå‘\n\n```\nè¾“å…¥ï¼šdataset.jsonl + config.yaml\n       â†“\nConfigParser â†’ æ ‡å‡†åŒ–ä¸º TrainingArguments + PeftConfig + DataTrainingArguments\n       â†“\nModelLoader â†’ åŠ è½½ base_model (AutoModel) + tokenizer + (vision_encoder if VLM)\n       â†“\nPeftAdapterManager â†’ ä¸ºæŒ‡å®š layer æ³¨å…¥ LoRA å±‚ï¼ˆå¦‚ target_modules=[\"q_proj\",\"v_proj\"]ï¼‰\n       â†“\nDataModule â†’ æ„é€  Dataset â†’ åº”ç”¨ template â†’ tokenize â†’ batch collation\n       â†“\nTrainerWrapper â†’ ç»‘å®š optimizer (AdamW) + scheduler (Cosine) + loss_fn (DPO/CE)\n       â†“\nHuggingFace Trainer â†’ æ‰§è¡Œè®­ç»ƒå¾ªç¯ï¼ˆforward/backward/updateï¼‰\n       â†“\nCallbackManager â†’ å†™æ—¥å¿—ã€ä¿å­˜ checkpointã€è¯„ä¼° BLEU/ROUGE\n       â†“\nè¾“å‡ºï¼šmerged_model/ + config.json + tokenizer/ + adapter_config.json\n```\n\n### 4. å…³é”®è®¾è®¡æ¨¡å¼\n\n- **å·¥å‚æ¨¡å¼**ï¼š`TrainerBuilder` æ ¹æ® `method` å­—æ®µè¿”å›ä¸åŒ Trainer å®ä¾‹ï¼ˆDPOTrainerã€PPOTrainer ç­‰ï¼‰\n- **ç­–ç•¥æ¨¡å¼**ï¼š`DataTemplate` ç±»æ—å®ç°ä¸åŒæ¨¡å‹çš„å¯¹è¯æ ¼å¼åŒ–é€»è¾‘ï¼ˆLLaMA3 vs Qwen vs Yiï¼‰\n- **è£…é¥°å™¨æ¨¡å¼**ï¼š`QuantizedTrainer` è£…é¥°åŸºç¡€ Trainerï¼Œæ³¨å…¥ 4-bit ä¼˜åŒ–\n- **ä¾èµ–æ³¨å…¥**ï¼šæ‰€æœ‰æ¨¡å—é€šè¿‡ `config` æ³¨å…¥ï¼Œé¿å…ç¡¬ç¼–ç è€¦åˆ\n\n> è®¾è®¡åŠ¨æœºï¼šæ”¯æŒçƒ­æ’æ‹”è®­ç»ƒæ–¹æ³•ä¸æ¨¡å‹æ¶æ„ï¼Œä¸ä¿®æ”¹æ ¸å¿ƒä»£ç å³å¯æ‰©å±•æ–°åŠŸèƒ½ã€‚\n\n---\n\n## ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| ç»„ä»¶ | é€‰æ‹©åŸå›  | æ›¿ä»£æ–¹æ¡ˆ | æ³¨æ„äº‹é¡¹ |\n|------|----------|----------|----------|\n| `transformers` (v4.38+) | å®˜æ–¹æ”¯æŒæ¨¡å‹æœ€å¤šã€æ¥å£ç¨³å®š | `llama-recipes`, `axolotl` | å¿…é¡» â‰¥ v4.38ï¼Œå¦åˆ™ LoRA æ— æ³•åœ¨ Qwen2 ä¸Šç”Ÿæ•ˆ |\n| `peft` (0.9+) | æ”¯æŒ DORAã€IA3ã€LoRA++ ç­‰æ–°æ–¹æ³• | `loralib`ï¼ˆä»…åŸºç¡€ LoRAï¼‰ | ä½¿ç”¨ `LoraConfig` æ—¶éœ€æŒ‡å®š `modules_to_save=[\"lm_head\"]` é¿å…è¾“å‡ºå±‚å†»ç»“ |\n| `bitsandbytes` (0.41+) | å”¯ä¸€æ”¯æŒ 4-bit + gradient checkpointing çš„åº“ | `gptq-for-llama`ï¼ˆä»…æ¨ç†ï¼‰ | å¿…é¡»å®‰è£… CUDA ç‰ˆæœ¬ï¼Œé CPU å…¼å®¹ï¼›PyTorch â‰¥ 2.1 |\n| `accelerate` | å¤šå¡/æ··åˆç²¾åº¦è‡ªåŠ¨é…ç½® | è‡ªå®šä¹‰ DDP | é…ç½®æ–‡ä»¶éœ€è®¾ç½® `mixed_precision: bf16` æ‰èƒ½å¯ç”¨ Ampere æ¶æ„ä¼˜åŠ¿ |\n| `gradio` (4.30+) | å¿«é€Ÿæ„å»º Web UIï¼Œæ—  JS å¼€å‘ | Streamlit / Dash | ä»…ç”¨äºæ¼”ç¤ºï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ç”¨ FastAPI + React |\n| `pydantic` | éªŒè¯ YAML é…ç½®ç»“æ„ | `jsonschema` | æ‰€æœ‰å­—æ®µå¿…é¡»å®šä¹‰ `Field(..., description=\"\")`ï¼Œä¾¿äº IDE æç¤º |\n\n> âš ï¸ **ç‰ˆæœ¬å…¼å®¹é™·é˜±**ï¼š  \n> - `transformers==4.38.2 + peft==0.9.0 + bitsandbytes==0.41.2` ä¸ºå®˜æ–¹æ¨èç»„åˆ  \n> - å‡çº§ transformers è‡³ v4.40+ å¯èƒ½å¯¼è‡´ QLoRA åœ¨ LLaMA-3 ä¸ŠæŠ¥ `KeyError: 'lm_head'`ï¼Œéœ€å›é€€æˆ–æ‰‹åŠ¨ patch\n\n---\n\n## ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. åˆ›å»ºç‹¬ç«‹ç¯å¢ƒï¼ˆæ¨èä½¿ç”¨ conda æˆ– venvï¼‰\npython -m venv llm_env && source llm_env/bin/activate  # Linux/Mac\n# æˆ– Windows: llm_env\\Scripts\\activate\n\n# 2. å®‰è£…æ ¸å¿ƒåŒ…ï¼ˆå®˜æ–¹æ¨èç¨³å®šç‰ˆï¼‰\npip install \"llamafactory[torch,deepspeed]\" --upgrade\n\n# 3. ï¼ˆå¯é€‰ï¼‰å®‰è£… GPU åŠ é€Ÿä¾èµ–ï¼ˆå¿…é¡»ï¼ï¼‰\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\npip install bitsandbytes==0.41.2  # å¿…é¡»æŒ‡å®šç‰ˆæœ¬ï¼\n\n# 4. å®‰è£… Web UI å¯è§†åŒ–ç»„ä»¶ï¼ˆéå¿…éœ€ï¼Œç”¨äº LLaMA Boardï¼‰\npip install gradio transformers[vision]  # VLM å¾®è°ƒéœ€è¦ vision æ¨¡å—\n\n# 5. ï¼ˆå¯é€‰ï¼‰å¯ç”¨ DeepSpeed å¤šå¡è®­ç»ƒ\npip install deepspeed==0.14.2\n\n# 6. éªŒè¯å®‰è£…ï¼ˆæ£€æŸ¥æ˜¯å¦æ”¯æŒ LoRA å’Œ QLoRAï¼‰\npython -c \"from peft import LoraConfig; print('âœ… PeFT OK')\"\npython -c \"import bitsandbytes as bnb; print('âœ… BNB OK')\"\n```\n\n> ğŸ’¡ **ç”Ÿäº§å»ºè®®**ï¼šä½¿ç”¨ Docker é•œåƒé¿å…ç¯å¢ƒå†²çª  \n> `docker pull hiyouga/llamafactory:latest && docker run --gpus all -it hiyouga/llamafactory`\n\n---\n\n## ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n### åœºæ™¯ï¼šå¾®è°ƒ LLaMA-3-8B åœ¨åŒ»ç–—é—®ç­”æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨ QLoRA + BF16\n\n**è¾“å…¥æ–‡ä»¶ `medical_qa.jsonl`**ï¼š\n```json\n{\"instruction\": \"å¦‚ä½•æ²»ç–—é«˜è¡€å‹ï¼Ÿ\", \"input\": \"\", \"output\": \"å»ºè®®ä½ç›é¥®é£Ÿã€è§„å¾‹è¿åŠ¨ï¼Œå¿…è¦æ—¶æœç”¨ACEæŠ‘åˆ¶å‰‚ã€‚\"}\n{\"instruction\": \"ç³–å°¿ç—…æ‚£è€…èƒ½åƒæ°´æœå—ï¼Ÿ\", \"input\": \"\", \"output\": \"å¯ä»¥é€‚é‡é£Ÿç”¨ä½GIæ°´æœå¦‚è‹¹æœã€è“è“ï¼Œé¿å…æœæ±å’Œé«˜ç³–å“ç§ã€‚\"}\n```\n\n**é…ç½®æ–‡ä»¶ `train_qlora.yaml`**ï¼š\n```yaml\nmodel_name_or_path: meta-llama/Meta-Llama-3-8B\ndataset: medical_qa.jsonl\nfinetuning_type: lora\nlora_target: q_proj,v_proj,k_proj,o_proj  # LLaMA-3 çš„ç›®æ ‡å±‚\ntraining_args:\n  per_device_train_batch_size: 1\n  gradient_accumulation_steps: 4\n  learning_rate: 2e-4\n  num_train_epochs: 3\n  max_seq_length: 2048\n  bf16: true\n  logging_steps: 50\n  save_strategy: epoch\n  output_dir: ./results/llama3-medical\npeft_args:\n  lora_rank: 64\n  lora_alpha: 128\n  lora_dropout: 0.05\n```\n\n**æ‰§è¡Œå‘½ä»¤**ï¼š\n```bash\nllamafactory-cli train \\\n    --config_file train_qlora.yaml \\\n    --use_peft true \\\n    --use_quantization true \\\n    --report_to wandb\n```\n\n### é¢„æœŸè¾“å‡º\n\n- `./results/llama3-medical/checkpoint-150/`ï¼šè®­ç»ƒä¸­ checkpointï¼ˆå« LoRA æƒé‡ï¼‰\n- `./results/llama3-medical/final/adapter_model.bin`ï¼šæœ€ç»ˆ LoRA é€‚é…å™¨\n- **å†…å­˜å ç”¨**ï¼šå•å¡ A100 80G â†’ çº¦ 24GB æ˜¾å­˜ï¼ˆQLoRA + BF16ï¼‰\n- **è®­ç»ƒæ—¶é—´**ï¼šçº¦ 90 åˆ†é’Ÿï¼ˆ3 epoch, ~500 samplesï¼‰\n\n### å…³é”®å‚æ•°è¯´æ˜\n\n| å‚æ•° | å«ä¹‰ | æ¨èå€¼ |\n|------|------|--------|\n| `lora",
    "last_scanned": "2026-01-16T02:03:15.396640",
    "last_analyzed": "2026-01-15T09:51:40.400320",
    "screenshot": "static/screenshots/646410686.jpg",
    "ai_visual_summary": "æ ¹æ®æˆªå›¾åˆ†æï¼Œè¿™æ˜¯ä¸€ä¸ªåä¸º LlamaFactory çš„å¼€æºé¡¹ç›®ï¼Œå…¶ç•Œé¢è®¾è®¡é£æ ¼ç®€æ´ã€ä¸“ä¸šï¼Œä»¥ä¿¡æ¯å¯†åº¦é«˜ä¸ºç‰¹ç‚¹ã€‚ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬é¡¹ç›®ä¿¡æ¯ï¼ˆå¦‚è®¸å¯è¯ã€è´¡çŒ®æŒ‡å—ï¼‰å’Œæ ¸å¿ƒçš„â€œæ”¯æŒçš„è®­ç»ƒæ–¹æ³•â€è¡¨æ ¼ã€‚è¯¥åº”ç”¨æ—¨åœ¨æä¾›ä¸€ä¸ªç»Ÿä¸€çš„ã€é«˜æ•ˆçš„å¾®è°ƒå¹³å°ï¼Œæ”¯æŒè¶…è¿‡100ç§å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œå…¶æ ¸å¿ƒæŠ€æœ¯å…³é”®è¯åŒ…æ‹¬å¤šç§å¾®è°ƒæ–¹æ³•ï¼ˆå¦‚ LoRAã€QLoRAã€DPOï¼‰å’Œæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚ transformersï¼‰ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›çš„ã€ç”¨äºé«˜æ•ˆå¾®è°ƒå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å·¥å…·ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "798201435",
    "name": "crawl4ai",
    "full_name": "unclecode/crawl4ai",
    "category": "llm_rag",
    "stars": 58588,
    "forks": 5960,
    "description": "ğŸš€ğŸ¤– Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN",
    "url": "https://github.com/unclecode/crawl4ai",
    "homepage": "https://crawl4ai.com",
    "language": "Python",
    "topics": "[]",
    "created_at": "2024-05-09T09:48:50Z",
    "updated_at": "2026-01-15T17:32:32Z",
    "readme_content": null,
    "ai_summary": "Crawl4AI æ˜¯ä¸€ä¸ªç”¨äºå°†ç½‘é¡µå†…å®¹è½¬æ¢ä¸ºé€‚åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½¿ç”¨çš„ç»“æ„åŒ–æ•°æ®çš„å¼€æºçˆ¬è™«å·¥å…·ï¼Œæ ¸å¿ƒç‰¹ç‚¹æ˜¯ç”Ÿæˆå¹²å‡€ã€å¯ç›´æ¥ç”¨äº RAG å’Œ AI æ•°æ®ç®¡é“çš„ Markdown æ ¼å¼ï¼Œå¹¶æä¾›ä¼ä¸šçº§ç›‘æ§å’Œå¤šä»£ç†çˆ¬å–èƒ½åŠ›ã€‚",
    "ai_tech_stack": "[\"Python\", \"FastAPI\", \"Pydantic v2\", \"Docker\", \"Selenium/Playwright\"]",
    "ai_use_cases": "[\"\\u6784\\u5efa\\u68c0\\u7d22\\u589e\\u5f3a\\u751f\\u6210\\uff08RAG\\uff09\\u7cfb\\u7edf\", \"AI \\u52a9\\u624b\\u7684\\u6570\\u636e\\u6765\\u6e90\\u81ea\\u52a8\\u5316\\u91c7\\u96c6\", \"\\u4f01\\u4e1a\\u77e5\\u8bc6\\u5e93\\u5efa\\u8bbe\\u4e0e\\u7ef4\\u62a4\"]",
    "ai_difficulty": 3,
    "ai_quick_start": "docker run -p 8000:8000 --add-host=host-gateway:172.16.254.1 -e CRAWL4AI_API_KEY=\"your-api-key\" unclecode/crawl4ai",
    "ai_tutorial": "## ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nCrawl4AI çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äºï¼š**å®ƒä¸æ˜¯â€œçˆ¬è™«â€ï¼Œè€Œæ˜¯ä¸º LLM/RAG é‡èº«å®šåˆ¶çš„è¯­ä¹‰æ„ŸçŸ¥å‹ç½‘é¡µæå–å¼•æ“**ã€‚ä¸»æµå·¥å…·ï¼ˆå¦‚ Scrapyã€Playwright + BeautifulSoupï¼‰èšç„¦äºâ€œè·å– HTMLâ€ï¼Œè€Œ Crawl4AI èšç„¦äºâ€œè¾“å‡ºå¯ç›´æ¥å–‚ç»™ LLM çš„é«˜è´¨é‡ Markdownâ€ã€‚\n\n- **è§£å†³ RAG ç—›ç‚¹**ï¼šä¼ ç»Ÿçˆ¬è™«è¿”å›å†—é•¿ã€å«å¯¼èˆª/å¹¿å‘Š/è„šæœ¬çš„ HTMLï¼ŒRAG æ£€ç´¢å™ªå£°æé«˜ã€‚Crawl4AI å†…ç½®è¯­ä¹‰æ¸…æ´— + ç»“æ„åŒ–æç‚¼ï¼ˆæ ‡é¢˜ã€æ®µè½ã€åˆ—è¡¨ã€ä»£ç å—ï¼‰ï¼Œè¾“å‡ºå¹²å‡€ Markdownï¼Œä¸Šä¸‹æ–‡é•¿åº¦åˆ©ç”¨ç‡æå‡ 3â€“5xã€‚\n- **åçˆ¬å¯¹æŠ—å·¥ä¸šåŒ–**ï¼šå†…ç½® reCAPTCHA v2/v3ã€Cloudflare Turnstileã€IP è½®æ¢ã€è¯·æ±‚æŒ‡çº¹æ··æ·†ã€æµè§ˆå™¨æŒ‡çº¹æ¨¡æ‹Ÿï¼Œæ— éœ€å¤–éƒ¨æœåŠ¡å³å¯ç»•è¿‡ä¸»æµé˜²æŠ¤ã€‚å¯¹æ¯” Scrapy + Selenium æ–¹æ¡ˆï¼Œå®ƒæŠŠâ€œåçˆ¬â€ä»è¿ç»´å™©æ¢¦å˜æˆå¯é…ç½®çš„æ¨¡å—ã€‚\n- **æˆæœ¬é¢ è¦†æ€§**ï¼šCrawl4AI Cloud API å®£ç§°æ¯” BrightData/ScrapingBee ä¾¿å®œ 80%ï¼Œæ ¸å¿ƒåœ¨äºå…¶è½»é‡æ— å¤´æµè§ˆå™¨æ±  + æ™ºèƒ½ç¼“å­˜å¤ç”¨ + åŸºäºå†…å®¹ç†µçš„å»é‡æœºåˆ¶ï¼Œè€Œéä¾èµ–æ˜‚è´µäº‘ä»£ç†ã€‚\n- **å¼€ç®±å³ç”¨ LLM é›†æˆ**ï¼šç›´æ¥è¾“å‡º JSON-LD / Markdown + å…ƒæ•°æ®ï¼ˆè¯­ä¹‰ç»“æ„ã€å¯ä¿¡åº¦è¯„åˆ†ã€é“¾æ¥å›¾è°±ï¼‰ï¼Œæ— éœ€åå¤„ç†ã€‚æ”¯æŒ OpenAI/Gemini/Claude ç­‰æ¨¡å‹çš„ prompt-ready æ ¼å¼ã€‚\n\n## ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n- **è¯­ä¹‰æ„ŸçŸ¥æå–å¼•æ“**ï¼šåŸºäº HTML DOM æ ‘ + CSS é€‰æ‹©å™¨å¯å‘å¼è§„åˆ™ï¼ˆé MLï¼‰è¿›è¡Œå†…å®¹å¯†åº¦åˆ†æï¼Œè¯†åˆ«â€œä¸»ä½“å†…å®¹åŒºåŸŸâ€ï¼ˆç±»ä¼¼ Readability.jsï¼‰ï¼Œä½†å¢å¼ºä¸º LLM å‹å¥½ç»“æ„ï¼šä¿ç•™æ ‡é¢˜å±‚çº§ã€ä»£ç å—æ ‡è®°ã€å¼•ç”¨å—ã€åˆ—è¡¨åµŒå¥—ï¼Œä¸¢å¼ƒè„šæœ¬/å¹¿å‘Š/é¡µè„šã€‚\n- **åŠ¨æ€æ¸²æŸ“ + æ™ºèƒ½ç­‰å¾…**ï¼šä½¿ç”¨ Playwrightï¼ˆChromiumï¼‰è€Œé Puppeteerï¼Œæ”¯æŒ `wait_for_selector` + `wait_for_function` çš„ç»„åˆç­–ç•¥ï¼Œè‡ªåŠ¨æ£€æµ‹â€œå†…å®¹åŠ è½½å®Œæˆâ€ä¿¡å·ï¼ˆå¦‚ DOM å…ƒç´ æ•°é‡å˜åŒ–ã€API è¯·æ±‚å®Œæˆï¼‰ï¼Œé¿å…å›ºå®šå»¶æ—¶ã€‚\n- **ç¼“å­˜æ„ŸçŸ¥çˆ¬å–æ¶æ„**ï¼šåŸºäº URL + HTTP headers + JavaScript æ‰§è¡Œä¸Šä¸‹æ–‡ç”Ÿæˆ SHA-256 å“ˆå¸Œä½œä¸ºç¼“å­˜é”®ã€‚æ”¯æŒå†…å­˜/Redis ä¸¤çº§ç¼“å­˜ï¼Œå‘½ä¸­ç‡ >70% å¯¹äºé‡å¤ç»“æ„ç½‘ç«™ï¼ˆå¦‚äº§å“åˆ—è¡¨é¡µï¼‰ã€‚\n- **å†…å®¹ç›¸å…³æ€§è¿‡æ»¤å™¨**ï¼šå¯¹æå–æ–‡æœ¬è¿›è¡Œè¯­ä¹‰å¯†åº¦è¯„åˆ†ï¼ˆè¯é¢‘ vs. åœç”¨è¯å æ¯” + æ ‡é¢˜åŒ¹é…åº¦ï¼‰ï¼Œä½äºé˜ˆå€¼çš„é¡µé¢è‡ªåŠ¨æ ‡è®°ä¸ºâ€œä½ä»·å€¼â€å¹¶è·³è¿‡ LLM æå–ï¼ŒèŠ‚çœ API æˆæœ¬ã€‚\n- **Webhook é˜Ÿåˆ—ä¸æŒ‡æ•°é€€é¿é‡è¯•**ï¼šæ‰€æœ‰çˆ¬å–ä»»åŠ¡æ”¯æŒå¼‚æ­¥æäº¤ï¼ˆ/crawl/jobï¼‰ï¼Œé€šè¿‡ WebSocket å®æ—¶æ¨é€çŠ¶æ€ã€‚å¤±è´¥ä»»åŠ¡è‡ªåŠ¨æŒ‰ 2^n æŒ‡æ•°é€€é¿ï¼ˆæœ€å¤§ 10 åˆ†é’Ÿï¼‰é‡è¯•ï¼Œé¿å…é›ªå´©ã€‚\n\n## ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n```\n[User Request]\n        â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   HTTP API Gateway    â”‚ â† RESTful endpoints (/crawl, /llm, /webhook)\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Job Queue Manager     â”‚ â† Redis Streams æˆ– RabbitMQï¼Œæ”¯æŒä¼˜å…ˆçº§é˜Ÿåˆ—\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Browser Pool Manager â”‚ â† ç®¡ç† 5â€“20 ä¸ª Playwright å®ä¾‹ï¼ˆæ— å¤´ Chromiumï¼‰\nâ”‚  (Dockerized)         â”‚    æ¯å®ä¾‹ç‹¬ç«‹ä¸Šä¸‹æ–‡ã€UAã€ä»£ç†ã€cookies\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Extraction Engine   â”‚ â† DOM è§£æ â†’ å†…å®¹æå– â†’ Markdown åŒ– â†’ ç»“æ„åŒ–å…ƒæ•°æ®\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Output Formatter     â”‚ â† è¾“å‡ºï¼šMarkdown + JSON (metadata: score, links, domain, time)\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Cache Layer         â”‚ â† Redis/Memoryï¼Œé”® = request_hash\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\n[Webhook â†’ User]  [Monitoring Dashboard]\n```\n\n### æ ¸å¿ƒæ¨¡å—èŒè´£\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| **API Gateway** | æ¥æ”¶ HTTP è¯·æ±‚ï¼Œæ ¡éªŒè®¤è¯ï¼ˆAPI keyï¼‰ï¼Œè·¯ç”±åˆ° Job Queueã€‚æ”¯æŒ CORSã€é€Ÿç‡é™åˆ¶ã€JWT éªŒè¯ |\n| **Job Queue Manager** | ç®¡ç†ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸï¼šå…¥é˜Ÿ â†’ åˆ†é…ç»™ Browser Worker â†’ è®°å½•çŠ¶æ€ â†’ è§¦å‘ Webhookã€‚ä½¿ç”¨ Redis Streams å®ç°åŸå­æ¶ˆè´¹ |\n| **Browser Pool Manager** | åŠ¨æ€ç®¡ç† Playwright æµè§ˆå™¨å®ä¾‹æ± ï¼Œæ”¯æŒæŒ‰éœ€æ‰©å®¹ï¼ˆDocker Compose scaleï¼‰ï¼Œéš”ç¦»æµè§ˆå™¨ä¸Šä¸‹æ–‡é˜²æ­¢æ±¡æŸ“ |\n| **Extraction Engine** | æ ¸å¿ƒï¼šåŸºäº `playwright` + `beautifulsoup4` + è‡ªå®šä¹‰è§„åˆ™å¼•æ“ï¼Œæ‰§è¡Œ JS â†’ æ¸²æŸ“ DOM â†’ æå–è¯­ä¹‰ç»“æ„ â†’ è¾“å‡º Markdown |\n| **Output Formatter** | å°†æå–ç»“æœæ ‡å‡†åŒ–ä¸º JSON Schemaï¼ˆtitle, content, links, metadata.score, source_urlï¼‰ï¼Œé€‚é… LLM è¾“å…¥æ ¼å¼ |\n| **Cache Layer** | åŸºäºè¯·æ±‚æŒ‡çº¹ç¼“å­˜å“åº”ï¼Œæ”¯æŒ TTL å’Œå¼ºåˆ¶åˆ·æ–°ã€‚é¿å…é‡å¤çˆ¬å–ç›¸åŒè¯­ä¹‰é¡µé¢ |\n\n### æ•°æ®æµå‘\n\n```\nHTTP POST /crawl\n  â†’ { url: \"https://example.com/article\", extract_content: true, timeout: 15000 }\n        â†“\n[API Gateway] â†’ éªŒè¯ API Key â†’ æ ¡éªŒ URL\n        â†“\n[Job Queue] â†’ ç”Ÿæˆ request_hash = SHA256(url + headers + js_exec_config)\n        â†“\n[Cache Layer] â†’ HIT? è¿”å›ç¼“å­˜ Markdown â†’ YES: ç»“æŸ\n        â†“ NO\n[Browser Pool] â†’ åˆ†é…ç©ºé—² Playwright å®ä¾‹ â†’ å¯åŠ¨æµè§ˆå™¨ â†’ å¯¼èˆªè‡³ URL\n        â†“\n[JS Execution] â†’ æ‰§è¡Œç”¨æˆ·å®šä¹‰è„šæœ¬ï¼ˆå¦‚ç‚¹å‡»â€œåŠ è½½æ›´å¤šâ€ï¼‰\n        â†“\n[DOM Analysis] â†’ ä½¿ç”¨ CSS é€‰æ‹©å™¨ + å†…å®¹å¯†åº¦ç®—æ³•å®šä½ä¸»ä½“å†…å®¹\n        â†“\n[Markdown Generation] â†’ è½¬æ¢ä¸º GitHub-flavored Markdownï¼Œä¿ç•™ H1â€“H4ã€code blockã€blockquote\n        â†“\n[Metadata Enrichment] â†’ æå–é“¾æ¥å›¾è°±ã€è¯­è¨€æ£€æµ‹ã€æ–‡æœ¬ç†µè¯„åˆ†ï¼ˆ0â€“1ï¼‰\n        â†“\n[Output Formatter] â†’ { \"content\": \"# Title\\n\\nParagraph...\", \"metadata\": { \"score\": 0.92, \"links\": [...] } }\n        â†“\n[Cache Layer] â†’ å­˜å…¥ Redis (key: hash, ttl: 3600)\n        â†“\n[Webhook] â†’ POST to user endpoint with status=success\n```\n\n### å…³é”®è®¾è®¡æ¨¡å¼\n\n- **ç­–ç•¥æ¨¡å¼ï¼ˆStrategy Patternï¼‰**ï¼šæå–è§„åˆ™ï¼ˆå¦‚â€œè·³è¿‡å¹¿å‘Šâ€ã€â€œä¿ç•™ä»£ç å—â€ï¼‰å¯æ’æ‹”ï¼Œæ”¯æŒè‡ªå®šä¹‰ `ExtractorStrategy` æ¥å£ã€‚\n- **å·¥å‚æ¨¡å¼ï¼ˆFactory Patternï¼‰**ï¼šBrowserPoolManager é€šè¿‡ `BrowserFactory.create()` å®ä¾‹åŒ–ä¸åŒé…ç½®çš„ Playwright å®ä¾‹ï¼ˆä»£ç†/æ— å¤´/è®¾å¤‡æ¨¡æ‹Ÿï¼‰ã€‚\n- **è§‚å¯Ÿè€…æ¨¡å¼ï¼ˆObserver Patternï¼‰**ï¼šä»»åŠ¡çŠ¶æ€å˜æ›´ â†’ è§¦å‘ Webhook è®¢é˜…è€…ã€‚æ”¯æŒå¤šç«¯ç‚¹ã€é‡è¯•ç­–ç•¥ã€‚\n- **å‘½ä»¤æ¨¡å¼ï¼ˆCommand Patternï¼‰**ï¼šæ¯ä¸ªçˆ¬å–è¯·æ±‚å°è£…ä¸º `CrawlCommand` å¯¹è±¡ï¼Œå¯åºåˆ—åŒ–ã€é‡æ”¾ã€å®¡è®¡ã€‚\n\n## ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| æŠ€æœ¯ | é€‰æ‹©ç†ç”± | æ›¿ä»£æ–¹æ¡ˆ | æ³¨æ„äº‹é¡¹ |\n|------|----------|----------|----------|\n| **Playwright (Python)** | åŸç”Ÿæ”¯æŒå¼‚æ­¥ã€è‡ªåŠ¨ç­‰å¾…ã€ç½‘ç»œæ‹¦æˆªã€è®¾å¤‡æ¨¡æ‹Ÿã€‚æ¯” Selenium ç¨³å®šï¼Œæ¯” Puppeteer æ›´è½»é‡ï¼ˆPython ç”Ÿæ€å‹å¥½ï¼‰ | Puppeteer + pyppeteer, Selenium | å¿…é¡»ä½¿ç”¨ `playwright>=1.40` ä»¥å…¼å®¹ Chromium 123+ï¼›æ—§ç‰ˆå­˜åœ¨å†…å­˜æ³„æ¼ |\n| **Pydantic v2** | å¼ºç±»å‹è¯·æ±‚/å“åº” Schemaï¼Œè‡ªåŠ¨ç”Ÿæˆ OpenAPI æ–‡æ¡£ã€‚æ”¯æŒ `Field(..., json_schema_extra={})` ç²¾ç¡®æ§åˆ¶ API æ–‡æ¡£ç”Ÿæˆ | dataclasses, attrs | å¿…é¡»ä½¿ç”¨ Python 3.8+ï¼›ä¸ FastAPI æ·±åº¦é›†æˆ |\n| **Redis** | é«˜æ€§èƒ½ç¼“å­˜ + ä»»åŠ¡é˜Ÿåˆ—ï¼ˆStreamsï¼‰ã€‚æ”¯æŒåŸå­æ“ä½œã€TTLã€æŒä¹…åŒ–ã€‚æ¯” SQLite æ›´é€‚åˆåˆ†å¸ƒå¼éƒ¨ç½² | RabbitMQ, Kafka, PostgreSQL | ç¼“å­˜é”®éœ€åŒ…å« `user_agent`, `proxy`, `js_exec` å‚æ•°ï¼Œå¦åˆ™è¯¯å‘½ä¸­ |\n| **FastAPI** | å¼‚æ­¥æ”¯æŒã€è‡ªåŠ¨ç”Ÿæˆ OpenAPI æ–‡æ¡£ã€ä½å»¶è¿Ÿã€‚æ¯” Flask æ›´é€‚åˆé«˜å¹¶å‘ API | Sanic, Starlette | ä¾èµ– uvicornï¼›å¿…é¡»å¯ç”¨ `--workers 4+` ç”Ÿäº§éƒ¨ç½² |\n| **BeautifulSoup4 + lxml** | å¿«é€Ÿ HTML è§£æï¼Œé…åˆ CSS é€‰æ‹©å™¨ç²¾å‡†å®šä½å…ƒç´ ã€‚lxml æ¯” html.parser æ€§èƒ½é«˜ 3x | pyquery, Trafilatura | é¿å…ä½¿ç”¨ `html5lib` â€”â€” å¤ªæ…¢ï¼›éœ€å®‰è£… `lxml` C æ‰©å±• |\n| **Docker** | å®ç°æµè§ˆå™¨å®ä¾‹çš„éš”ç¦»éƒ¨ç½²ï¼Œæ”¯æŒå¼¹æ€§ä¼¸ç¼©ã€‚é¿å… Playwright åœ¨å¤šçº¿ç¨‹ä¸­å´©æºƒæ±¡æŸ“ä¸»è¿›ç¨‹ | Kubernetes, Nomad | å®¹å™¨å†…å¿…é¡»å¯ç”¨ `--no-sandbox` å’Œå…±äº«å†…å­˜ `/dev/shm:1G` |\n\n## ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨è Python 3.9â€“3.12ï¼‰\npython -m venv crawl4ai-env\nsource crawl4ai-env/bin/activate  # Windows: crawl4ai-env\\Scripts\\activate\n\n# 2. å®‰è£…æ ¸å¿ƒåŒ…ï¼ˆPyPI å‘å¸ƒç‰ˆï¼‰\npip install \"crawl4ai[all]\"  # åŒ…å« Playwrightã€Redisã€FastAPIã€lxml ç­‰å…¨éƒ¨ä¾èµ–\n\n# 3. ä¸‹è½½æµè§ˆå™¨é©±åŠ¨ï¼ˆPlaywright è‡ªåŠ¨ç®¡ç†ï¼Œä½†éœ€é¦–æ¬¡åˆå§‹åŒ–ï¼‰\nplaywright install chromium  # å®‰è£… Chromium åŸºç¡€å†…æ ¸\nplaywright install-deps      # å®‰è£…ç³»ç»Ÿä¾èµ–ï¼ˆå¦‚ libnss3, libatk-bridge2.0ï¼‰\n\n# 4. ï¼ˆå¯é€‰ï¼‰å¯åŠ¨æœ¬åœ°æœåŠ¡ç«¯ï¼ˆç”¨äºç”Ÿäº§éƒ¨ç½²ï¼‰\n# å¯åŠ¨ API + ç›‘æ§é¢æ¿ï¼ˆé»˜è®¤ç›‘å¬ 8000ï¼‰\npython -m crawl4ai.server\n\n# 5. é…ç½®ç¯å¢ƒå˜é‡ï¼ˆ.env æ–‡ä»¶ï¼Œæ¨èï¼‰\nCRAWL4AI_API_KEY=your-secret-key-here\nCRAWL4AI_REDIS_URL=redis://localhost:6379/0\nCRAWL4AI_MAX_CONCURRENT_BROWSERS=10\nCRAWL4AI_TIMEOUT_MS=20000\nCRAWL4AI_PROXY_LIST=http://user:pass@proxy1.com:8080,http://user:pass@proxy2.com:8080\n\n# 6. éªŒè¯å®‰è£…\npython -c \"from crawl4ai import Crawl4AI; print('âœ… Success')\"\n```\n\n## ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n```python\nfrom crawl4ai import Crawl4AI\nimport asyncio\n\nasync def main():\n    # åˆå§‹åŒ–çˆ¬è™«å®ä¾‹ï¼ˆæ”¯æŒ API å¯†é’¥è®¤è¯ï¼‰\n    crawler = Crawl4AI(\n        api_key=\"your-api-key\",  # å¯é€‰ï¼Œè‹¥ä½¿ç”¨äº‘æœåŠ¡\n        timeout=15000,           # æ¯«ç§’è¶…æ—¶\n        wait_for_elements=[\".article-content\"],  # ç­‰å¾…ç‰¹å®šå…ƒç´ åŠ è½½\n        extract_content=True,\n        remove_selectors=[\"nav\", \"footer\", \".ads\"],\n        js_code=\"\"\"\n          // è‡ªå®šä¹‰ JSï¼šç‚¹å‡»â€œåŠ è½½æ›´å¤šâ€æŒ‰é’®\n          document.querySelector('.load-more').click();\n          await new Promise(r => setTimeout(r, 3000));\n        \"\"\",\n    )\n\n    # çœŸå®åœºæ™¯ï¼šçˆ¬å–ä¸€ç¯‡æŠ€æœ¯åšå®¢ï¼ˆå«åŠ¨æ€åŠ è½½ï¼‰\n    url = \"https://example-blog.com/llm-rag-best-practices\"\n\n    result = await crawler.async_crawl(url)\n\n    print(\"âœ… æå–å®Œæˆ\")\n    print(f\"æ ‡é¢˜: {result.title}\")\n    print(f\"å†…å®¹é•¿åº¦: {len(result.content)} å­—ç¬¦\")\n    print(f\"è¯­ä¹‰è´¨é‡è¯„åˆ†: {result.metadata.score:.2f}\")\n    print(f\"æå–é“¾æ¥æ•°: {len(result.metadata.links)}\")\n\n    # è¾“å‡ºä¸º Markdownï¼Œç›´æ¥å–‚ç»™ LLM\n    print(\"\\n--- MARKDOWN ---\\n\")\n    print(result.content)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n**é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼š**\n```markdown\n# LLM RAG Best Practices in 2025\n\n## Chunking Strategies\n\nText chunking is critical for retrieval quality. We recommend:\n- **Semantic chunking**: Use sentence transformers to split at natural boundaries.\n- **Overlap**: 10â€“15% overlap between chunks to preserve context.\n\n## Indexing with Vector DBs\n\nUse Qdrant or Milvus over FAISS for production:\n- Supports metadata filtering\n- Auto-replication and sharding\n- Built-in hybrid search (keyword + vector)\n\n## Retrieval Augmentation\n\nCombine BM25 with dense embeddings:\n```python\nretriever = HybridRetriever(\n",
    "last_scanned": "2026-01-16T02:03:15.397640",
    "last_analyzed": "2026-01-15T10:53:34.819890",
    "screenshot": "static/screenshots/798201435.jpg",
    "ai_visual_summary": "è¯¥ç•Œé¢æ˜¯ `crawl4ai` é¡¹ç›®çš„ GitHub ä»“åº“ `README` æ–‡ä»¶ï¼Œé‡‡ç”¨ç®€æ´çš„æ–‡æ¡£å¼è®¾è®¡é£æ ¼ï¼Œä»¥æ¸…æ™°çš„æ ‡é¢˜å’Œåˆ—è¡¨ç»„ç»‡ä¿¡æ¯ã€‚ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬é¡¹ç›®åŠŸèƒ½ä»‹ç»ï¼ˆå¦‚æ‰§è¡Œ JavaScriptã€æå–ç»“æ„åŒ–æ•°æ®ï¼‰ã€ä½¿ç”¨æŠ€å·§ï¼ˆå¦‚å¤„ç† CAPTCHAï¼‰å’Œç‰ˆæœ¬æ›´æ–°æ—¥å¿—ã€‚æŠ€æœ¯å…³é”®è¯å¦‚ `LLM`ï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰ã€`CAPTCHA`ã€`reCAPTCHA`ã€`Docker` å’Œ `Python` æ˜ç¡®æŒ‡å‡ºè¯¥é¡¹ç›®æ˜¯ä¸€ä¸ªé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„å¼€æºç½‘ç»œçˆ¬è™«ä¸æ•°æ®æå–å·¥å…·ï¼Œå…¶æ ¸å¿ƒåŠŸèƒ½æ˜¯è‡ªåŠ¨åŒ–åœ°ä»ç½‘é¡µä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œå¹¶æ”¯æŒå¤„ç†åçˆ¬è™«æœºåˆ¶ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "571186647",
    "name": "pathway",
    "full_name": "pathwaycom/pathway",
    "category": "llm_rag",
    "stars": 57115,
    "forks": 1545,
    "description": "Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.",
    "url": "https://github.com/pathwaycom/pathway",
    "homepage": "https://pathway.com",
    "language": "Python",
    "topics": "[\"batch-processing\", \"data-analytics\", \"data-pipelines\", \"data-processing\", \"dataflow\", \"etl\", \"etl-framework\", \"iot-analytics\", \"kafka\", \"machine-learning-algorithms\", \"pathway\", \"python\", \"real-time\", \"rust\", \"stream-processing\", \"streaming\", \"time-series-analysis\"]",
    "created_at": "2022-11-27T13:01:14Z",
    "updated_at": "2026-01-15T18:03:01Z",
    "readme_content": null,
    "ai_summary": "Pathway æ˜¯ä¸€ä¸ªåŸºäº Python çš„ ETL æ¡†æ¶ï¼Œä¸“æ³¨äºæµå¤„ç†ã€å®æ—¶åˆ†æã€LLM ç®¡é“å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åº”ç”¨ã€‚å…¶æ ¸å¿ƒç‰¹ç‚¹æ˜¯æä¾›ç»Ÿä¸€çš„ä»£ç æ¥å£æ”¯æŒæ‰¹å¤„ç†ä¸æµå¼æ•°æ®ï¼Œå¹¶æ— ç¼é›†æˆä¸»æµ ML åº“ã€‚",
    "ai_tech_stack": "[\"Python\", \"ETL\\u6846\\u67b6\", \"Apache Spark/Flink\\u517c\\u5bb9\\u6027\", \"\\u5206\\u5e03\\u5f0f\\u8ba1\\u7b97\"]",
    "ai_use_cases": "[\"\\u5b9e\\u65f6\\u6570\\u636e\\u5206\\u6790\\u7ba1\\u9053\", \"\\u68c0\\u7d22\\u589e\\u5f3a\\u751f\\u6210\\uff08RAG\\uff09\\u7cfb\\u7edf\\u5f00\\u53d1\", \"\\u673a\\u5668\\u5b66\\u4e60\\u6a21\\u578b\\u6d41\\u6c34\\u7ebf\\u96c6\\u6210\", \"\\u6d41\\u5f0f\\u6570\\u636e\\u5904\\u7406\\u4e0e\\u8f6c\\u6362\"]",
    "ai_difficulty": 3,
    "ai_quick_start": "pip install pathway && echo 'å®‰è£…å®Œæˆï¼Œè¿è¡Œç¤ºä¾‹éœ€æŸ¥çœ‹å®˜æ–¹æ–‡æ¡£'",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nPathway çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äºï¼š**ç”¨ Python ç¼–å†™è¯­ä¹‰ç­‰ä»·äºå¢é‡æµå¼è®¡ç®—çš„ç¨‹åºï¼Œå´ç”±åº•å±‚ Rust å¼•æ“ä»¥ Differential Dataflow ä¸ºå†…æ ¸å®ç°é›¶é‡å¤ã€ä½å»¶è¿Ÿã€é«˜ååçš„æœ‰çŠ¶æ€æµå¤„ç†**ã€‚å®ƒè§£å†³äº†ä¼ ç»Ÿ ETL/æµå¤„ç†æ¡†æ¶çš„ä¸‰å¤§ç—›ç‚¹ï¼š\n\n1. **å¼€å‘ä½“éªŒä¸æ€§èƒ½çš„å‰²è£‚**ï¼šFlink/Spark Structured Streaming è¦æ±‚ç”¨ Scala/Java æˆ–å—é™çš„ SQLï¼ŒPython åªèƒ½ä½œä¸º UDF æŒ‚è½½ï¼›è€Œ Pandas/Dask æ— æ³•åšå¢é‡æ›´æ–°ã€‚Pathway è®©ä½ ç”¨çº¯ Python å†™å‡ºç­‰æ•ˆäº Kafka Streams + Materialized Views çš„é€»è¾‘ï¼Œå´è·å¾—äºšç§’çº§å»¶è¿Ÿä¸ TB çº§ååã€‚\n2. **æ‰¹æµä¸€ä½“çš„è¯­ä¹‰ä¸€è‡´æ€§**ï¼šåŒä¸€æ®µä»£ç å¯æ— ç¼åœ¨æ‰¹ï¼ˆæ–‡ä»¶ï¼‰ã€æµï¼ˆKafkaï¼‰ã€æ¨¡æ‹Ÿï¼ˆå†…å­˜ç”Ÿæˆå™¨ï¼‰æ¨¡å¼é—´åˆ‡æ¢ã€‚æ— éœ€é‡å†™é€»è¾‘ï¼Œåªéœ€æ”¹è¾“å…¥æºâ€”â€”è¿™æ˜¯å”¯ä¸€å®ç°â€œwrite once, run anywhereâ€è¯­ä¹‰çš„ Python æ¡†æ¶ã€‚\n3. **LLM/RAG åŸç”Ÿé›†æˆ**ï¼šä¼ ç»Ÿ RAG æµæ°´çº¿éœ€æ‰‹åŠ¨ç®¡ç†å‘é‡åº“æ›´æ–°ã€æ£€ç´¢ç¼“å­˜å¤±æ•ˆã€ç»“æœåˆå¹¶ã€‚Pathway ç”¨ `pw.iterate()` å’Œ `pw.window` è‡ªåŠ¨æ„å»ºåŠ¨æ€ä¸Šä¸‹æ–‡çª—å£ï¼Œå®ç°â€œæ–‡æ¡£å˜æ›´ â†’ å‘é‡é‡ç®— â†’ æ£€ç´¢ç»“æœåˆ·æ–°â€é—­ç¯ï¼Œæ— éœ€å¤–éƒ¨è°ƒåº¦å™¨ã€‚\n\nå®ƒä¸æ˜¯å¦ä¸€ä¸ªâ€œPython å°è£…çš„æµå¼•æ“â€ï¼Œè€Œæ˜¯**ç¬¬ä¸€ä¸ªè®© Python å¼€å‘è€…èƒ½ä»¥å£°æ˜å¼å‡½æ•°å¼é£æ ¼ï¼Œç›´æ¥æ“ä½œæœ‰çŠ¶æ€å¢é‡æ•°æ®æµçš„ç”Ÿäº§çº§æ¡†æ¶**ã€‚\n\n---\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n1. **Differential Dataflow æ ¸å¿ƒå¼•æ“**ï¼š  \n   Rust å®ç°çš„ DDï¼ˆDifferential Dataflowï¼‰æ˜¯å¾®è½¯ Research çš„æ ¸å¿ƒæˆæœï¼Œæ”¯æŒï¼š\n   - **å¢é‡æ›´æ–°**ï¼šåªè®¡ç®—è¾“å…¥å˜åŒ–éƒ¨åˆ†ï¼Œä¸é‡ç®—å…¨é‡ã€‚\n   - **æ—¶é—´æˆ³è¯­ä¹‰**ï¼šæ¯æ¡è®°å½•å¸¦é€»è¾‘æ—¶é’Ÿï¼Œæ”¯æŒä¹±åºã€å»¶è¿Ÿã€æ°´å°ã€‚\n   - **åµŒå¥—é›†åˆ**ï¼šæµä¸­å¯åŒ…å«æµï¼ˆå¦‚æ¯ä¸ªç”¨æˆ·æœ‰ç‹¬ç«‹ä¼šè¯æµï¼‰ï¼Œæ— éœ€ JOINã€‚\n\n2. **Python AST â†’ Rust IR ç¼–è¯‘å™¨**ï¼š  \n   Pathway ä¸æ˜¯è§£é‡Šæ‰§è¡Œ Python ä»£ç ã€‚å®ƒé€šè¿‡ `ast` æ¨¡å—è§£æç”¨æˆ·å‡½æ•°ï¼Œç¼–è¯‘ä¸ºä¸­é—´è¡¨ç¤ºï¼ˆIRï¼‰ï¼Œå†ç”± Rust å¼•æ“ JIT ç¼–è¯‘ä¸ºé«˜æ•ˆæŒ‡ä»¤ã€‚è¿™æ„å‘³ç€ï¼š\n   - æ—  GIL é˜»å¡ï¼šè®¡ç®—çº¿ç¨‹å®Œå…¨å¹¶è¡Œã€‚\n   - å‡½æ•°é—­åŒ…è¢«æ•è·å¹¶åºåˆ—åŒ–åˆ°å¼•æ“å†…å­˜ã€‚\n   - æ”¯æŒ `lambda`ã€`map`ã€`filter`ã€`groupby` ç­‰é«˜é˜¶å‡½æ•°çš„é›¶å¼€é”€ç¿»è¯‘ã€‚\n\n3. **å†…å­˜é©»ç•™çŠ¶æ€ç®¡ç†**ï¼š  \n   æ‰€æœ‰ä¸­é—´èšåˆï¼ˆå¦‚çª—å£è®¡æ•°ã€å‘é‡ç´¢å¼•ï¼‰éƒ½é©»ç•™åœ¨å¼•æ“å†…å­˜ä¸­ï¼Œè€Œéå†™å…¥å¤–éƒ¨å­˜å‚¨ã€‚è¿™ä½¿å¾—ï¼š\n   - æ£€ç´¢å»¶è¿Ÿ < 10ms\n   - æ›´æ–°åå > 50K events/sec/nodeï¼ˆå®æµ‹ï¼‰\n   - æ”¯æŒå®æ—¶ RAG çš„â€œåŠ¨æ€ä¸Šä¸‹æ–‡â€â€”â€”æ–‡æ¡£å˜æ›´åï¼Œæ£€ç´¢ç»“æœè‡ªåŠ¨åˆ·æ–°ï¼Œæ— éœ€é‡å¯æœåŠ¡ã€‚\n\n4. **è¿­ä»£ç®—å­ (`pw.iterate`)**ï¼š  \n   å®ç°äº†**æµå¼åé¦ˆå¾ªç¯**ï¼Œç”¨äº LLM æ‘˜è¦ç”Ÿæˆã€å¤šè½®å¯¹è¯çŠ¶æ€æœºç­‰åœºæ™¯ã€‚ä¾‹å¦‚ï¼š\n   ```python\n   output = pw.iterate(\n       lambda x: llm_summarize(x),  # è¾“å…¥æ˜¯å½“å‰æ–‡æœ¬æµ\n       initial=initial_context,\n       update=True\n   )\n   ```\n   æ¯æ¬¡è¾“å…¥æ›´æ–°ï¼Œè¾“å‡ºè¢«å¢é‡é‡ç®—ï¼Œé¿å…é‡å¤è°ƒç”¨ LLMã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n#### 1. æ•´ä½“æ¶æ„ï¼ˆæ–‡å­—æè¿°ï¼‰\n\n```\n[Python User Code] \n        â†“ (AST è§£æ + IR ç¼–è¯‘)\n[Pathway Python Runtime]\n        â†“ (gRPC/IPC)\n[Rust Engine Core (Differential Dataflow)]\nâ”œâ”€â”€ Stream Graph Scheduler\nâ”œâ”€â”€ State Store (in-memory key-value, sharded)\nâ”œâ”€â”€ Time Manager (logical clocks, watermarks)\nâ”œâ”€â”€ Connector Adapter Layer\nâ””â”€â”€ JIT Compiler (LLVM-based)\n\n        â†“\n[Output: Kafka / REST / Redis / Websocket]\n```\n\n#### 2. æ ¸å¿ƒæ¨¡å—èŒè´£\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| **Python Runtime** | è§£æç”¨æˆ·å‡½æ•°ã€æ„å»ºå›¾ç»“æ„ã€åºåˆ—åŒ–é—­åŒ…ã€ç®¡ç†è¿æ¥å™¨ç”Ÿå‘½å‘¨æœŸ |\n| **Rust Engine** | æ‰§è¡Œå¢é‡è®¡ç®—å›¾ï¼Œç»´æŠ¤çŠ¶æ€å¿«ç…§ï¼Œå¤„ç†æ—¶é—´è¯­ä¹‰ï¼Œè°ƒåº¦ä»»åŠ¡ |\n| **Connector Layer** | æ”¯æŒ Kafka, PostgreSQL CDC, S3, WebSocket, HTTP ç­‰è¾“å…¥/è¾“å‡ºæºï¼Œç»Ÿä¸€ä¸º `pw.stream` / `pw.table` æŠ½è±¡ |\n| **State Store** | åŸºäº RocksDB çš„å†…å­˜æ˜ å°„é”®å€¼å­˜å‚¨ï¼Œæ”¯æŒå¿«ç…§ã€å¢é‡æ¢å¤ã€åˆ†åŒº |\n\n#### 3. æ•°æ®æµå‘\n\n```\nInput (Kafka topic) \nâ†’ pw.read_kafka() â†’ [Stream Table] \nâ†’ .groupby().reduce() â†’ [Agg Table]  \nâ†’ .join(other_table, on=...) â†’ [Enriched Table]\nâ†’ .apply(llm_rag_function) â†’ [LLM Output]\nâ†’ pw.write_redis() â†’ å®æ—¶ç¼“å­˜\n```\n\næ‰€æœ‰ä¸­é—´çŠ¶æ€éƒ½**ä¿æŒä¸ºå¢é‡è¡¨ï¼ˆTableï¼‰**ï¼Œè€Œéæµã€‚æ¯ä¸ª Table æ˜¯ä¸€ä¸ªæŒç»­æ›´æ–°çš„é”®å€¼é›†åˆï¼Œæ”¯æŒ JOINã€WINDOWã€ITERATEã€‚\n\n#### 4. å…³é”®è®¾è®¡æ¨¡å¼\n\n- **å‡½æ•°å¼ä¸å˜æ€§ + å¢é‡æ›´æ–°**ï¼šç”¨æˆ·å†™çº¯å‡½æ•°ï¼ˆæ— å‰¯ä½œç”¨ï¼‰ï¼Œå¼•æ“è‡ªåŠ¨è¿½è¸ªå˜æ›´å·®é›†ï¼ˆdiffï¼‰ã€‚  \n  â†’ *ä¸ºä»€ä¹ˆï¼Ÿ* ç¡®ä¿å¯é‡æ”¾ã€å¯æ¢å¤ã€å¯å¹¶è¡Œã€‚\n  \n- **Table-as-State æ¨¡å¼**ï¼šæ‰€æœ‰ä¸­é—´ç»“æœæ˜¯ `pw.Table`ï¼Œè€Œé `Iterator`ã€‚  \n  â†’ *ä¸ºä»€ä¹ˆï¼Ÿ* æ”¯æŒä»»æ„æ—¶é—´ç‚¹çš„ JOIN å’ŒæŸ¥è¯¢ï¼Œå®ç°â€œå®æ—¶è§†å›¾â€è¯­ä¹‰ã€‚\n\n- **Pipeline Composition via Method Chaining**ï¼šç±»ä¼¼ Pandasï¼Œä½†è¯­ä¹‰æ›´ä¸¥æ ¼ï¼ˆç±»å‹å®‰å…¨ã€ç¡®å®šæ€§æ‰§è¡Œï¼‰ã€‚  \n  â†’ *ä¸ºä»€ä¹ˆï¼Ÿ* é™ä½å­¦ä¹ æˆæœ¬ï¼Œå¤ç”¨ Python å¼€å‘è€…è‚Œè‚‰è®°å¿†ã€‚\n\n---\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| ç»„ä»¶ | é€‰æ‹©ç†ç”± | æ›¿ä»£æ–¹æ¡ˆ | æ³¨æ„äº‹é¡¹ |\n|------|----------|-----------|----------|\n| **Rust** | å†…å­˜å®‰å…¨ã€é›¶å¼€é”€æŠ½è±¡ã€å¹¶å‘æ—  GILã€å¯åµŒå…¥ Python | Go, C++ | å¿…é¡»åŒ¹é… Rust ç¼–è¯‘å™¨ç‰ˆæœ¬ï¼ˆ`pathway` ä¼šé¢„ç¼–è¯‘äºŒè¿›åˆ¶ï¼‰ |\n| **Differential Dataflow** | å”¯ä¸€æ”¯æŒåµŒå¥—æµã€ä½å»¶è¿Ÿå¢é‡æ›´æ–°çš„å¼€æºå¼•æ“ | Apache Flink, Materialize | ä¸å¯æ›¿æ¢ï¼šFlink çš„çª—å£æ˜¯æ—¶é—´æˆ³ï¼ŒPathway æ˜¯é€»è¾‘æ—¶é’Ÿï¼ˆæ›´çµæ´»ï¼‰ |\n| **Python 3.9+** | ç”Ÿæ€ä¸°å¯Œï¼ˆPyTorch, langchainï¼‰ã€AST æ”¯æŒå¥½ | PyPy, Jython | å¿…é¡»ç”¨ CPythonï¼›ä¸æ”¯æŒå¼‚æ­¥å‡½æ•°ï¼ˆ`async def` ä¸å¯ç”¨ï¼‰ |\n| **PyO3 / maturin** | é«˜æ•ˆç»‘å®š Rust ä¸ Pythonï¼Œæ”¯æŒ Wheel æ‰“åŒ… | Cython, cffi | `pip install pathway` è‡ªåŠ¨ä¸‹è½½é¢„ç¼–è¯‘ wheelï¼Œæ— éœ€æœ¬åœ°ç¼–è¯‘ |\n| **RocksDB** | é«˜æ€§èƒ½åµŒå…¥å¼ KVï¼Œæ”¯æŒå¿«ç…§å’Œå‹ç¼© | LevelDB, BoltDB | é»˜è®¤å†…å­˜æ˜ å°„ï¼Œç”Ÿäº§ç¯å¢ƒéœ€è°ƒä¼˜ `max_open_files` |\n\n> âš ï¸ æ³¨æ„ï¼šPathway ä¸å…¼å®¹ Python 3.8 åŠä»¥ä¸‹ã€‚å®‰è£…æ—¶è‹¥æŠ¥é”™â€œno wheel for your platformâ€ï¼Œéœ€å‡çº§ pip åˆ° >=21.0ã€‚\n\n---\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. ç¡®ä¿ Python 3.9+ (æ¨è pyenv)\npython --version  # è¾“å‡ºåº”ä¸º 3.9.x æˆ–æ›´é«˜\n\n# 2. å‡çº§ pipï¼ˆé¿å…æ—§ç‰ˆæ— æ³•è§£æ wheelï¼‰\npip install --upgrade pip\n\n# 3. å®‰è£… pathwayï¼ˆè‡ªåŠ¨ä¸‹è½½é¢„ç¼–è¯‘ Rust äºŒè¿›åˆ¶ï¼‰\npip install -U pathway\n\n# 4. éªŒè¯å®‰è£…\npython -c \"import pathway as pw; print(pw.__version__)\"\n\n# 5. ï¼ˆå¯é€‰ï¼‰å®‰è£…å¼€å‘ä¾èµ–ï¼ˆç”¨äºè°ƒè¯•/è´¡çŒ®ï¼‰\npip install pathway[dev]  # åŒ…å« pytest, black, mypy ç­‰\n```\n\n> âœ… æ‰€æœ‰å¹³å°ï¼ˆLinux/macOS/Windows WSL2ï¼‰å‡æ”¯æŒã€‚Windows åŸç”Ÿä¸æ”¯æŒï¼Œéœ€ç”¨ WSL2ã€‚\n\n---\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n#### åœºæ™¯ï¼šå®æ—¶é—®ç­”æœºå™¨äººï¼ˆRAGï¼‰\n\nè¾“å…¥ï¼šç”¨æˆ·æé—®æµï¼ˆKafka topic `questions`ï¼‰ï¼Œæ–‡æ¡£æ›´æ–°æµï¼ˆPostgreSQL CDC è¡¨ `documents`ï¼‰  \nè¾“å‡ºï¼šè‡ªåŠ¨å›å¤æµï¼ˆå†™å…¥ Redisï¼‰\n\n```python\nimport pathway as pw\nfrom pathway.xpacks.llm import embedders, llms\nfrom pathway.xpacks.llm.vector_store import VectorStore\n\n# 1. è¾“å…¥æº\nquestions = pw.io.kafka.read(\n    kafka_settings=pw.kafka.Settings(\n        bootstrap_servers=\"localhost:9092\",\n        topic=\"questions\"\n    ),\n    format=\"json\",\n    value_columns=[\"user_id\", \"text\"],\n    types={\"user_id\": str, \"text\": str}\n)\n\ndocuments = pw.io.postgres.read(\n    table_name=\"documents\",\n    connection_params={\n        \"host\": \"localhost\",\n        \"port\": 5432,\n        \"database\": \"docs\",\n        \"user\": \"postgres\"\n    },\n    update_mode=\"append\",  # CDC æ¨¡å¼\n    value_columns=[\"id\", \"content\", \"title\"],\n    types={\"id\": int, \"content\": str, \"title\": str}\n)\n\n# 2. å‘é‡åŒ–æ–‡æ¡£\nembedder = embedders.OpenAIEmbedder()\ndocument_vectors = documents.select(\n    id=pw.this.id,\n    content=pw.this.content,\n    vector=embedder(pw.this.content)\n)\n\n# 3. æ„å»ºå‘é‡ç´¢å¼•ï¼ˆå®æ—¶æ›´æ–°ï¼‰\nvector_store = VectorStore(document_vectors, embedding_column=\"vector\")\n\n# 4. å¯¹æ¯ä¸ªé—®é¢˜æ£€ç´¢ top-2 æ–‡æ¡£\ncontext = questions.select(\n    question=pw.this.text,\n    context=vector_store.retrieve(pw.this.text, k=2)\n)\n\n# 5. è°ƒç”¨ LLM ç”Ÿæˆå›ç­”\nllm = llms.OpenAIChatLLM(model=\"gpt-4-turbo\")\nanswers = context.select(\n    user_id=pw.this.user_id,\n    answer=llm(\n        prompt_template=\"\"\"\n        Use the following context to answer:\n        {context}\n        \n        Question: {question}\n        Answer concisely.\n        \"\"\",\n        question=pw.this.question,\n        context=pw.this.context\n    )\n)\n\n# 6. è¾“å‡ºåˆ° Redis\npw.io.redis.write(answers, host=\"localhost\", port=6379, key_prefix=\"answer:\")\n\n# 7. å¯åŠ¨ç®¡é“ï¼ˆé˜»å¡è¿è¡Œï¼‰\npw.run()\n```\n\n#### é¢„æœŸè¾“å‡ºï¼š\n\nRedis ä¸­ç”Ÿæˆé”®å€¼ï¼š\n```\n\"answer:user_123\" â†’ \"Based on the document about Pathway's stream engine, it uses Differential Dataflow for incremental updates.\"\n```\n\n#### å…³é”®å‚æ•°è¯´æ˜ï¼š\n\n- `update_mode=\"append\"`ï¼šPostgreSQL CDC æ¨¡å¼ï¼Œè‡ªåŠ¨ç›‘å¬ `INSERT/UPDATE`ã€‚\n- `k=2`ï¼šæ£€ç´¢æœ€ç›¸å…³çš„ 2 ç¯‡æ–‡æ¡£ï¼Œæ§åˆ¶ LLM ä¸Šä¸‹æ–‡é•¿åº¦ã€‚\n- `VectorStore`ï¼šå†…å­˜ä¸­ç»´æŠ¤ FAISS + å¢é‡æ›´æ–°ç´¢å¼•ï¼Œæ”¯æŒæ¯ç§’æ•°åƒæ¬¡æŸ¥è¯¢ã€‚\n\n---\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n| æŒ‡æ ‡ | é¢„ä¼°å€¼ï¼ˆå•èŠ‚ç‚¹ï¼‰ | è¯´æ˜ |\n|------|------------------|------|\n| ååé‡ | 50K+ events/sec | åŸºäº Rust å¼•æ“ï¼Œæ—  GC åœé¡¿ |\n| æŸ¥è¯¢å»¶è¿Ÿ | <10ms (P99) | VectorStore æ£€ç´¢ + LLM è°ƒç”¨å‡å¼‚æ­¥æµæ°´çº¿ |\n| å†…å­˜å ç”¨ | ~2GBï¼ˆå« 10K å‘é‡ï¼‰ | FAISS ç´¢å¼• + å¢é‡è¡¨çŠ¶æ€ç¼“å­˜ |\n| æ‰©å±•æ€§ | æ”¯æŒ Kubernetes å¤šå‰¯æœ¬ | æ¯ä¸ª Pod æ˜¯ç‹¬ç«‹è®¡ç®—å•å…ƒï¼Œé€šè¿‡ Kafka åˆ†åŒºå®ç°æ°´å¹³æ‰©å±• |\n\n#### æ€§èƒ½ç“¶é¢ˆï¼š\n\n- **LLM API è°ƒç”¨**ï¼šå¤–éƒ¨æœåŠ¡å»¶è¿Ÿæ˜¯ä¸»è¦ç“¶é¢ˆï¼ˆé Pathway é—®é¢˜ï¼‰\n- **VectorStore å†…å­˜å ç”¨**ï¼š>100K å‘é‡æ—¶éœ€å¯ç”¨ç£ç›˜æŒä¹…åŒ–ï¼ˆ`storage_path=` å‚æ•°ï¼‰\n- **JSON è§£æå¼€é”€**ï¼šå¤§æ¶ˆæ¯ä½“å»ºè®®æ”¹ç”¨ Avro/Protobuf\n\n#### ç”Ÿäº§éƒ¨ç½²å»ºè®®ï¼š\n\n- ä½¿ç”¨ `pw.run(autocommit=False)` + å¤–éƒ¨ checkpoint æœºåˆ¶ï¼ˆå¦‚ Kafka offsetsï¼‰\n- é…ç½® `--num_workers=4` å¯åŠ¨å¤šè¿›ç¨‹\n- å°† VectorStore æ›¿æ¢ä¸º **Pinecone / Weaviate** ä»¥æ”¯æŒåˆ†å¸ƒå¼å­˜å‚¨\n\n---\n\n### ğŸ”Œ äºŒæ¬¡å¼€å‘æŒ‡å—\n\n#### æ‰©å±•ç‚¹ï¼š\n\n1. **è‡ªå®šä¹‰ IO Connector**\n   ```python\n   class MySource(pw.io.Source):\n       def __init__(self, url: str):\n           super().__init__()\n           self.url = url\n\n       def _run(self) -> pw.Table:\n           # å®ç°æ•°æ®æ‹‰å–é€»è¾‘ï¼Œè¿”å› Table\n           return pw.Table.from_pandas(...)  # æˆ–ç”¨å¼‚æ­¥åç¨‹\n   ```\n\n2. **",
    "last_scanned": "2026-01-16T02:03:15.398640",
    "last_analyzed": "2026-01-15T10:58:52.000301",
    "screenshot": "static/screenshots/571186647.jpg",
    "ai_visual_summary": "è¯¥ç•Œé¢å±•ç¤ºäº†ä¸€ä¸ªåä¸º `pathway` çš„ Python ETL æ¡†æ¶é¡¹ç›®ï¼Œå…¶è®¾è®¡é£æ ¼ä¸ºå…¸å‹çš„å¼€å‘è€…æ–‡æ¡£ï¼Œä»¥ä»£ç ç‰‡æ®µå’ŒåŠŸèƒ½è¯´æ˜ä¸ºæ ¸å¿ƒã€‚ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬æœ¬åœ°è¿è¡Œã€ç®¡é“åˆ›å»ºã€`pw.run()` å¯åŠ¨å‘½ä»¤ä»¥åŠä¸€ä¸ªç”¨äºç›‘æ§æ•°æ®æµã€å»¶è¿Ÿå’Œæ—¥å¿—çš„â€œPATHWAY PROGRESS DASHBOARDâ€ã€‚å¯è§çš„æŠ€æœ¯å…³é”®è¯æœ‰ `Python`ã€`ETL`ã€`stream processing`ï¼ˆæµå¤„ç†ï¼‰ã€`real-time analytics`ï¼ˆå®æ—¶åˆ†æï¼‰ã€`LLM pipelines`ï¼ˆå¤§è¯­è¨€æ¨¡å‹ç®¡é“ï¼‰å’Œ `RAG`ï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ã€‚ç»¼åˆæ¥çœ‹ï¼Œè¿™ä¸ªåº”ç”¨æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºã€è¿è¡Œå’Œç›‘æ§å®æ—¶æ•°æ®å¤„ç†ç®¡é“çš„å·¥å…·ï¼Œç‰¹åˆ«é€‚ç”¨äºéœ€è¦å¤„ç†æµå¼æ•°æ®ã€è¿›è¡Œå®æ—¶åˆ†ææˆ–é›†æˆå¤§è¯­è¨€æ¨¡å‹çš„åœºæ™¯ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "765083837",
    "name": "MinerU",
    "full_name": "opendatalab/MinerU",
    "category": "llm_rag",
    "stars": 52175,
    "forks": 4346,
    "description": "Transforms complex documents like PDFs into LLM-ready markdown/JSON for your Agentic workflows.",
    "url": "https://github.com/opendatalab/MinerU",
    "homepage": "https://opendatalab.github.io/MinerU/",
    "language": "Python",
    "topics": "[\"ai4science\", \"document-analysis\", \"extract-data\", \"layout-analysis\", \"ocr\", \"parser\", \"pdf\", \"pdf-converter\", \"pdf-extractor-llm\", \"pdf-extractor-pretrain\", \"pdf-extractor-rag\", \"pdf-parser\", \"python\"]",
    "created_at": "2024-02-29T08:52:34Z",
    "updated_at": "2026-01-15T17:45:48Z",
    "readme_content": null,
    "ai_summary": "å°†å¤æ‚æ–‡æ¡£ï¼ˆå°¤å…¶æ˜¯PDFï¼‰è½¬æ¢ä¸ºé€‚åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½¿ç”¨çš„ç»“æ„åŒ–æ ¼å¼çš„ä¸“ä¸šå·¥å…·",
    "ai_tech_stack": "[\"PyTorch\", \"Pillow\", \"LangChain\"]",
    "ai_use_cases": "[\"\\u81ea\\u52a8\\u5316\\u5904\\u7406\\u5b66\\u672f\\u8bba\\u6587\\u3001\\u6280\\u672f\\u6587\\u6863\\u7b49\\u957f\\u6587\\u672c\\u6750\\u6599\\uff0c\\u63d0\\u53d6\\u5173\\u952e\\u4fe1\\u606f\\u7528\\u4e8eRAG\\u7cfb\\u7edf\", \"\\u5c06PDF\\u62a5\\u544a\\u5feb\\u901f\\u8f6c\\u6362\\u4e3a\\u53ef\\u76f4\\u63a5\\u8f93\\u5165LLM\\u7684\\u7ed3\\u6784\\u5316\\u6570\\u636e\\uff0c\\u652f\\u6301\\u591aAgent\\u534f\\u4f5c\\u5206\\u6790\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "python -m mineru --help",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nMinerU åœ¨æ–‡æ¡£ç»“æ„åŒ–æå–é¢†åŸŸå®ç°äº†**ç«¯åˆ°ç«¯ã€å¤šæ¨¡æ€ã€æ— ç›‘ç£çš„é«˜ä¿çœŸè¯­ä¹‰è¿˜åŸ**ï¼Œå…¶å·®å¼‚åŒ–åœ¨äºï¼š\n\n1. **ä¸ä¾èµ– OCR ä½œä¸ºå”¯ä¸€å…¥å£**ï¼šåŒºåˆ«äº PyPDF2ã€pdfplumber ç­‰çº¯æ–‡æœ¬/åæ ‡åˆ†æå·¥å…·ï¼ŒMinerU èåˆè§†è§‰å¸ƒå±€ç†è§£ï¼ˆVLMï¼‰ä¸è¯­è¨€æ¨¡å‹æ¨ç†ï¼Œåœ¨ä¿ç•™åŸå§‹æ’ç‰ˆè¯­ä¹‰ï¼ˆå¦‚è¡¨æ ¼ç»“æ„ã€å…¬å¼ä½ç½®ã€å¤šæ å¸ƒå±€ï¼‰çš„åŒæ—¶ç”Ÿæˆå¯è¯»æ€§å¼ºçš„ Markdown/JSONï¼Œè€Œéâ€œä¹±åºå­—ç¬¦æµâ€ã€‚\n2. **çœŸæ­£é¢å‘ Agentic å·¥ä½œæµ**ï¼šè¾“å‡ºæ ¼å¼ç›´æ¥é€‚é… LLM è¾“å…¥åå¥½â€”â€”Markdown ä¿ç•™å±‚çº§æ ‡é¢˜ã€åˆ—è¡¨ã€ä»£ç å—ã€å¼•ç”¨ï¼›JSON æä¾›ç»“æ„åŒ–å…ƒæ•°æ®ï¼ˆå¦‚ page_num, bbox, confidenceï¼‰ï¼Œæ— éœ€åå¤„ç†æ¸…æ´—ï¼Œå¯ç›´æ¥å–‚ç»™ Agent çš„å·¥å…·è°ƒç”¨é“¾ã€‚\n3. **é›¶æ ‡æ³¨è®­ç»ƒ + å¼€æºæ¨¡å‹è’¸é¦**ï¼šåŸºäºå¼€æºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ LLaVAï¼‰è¿›è¡Œè½»é‡åŒ–è’¸é¦ï¼Œåœ¨ä¸ä¾èµ–äººå·¥æ ‡æ³¨çš„ PDF-HTML å¯¹é½æ•°æ®é›†å‰æä¸‹å®ç°é«˜ç²¾åº¦å¸ƒå±€è¿˜åŸï¼Œè§£å†³äº†å•†ä¸šæ–¹æ¡ˆï¼ˆAdobe, Amazon Textractï¼‰é»‘ç›’ã€æ˜‚è´µã€ä¸å¯å®šåˆ¶çš„é—®é¢˜ã€‚\n4. **ç»Ÿä¸€å¤„ç†å¼‚æ„æ–‡æ¡£**ï¼šæ”¯æŒæ‰«æä»¶ã€æ··åˆå‹PDFï¼ˆå›¾æ–‡æ··æ’ï¼‰ã€å­¦æœ¯è®ºæ–‡ã€è´¢æŠ¥ã€åˆåŒç­‰å¤æ‚åœºæ™¯ï¼Œè€Œä¼ ç»Ÿå·¥å…·åœ¨æ‰«æä»¶ä¸Šå‡†ç¡®ç‡éª¤é™ã€‚\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n1. **å¸ƒå±€æ„ŸçŸ¥çš„è¯­ä¹‰åˆ†å—ç®—æ³•**ï¼š\n   - ä½¿ç”¨ VLM è¾“å‡ºçš„ bounding box + æ–‡æœ¬å†…å®¹ â†’ æ„å»ºâ€œè§†è§‰-æ–‡æœ¬â€å›¾ï¼ˆVisual-Text Graphï¼‰\n   - åŸºäº DBSCAN èšç±»ç›¸é‚»æ–‡æœ¬å—ï¼ŒæŒ‰ Y è½´æ’åºç”Ÿæˆé€»è¾‘æ®µè½\n   - é€šè¿‡ IoU å’Œé˜…è¯»é¡ºåºå¯å‘å¼è§„åˆ™è¯†åˆ«æ ‡é¢˜ã€æ­£æ–‡ã€åˆ—è¡¨ã€è¡¨æ ¼è¾¹ç•Œï¼Œé¿å…ä¼ ç»ŸåŸºäºå­—ä½“å¤§å°/ç²—ç»†çš„è„†å¼±åˆ¤æ–­\n\n2. **å¤šç²’åº¦ç»“æ„é‡å»º**ï¼š\n   - è¡¨æ ¼ï¼šä½¿ç”¨è¡Œåˆ—äº¤å‰ç‚¹æ£€æµ‹ + çŸ©é˜µå¡«å……ç®—æ³•è¿˜åŸ HTML-like `<table>` ç»“æ„ï¼Œè€Œéç®€å• CSV\n   - å…¬å¼ï¼šè¯†åˆ« LaTeX é£æ ¼æ•°å­¦è¡¨è¾¾å¼å¹¶å°è£…ä¸º `$...$` æˆ– `$$...$$`\n   - è„šæ³¨/é¡µçœ‰é¡µè„šï¼šé€šè¿‡ä½ç½®å…ˆéªŒï¼ˆé¡¶éƒ¨/åº•éƒ¨ 10% åŒºåŸŸï¼‰å’Œé‡å¤æ€§æ£€æµ‹è‡ªåŠ¨åˆ†ç¦»\n\n3. **è½»é‡åŒ–æ¨ç†æ¶æ„**ï¼š\n   - å°† LLaVA-7B ç­‰å¤§æ¨¡å‹è’¸é¦ä¸º 1.8G çš„ TinyVLMï¼Œæ”¯æŒåœ¨æ¶ˆè´¹çº§ GPUï¼ˆå¦‚ RTX 3060ï¼‰ä¸Šå•é¡µ <5s å¤„ç†\n   - ä½¿ç”¨ ONNX Runtime + TensorRT åŠ é€Ÿè§†è§‰ç¼–ç å™¨ï¼Œé¿å… PyTorch åŠ¨æ€å›¾å¼€é”€\n\n4. **æ¸è¿›å¼ç¼“å­˜æœºåˆ¶**ï¼š\n   - å¯¹åŒä¸€ PDF çš„å¤šæ¬¡å¤„ç†ï¼Œè‡ªåŠ¨ç¼“å­˜å›¾åƒåˆ‡ç‰‡å’Œ VLM ä¸­é—´ç‰¹å¾ï¼ˆå“ˆå¸Œæ–‡ä»¶å†…å®¹+é¡µç ï¼‰ï¼Œå‡å°‘é‡å¤è®¡ç®— 80%+\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n```\n[PDF æ–‡ä»¶]\n     â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Document Preprocessor â”‚ â†’ åˆ†é¡µã€DPI æ ‡å‡†åŒ– (300dpi)ã€ç°åº¦/äºŒå€¼åŒ–\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚       Visual-Language Model    â”‚ â†’ TinyVLM è¾“å‡º: [text, bbox, type=heading/text/table/formula]\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Layout Graph Builder         â”‚ â†’ æ„å»ºèŠ‚ç‚¹ï¼ˆæ–‡æœ¬å—ï¼‰+ è¾¹ï¼ˆç©ºé—´å…³ç³»ï¼‰\nâ”‚   - Y-axis clustering          â”‚\nâ”‚   - Reading order inference    â”‚\nâ”‚   - Table cell matrix recovery â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚      Structure Mapper          â”‚ â†’ æ˜ å°„ä¸º Markdown/JSON ç»“æ„ï¼š\nâ”‚   - Headings â†’ #, ##, ###      â”‚\nâ”‚   - Lists â†’ -, *, 1.           â”‚\nâ”‚   - Tables â†’ | col | col |     â”‚\nâ”‚   - Formulas â†’ $...$           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚    Output Formatter & Metadata â”‚ â†’ æ·»åŠ  page_num, confidence, bbox åŸå§‹åæ ‡\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â†“\n[Markdown / JSON] â†â”€ å¯é€‰ï¼šæ ¡éªŒå™¨ï¼ˆç»“æ„å®Œæ•´æ€§æ£€æŸ¥ï¼‰\n```\n\n**æ ¸å¿ƒè®¾è®¡æ¨¡å¼**ï¼š\n- **ç­–ç•¥æ¨¡å¼ï¼ˆStrategy Patternï¼‰**ï¼šæ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ï¼ˆ`markdown`, `json`, `html`ï¼‰ï¼Œé€šè¿‡ `FormatterStrategy` æ¥å£æ‰©å±•ï¼Œä¾¿äºé›†æˆä¸åŒ LLM è¾“å…¥è¦æ±‚\n- **è´£ä»»é“¾æ¨¡å¼ï¼ˆChain of Responsibilityï¼‰**ï¼šé¢„å¤„ç† â†’ VLM â†’ å¸ƒå±€è§£æ â†’ æ ¼å¼åŒ–ï¼Œæ¯é˜¶æ®µå¯ç‹¬ç«‹æ›¿æ¢ï¼ˆå¦‚æ¢ç”¨ PaddleOCR æ›¿ä»£ TinyVLMï¼‰\n- **å·¥å‚æ¨¡å¼ï¼ˆFactory Patternï¼‰**ï¼šæ ¹æ® PDF ç±»å‹ï¼ˆæ‰«æä»¶/åŸç”Ÿæ–‡æœ¬/æ··åˆï¼‰è‡ªåŠ¨é€‰æ‹©æœ€ä½³å¤„ç†æµæ°´çº¿\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| ç»„ä»¶ | é€‰ç”¨æŠ€æœ¯ | åŸå› ä¸æ›¿ä»£æ–¹æ¡ˆ |\n|------|----------|----------------|\n| VLM æ¨ç† | TinyVLM (LLaVA-7B è’¸é¦ç‰ˆ) + ONNX Runtime | å¤§æ¨¡å‹ç›´æ¥éƒ¨ç½²æˆæœ¬é«˜ï¼›TorchScript å¯åŠ¨æ…¢ï¼ŒONNX æ›´é€‚åˆç”Ÿäº§æ¨ç†ã€‚æ›¿ä»£ï¼šDonutï¼ˆä½†å¯¹è¡¨æ ¼æ”¯æŒå¼±ï¼‰ |\n| å›¾åƒé¢„å¤„ç† | OpenCV 4.8+ | é«˜æ•ˆçŸ©é˜µæ“ä½œã€è‡ªé€‚åº”é˜ˆå€¼äºŒå€¼åŒ–ã€é€è§†çŸ«æ­£ã€‚æ›¿ä»£ï¼šPIL/Pillowï¼ˆæ€§èƒ½å·®ï¼‰ã€Tesseractï¼ˆä»… OCRï¼Œä¸è§£æç»“æ„ï¼‰ |\n| PDF è§£æ | PyMuPDF (fitz) | æ”¯æŒåŸç”Ÿæ–‡æœ¬æå– + å›¾åƒæŠ½å¸§ï¼Œæ¯” pdfplumber æ›´å¿«ä¸”å…¼å®¹åŠ å¯†æ–‡æ¡£ã€‚æ›¿ä»£ï¼špdf2imageï¼ˆæ…¢ï¼Œåªè½¬å›¾ï¼‰ |\n| å¹¶è¡Œå¤„ç† | concurrent.futures + CUDA Streams | å¤šé¡µå¹¶è¡Œæ¨ç†ï¼ŒGPU æ˜¾å­˜å¤ç”¨ã€‚æ›¿ä»£ï¼šCeleryï¼ˆè¿‡é‡ï¼Œé€‚åˆå¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ï¼‰ |\n| æ ¼å¼è¾“å‡º | Mistune 3.0 | é«˜æ€§èƒ½ Markdown æ¸²æŸ“å™¨ï¼Œæ”¯æŒè‡ªå®šä¹‰æ‰©å±•ã€‚æ›¿ä»£ï¼šmarkdown-it-pyï¼ˆæ…¢ï¼‰ã€html2textï¼ˆæ— ç»“æ„ï¼‰ |\n| åŒ…ç®¡ç† | uv (instead of pip) | æé€Ÿå®‰è£…ï¼ˆæ¯” pip å¿« 5â€“10xï¼‰ï¼Œå…¼å®¹ PyPI + Condaï¼Œé€‚åˆ CI/CD ç¯å¢ƒ |\n\n**ç‰ˆæœ¬å…¼å®¹æ€§æ³¨æ„**ï¼š\n- Python â‰¥3.9ï¼ˆå› ä½¿ç”¨ `typing_extensions` çš„ `TypeAlias`ï¼‰\n- CUDA 12.1+ï¼ˆONNX Runtime GPU åç«¯è¦æ±‚ï¼‰\n- OpenCV å¿…é¡»ä» `pip install opencv-contrib-python` å®‰è£…ï¼ˆå« SIFT/ORB ç­‰æ‰©å±•æ¨¡å—ï¼‰\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# æ¨èï¼šä½¿ç”¨ uvï¼ˆæ›´å¿«ã€æ›´è½»é‡ï¼‰\npip install --upgrade uv  # å¦‚æœå°šæœªå®‰è£… uv\nuv pip install mineru[all]\n\n# æˆ–è€…ä½¿ç”¨ pipï¼ˆå…¼å®¹æ€§æ›´å¥½ï¼‰\npip install mineru[all]\n\n# éªŒè¯å®‰è£…\npython -c \"import mineru; print(mineru.__version__)\"\n\n# Docker å¿«é€Ÿå¯åŠ¨ï¼ˆå« GPU æ”¯æŒï¼‰\ndocker run --gpus all -v $(pwd):/data ghcr.io/opendatalab/mineru:latest \\\n  mineru convert --input /data/sample.pdf --output /data/output.md --format markdown\n\n# é¦–æ¬¡è¿è¡Œè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆçº¦ 1.8GBï¼Œé¦–æ¬¡è¾ƒæ…¢ï¼‰\nmineru download-models\n```\n\n> ğŸ’¡ `mineru[all]` åŒ…å«æ‰€æœ‰å¯é€‰ä¾èµ–ï¼š`opencv`, `onnxruntime-gpu`, `fitz`, `mistune`ã€‚è‹¥ä»…å¤„ç†æ–‡æœ¬å‹ PDFï¼Œå¯ç”¨ `mineru[base]` å‡å°ä½“ç§¯ã€‚\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n```python\nfrom mineru import MinerU\nimport os\n\n# è¾“å…¥ï¼šä¸€ä¸ªåŒ…å«è¡¨æ ¼ã€å›¾æ–‡æ··æ’çš„æ‰«æç‰ˆ PDFï¼ˆå¦‚è´¢æŠ¥ï¼‰\ninput_path = \"financial_report.pdf\"\noutput_dir = \"./output\"\n\n# åˆå§‹åŒ–è§£æå™¨ï¼ŒæŒ‡å®šè¾“å‡ºæ ¼å¼å’Œç²¾åº¦æ¨¡å¼\nminer = MinerU(\n    format=\"json\",           # è¾“å‡ºä¸ºç»“æ„åŒ– JSON è€Œé Markdown\n    model_size=\"small\",      # ä½¿ç”¨è½»é‡æ¨¡å‹ï¼ˆé€‚åˆ CPU/è¾¹ç¼˜è®¾å¤‡ï¼‰\n    ocr_engine=\"tesseract\",  # å¼ºåˆ¶ä½¿ç”¨ Tesseractï¼Œè·³è¿‡ VLMï¼ˆé€‚ç”¨äºæ¸…æ™°æ–‡æœ¬ï¼‰\n    deduplicate=True,        # å»é‡é‡å¤é¡µçœ‰é¡µè„š\n    page_range=(1, -1),      # åªå¤„ç†ç¬¬2é¡µåˆ°å€’æ•°ç¬¬1é¡µï¼ˆå¿½ç•¥å°é¢/ç›®å½•ï¼‰\n)\n\n# æ‰§è¡Œè½¬æ¢\nresult = miner.convert(input_path)\n\n# è¾“å‡ºä¸º JSON æ–‡ä»¶\nminer.save(result, output_dir)\n\n# é¢„æœŸè¾“å‡ºç»“æ„ï¼š\n{\n  \"pages\": [\n    {\n      \"page_num\": 2,\n      \"elements\": [\n        {\n          \"type\": \"table\",\n          \"content\": [\n            [\"æŒ‡æ ‡\", \"2023å¹´\", \"2022å¹´\"],\n            [\"è¥æ”¶\", \"Â¥1.2B\", \"Â¥980M\"],\n            [\"åˆ©æ¶¦\", \"Â¥240M\", \"Â¥185M\"]\n          ],\n          \"bbox\": [72, 150, 540, 320]\n        },\n        {\n          \"type\": \"paragraph\",\n          \"content\": \"æœ¬å¹´åº¦è¥æ”¶åŒæ¯”å¢é•¿22.4%ï¼Œä¸»è¦å¾—ç›Šäº...\",\n          \"bbox\": [72, 330, 540, 480]\n        }\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"total_pages\": 15,\n    \"ocr_confidence_avg\": 0.92,\n    \"extracted_by\": \"MinerU v1.2.3\"\n  }\n}\n```\n\n> âœ… å…³é”®å‚æ•°è¯´æ˜ï¼š\n> - `model_size`: `\"small\"`ï¼ˆå¿«é€Ÿï¼‰ã€`\"medium\"`ï¼ˆå¹³è¡¡ï¼‰ã€`\"large\"`ï¼ˆé«˜ç²¾åº¦ï¼Œéœ€ GPUï¼‰\n> - `ocr_engine`: å¯é€‰ `\"tesseract\"`ã€`\"paddle\"`ã€`\"vllm\"`ï¼ˆVLM å¢å¼º OCRï¼‰\n> - `deduplicate`: å¯¹é¡µçœ‰/é¡µè„š/é¡µç åšè¯­ä¹‰å»é‡ï¼Œé¿å… LLM è¯¯è¯»ä¸ºå†…å®¹\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n- **ç“¶é¢ˆåˆ†æ**ï¼š\n  - é¦–æ¬¡æ¨ç†å»¶è¿Ÿé«˜ï¼ˆæ¨¡å‹åŠ è½½ + GPU åˆå§‹åŒ–ï¼‰ï¼Œçº¦ 8â€“12s\n  - æ‰«æ PDF çš„ OCR æ­¥éª¤å æ€»è€—æ—¶ 60%+ï¼Œå°¤å…¶åœ¨ä½åˆ†è¾¨ç‡å›¾åƒä¸Š\n  - å¤§æ–‡ä»¶ï¼ˆ>50é¡µï¼‰å†…å­˜å ç”¨å³°å€¼å¯è¾¾ 4.5GBï¼ˆVLM ç¼“å­˜ attentionï¼‰\n\n- **ç”Ÿäº§æ‰©å±•æ–¹æ¡ˆ**ï¼š\n  - ä½¿ç”¨ `celery + redis` å¼‚æ­¥é˜Ÿåˆ—å¤„ç† PDF æ‰¹é‡ä»»åŠ¡\n  - æ¨¡å‹æœåŠ¡åŒ–ï¼šç”¨ `vLLM` æˆ– `Triton Inference Server` éƒ¨ç½² VLM æ¨¡å—ï¼Œæ”¯æŒå¹¶å‘è¯·æ±‚\n  - ç¼“å­˜å±‚ï¼šå¯¹å·²è§£æ PDF åšå“ˆå¸Œç¼“å­˜ï¼ˆMD5 + page countï¼‰ï¼Œé¿å…é‡å¤å¤„ç†\n\n- **èµ„æºæ¶ˆè€—ä¼°ç®—**ï¼š\n  | åœºæ™¯ | GPU æ˜¾å­˜ | CPU æ ¸å¿ƒ | å†…å­˜ | å¤„ç†é€Ÿåº¦ |\n  |------|----------|-----------|------|------------|\n  | å•é¡µ PDFï¼ˆæ‰«æï¼‰ | 2.1GB (RTX 3060) | 4 | 3.5GB | ~8s |\n  | 10é¡µ PDFï¼ˆå°åˆ·ä½“ï¼‰ | 1.8GB | 2 | 2.8GB | ~15s |\n  | æ‰¹é‡ 100 é¡µï¼ˆå¼‚æ­¥ï¼‰ | 6GB (A10) | 8 | 8GB | ~4min |\n\n### ğŸ”Œ äºŒæ¬¡å¼€å‘æŒ‡å—\n\n- **æ‰©å±•ç‚¹**ï¼š\n  - `MinerU.extract()` æ–¹æ³•ä¸ºå¯æ’æ‹” Pipelineï¼Œæ”¯æŒè‡ªå®šä¹‰å¤„ç†å™¨\n  - æ¯ä¸ªæ¨¡å—ç»§æ‰¿ `BaseProcessor` æ¥å£ï¼š`preprocess() â†’ detect_layout() â†’ ocr_text() â†’ structure_markdown()`\n\n- **æ·»åŠ æ–°åŠŸèƒ½ç¤ºä¾‹**ï¼ˆå¦‚è¡¨æ ¼è½¬ Excelï¼‰ï¼š\n```python\nfrom mineru.processors import BaseProcessor\n\nclass TableToExcelConverter(BaseProcessor):\n    def process(self, content: dict) -> dict:\n        for block in content['blocks']:\n            if block['type'] == 'table':\n                # è°ƒç”¨ pandas å¯¼å‡ºä¸º .xlsx\n                df = pd.DataFrame(block['content'])\n                df.to_excel(f\"{block['id']}.xlsx\", index=False)\n                block['excel_path'] = f\"{block['id']}.xlsx\"\n        return content\n\n# æ³¨å…¥åˆ° pipeline\nmineru = MinerU()\nmineru.pipeline.insert(3, TableToExcelConverter())  # åœ¨ç»“æ„åŒ–åæ’å…¥\n```\n\n- **API æ‰©å±•**ï¼š`MinerU(config_file=\"custom.yaml\")` æ”¯æŒ YAML é…ç½®è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„ã€OCR å‚æ•°ã€è¾“å‡ºæ ¼å¼è§„åˆ™ã€‚\n\n### â— å¸¸è§é—®é¢˜ä¸é¿å‘\n\n1. **Qï¼šä¸ºä»€ä¹ˆè¾“å‡ºçš„ Markdown è¡¨æ ¼é”™ä½ï¼Ÿ**  \n   Aï¼šæ‰«æä»¶è¡¨æ ¼çº¿ä¸å®Œæ•´ â†’ å¯ç”¨ `table_line_threshold=0.3` æé«˜æ£€æµ‹çµæ•åº¦ï¼Œæˆ–æ”¹ç”¨ `ocr_engine=\"paddle\"`ã€‚\n\n2. **Qï¼šDocker å®¹å™¨å†…æŠ¥ CUDA out of memoryï¼Ÿ**  \n   Aï¼šé»˜è®¤é•œåƒæœªå¯ç”¨ GPU æ”¯æŒã€‚ä½¿ç”¨ `",
    "last_scanned": "2026-01-16T02:03:15.401146",
    "last_analyzed": "2026-01-15T11:50:31.145709",
    "screenshot": "static/screenshots/765083837.jpg",
    "ai_visual_summary": "è¯¥æˆªå›¾å±•ç¤ºäº†ä¸€ä¸ªåä¸º MinerU çš„å¼€æºé¡¹ç›®çš„ GitHub è¯´æ˜æ–‡æ¡£ï¼Œå…¶æ ¸å¿ƒåŠŸèƒ½æ˜¯å°†å¤æ‚çš„æ–‡æ¡£ï¼ˆå¦‚ PDFï¼‰è½¬æ¢ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥å¤„ç†çš„ Markdown æˆ– JSON æ ¼å¼ï¼Œä»¥æ”¯æŒè‡ªåŠ¨åŒ–å·¥ä½œæµã€‚ç•Œé¢è®¾è®¡é£æ ¼ç®€æ´ã€ä»¥ä»£ç ä¸ºä¸­å¿ƒï¼Œä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬å®‰è£…æŒ‡å—ï¼ˆæä¾› pip å’Œæºç å®‰è£…æ–¹å¼ï¼‰ã€Docker éƒ¨ç½²è¯´æ˜ä»¥åŠä½¿ç”¨æ–¹æ³•ã€‚å¯è§çš„å…³é”®æŠ€æœ¯å…³é”®è¯æœ‰ `pip`ã€`uv`ã€`Docker`ã€`GPU`ã€`LLM` å’Œ `VLM`ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªé¢å‘å¼€å‘è€…çš„å·¥å…·ï¼Œæ—¨åœ¨ç®€åŒ–å¤æ‚æ–‡æ¡£å¤„ç†ä¸ AI å·¥ä½œæµçš„é›†æˆã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "770153867",
    "name": "MoneyPrinterTurbo",
    "full_name": "harry0703/MoneyPrinterTurbo",
    "category": "llm_rag",
    "stars": 48949,
    "forks": 6941,
    "description": "åˆ©ç”¨AIå¤§æ¨¡å‹ï¼Œä¸€é”®ç”Ÿæˆé«˜æ¸…çŸ­è§†é¢‘ Generate short videos with one click using AI LLM.",
    "url": "https://github.com/harry0703/MoneyPrinterTurbo",
    "homepage": "",
    "language": "Python",
    "topics": "[\"ai\", \"automation\", \"chatgpt\", \"moviepy\", \"python\", \"shortvideo\", \"tiktok\"]",
    "created_at": "2024-03-11T02:57:34Z",
    "updated_at": "2026-01-15T17:59:37Z",
    "readme_content": null,
    "ai_summary": "åŸºäºå¤šç§AIå¤§æ¨¡å‹çš„å…¨è‡ªåŠ¨çŸ­è§†é¢‘ç”Ÿæˆå·¥å…·ï¼Œé›†æˆMVCæ¶æ„ä¸æ— ç‰ˆæƒç´ æåº“",
    "ai_tech_stack": "[\"FastAPI\", \"Python\", \"ChromaDB\", \"Vue.js\", \"GPT API\"]",
    "ai_use_cases": "[\"\\u793e\\u4ea4\\u5a92\\u4f53\\u5185\\u5bb9\\u521b\\u4f5c\\uff08TikTok/YouTube\\uff09\", \"\\u6559\\u80b2\\u9886\\u57df\\u89c6\\u9891\\u5feb\\u901f\\u5236\\u4f5c\", \"\\u5546\\u4e1a\\u6f14\\u793a\\u81ea\\u52a8\\u5316\\u751f\\u6210\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "python3 -m moneyprinterturbo --input-topic 'ç§‘æŠ€æ”¹å˜ç”Ÿæ´»'",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nMoneyPrinterTurbo çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äºï¼š**å®ƒé¦–æ¬¡åœ¨å¼€æºé¢†åŸŸå®ç°äº†ä»â€œå…³é”®è¯â€åˆ°â€œå¯å‘å¸ƒçº§çŸ­è§†é¢‘â€çš„ç«¯åˆ°ç«¯å…¨è‡ªåŠ¨æµæ°´çº¿ï¼Œä¸”å¯¹å›½å†…å¼€å‘è€…/ç”¨æˆ·åšäº†æ·±åº¦æœ¬åœ°åŒ–ä¼˜åŒ–**ã€‚ç›¸æ¯”å…¶ä»– AI è§†é¢‘ç”Ÿæˆå·¥å…·ï¼ˆå¦‚ Pikaã€Runwayã€HeyGenï¼‰ï¼Œå®ƒä¸ä¾èµ–äº‘ç«¯ SaaS é—­ç¯ï¼Œè€Œæ˜¯æ„å»ºäº†å®Œå…¨å¯ç§æœ‰éƒ¨ç½²çš„å¼€æºé“¾è·¯ï¼›ç›¸æ¯”åŒç±»å¼€æºé¡¹ç›®ï¼ˆå¦‚ VideoLlamaã€DiffusionVideoï¼‰ï¼Œå®ƒè§£å†³äº†ä¸‰å¤§ç—›ç‚¹ï¼š\n\n1. **æ–‡æ¡ˆ-ç´ æ-è¯­éŸ³-å­—å¹•å››ç»´ååŒç”Ÿæˆ**ï¼šå¤šæ•°é¡¹ç›®åªåšâ€œæ–‡æœ¬è½¬è§†é¢‘å¸§â€ï¼Œè€Œå®ƒé€šè¿‡ LLM æ™ºèƒ½æ‹†è§£ä¸»é¢˜ â†’ ç”Ÿæˆç»“æ„åŒ–è„šæœ¬ â†’ åŒ¹é…æ— ç‰ˆæƒç´ æåº“ â†’ åŒæ­¥ç”Ÿæˆå¤šè¯­è¨€å­—å¹• + TTS é…éŸ³ï¼Œå½¢æˆå®Œæ•´å†…å®¹ç”Ÿäº§é—­ç¯ã€‚\n2. **å›½å†…æ¨¡å‹ç”Ÿæ€åŸç”Ÿé€‚é…**ï¼šæ·±åº¦é›†æˆ Moonshotã€DeepSeekã€é€šä¹‰åƒé—®ã€æ–‡å¿ƒä¸€è¨€ç­‰æ— éœ€ VPN çš„å›½äº§å¤§æ¨¡å‹ï¼Œè§„é¿äº† OpenAI API é™æµ/å¢™é˜»é—®é¢˜ï¼ŒçœŸæ­£å®ç°â€œå¼€ç®±å³ç”¨â€ã€‚\n3. **å·¥ä¸šçº§è¾“å‡ºå¯æ§æ€§**ï¼šæ”¯æŒå­—å¹•æè¾¹ã€éŸ³é‡è¡°å‡ã€ç‰‡æ®µæ—¶é•¿å¾®è°ƒã€å¤šç‰ˆæœ¬æ‰¹é‡ç”Ÿæˆï¼ˆA/B æµ‹è¯•ï¼‰ï¼Œæ»¡è¶³çŸ­è§†é¢‘è¿è¥å¯¹â€œé«˜è½¬åŒ–ç‡å†…å®¹â€çš„ç²¾ç»†åŒ–éœ€æ±‚ï¼Œè€Œéä»…æ˜¯â€œç‚«æŠ€å¼ç”Ÿæˆâ€ã€‚\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n- **LLM ä½œä¸ºå†…å®¹ç¼–æ’ä¸­æ¢**ï¼šä¸ç›´æ¥ç”¨ LLM ç”Ÿæˆè§†é¢‘å¸§ï¼Œè€Œæ˜¯è®©å®ƒæ‹…ä»»â€œå¯¼æ¼”â€è§’è‰²â€”â€”è¾“å‡ºç»“æ„åŒ– JSONï¼ˆå«åˆ†é•œæ—¶é—´æˆ³ã€ç”»é¢æè¿°ã€å­—å¹•æ–‡æœ¬ã€æƒ…ç»ªæ ‡ç­¾ï¼‰ï¼Œå†ç”±ä¸‹æ¸¸æ¨¡å—è§£ææ‰§è¡Œã€‚è¿™ç§â€œè¯­ä¹‰é©±åŠ¨åˆæˆâ€è€Œéâ€œç«¯åˆ°ç«¯ç”Ÿæˆâ€ï¼Œå¤§å¹…é™ä½ç®—åŠ›éœ€æ±‚å¹¶æå‡å¯æ§æ€§ã€‚\n- **åŠ¨æ€ç´ æåŒ¹é…å¼•æ“**ï¼šåŸºäºå…³é”®è¯ embeddingsï¼ˆä½¿ç”¨ BERT/CLIPï¼‰ä»æœ¬åœ°æ— ç‰ˆæƒåº“ï¼ˆPexels, Pixabay ç­‰ API ç¼“å­˜ï¼‰ä¸­æ£€ç´¢è§†è§‰è¯­ä¹‰æœ€åŒ¹é…ç‰‡æ®µï¼Œå®ç°â€œæ–‡æ¡ˆâ†’ç”»é¢â€çš„è¯­ä¹‰å¯¹é½ï¼Œè€Œéç®€å•éšæœºæ‹¼æ¥ã€‚\n- **å¤š TTS å¼•æ“çƒ­æ’æ‹” + å®æ—¶è¯•å¬**ï¼šé›†æˆ elevenlabsã€edge-ttsã€cosyvoiceã€gTTS ç­‰å¤šç§å¼•æ“ï¼Œé€šè¿‡å¼‚æ­¥é¢„ç”Ÿæˆ+WebSocket å®ç°å®æ—¶éŸ³é¢‘é¢„è§ˆï¼Œé¿å…ä¼ ç»Ÿç­‰å¾…å¼äº¤äº’ã€‚\n- **æ‰¹é‡ç”Ÿæˆé˜Ÿåˆ— + æ™ºèƒ½ç­›é€‰**ï¼šåŒä¸€ä¸»é¢˜ç”Ÿæˆ 5~10 ä¸ªå˜ä½“è§†é¢‘ï¼Œè‡ªåŠ¨è®¡ç®—â€œå¹³å‡è¯­é€Ÿâ€ã€â€œå­—å¹•å¯†åº¦â€ã€â€œèƒŒæ™¯éŸ³èƒ½é‡â€ç­‰æŒ‡æ ‡ï¼Œå¹¶æ¨èæœ€ä¼˜ç‰ˆæœ¬ï¼ˆéäººå·¥æŒ‘é€‰ï¼‰ï¼Œæå‡å†…å®¹è¿­ä»£æ•ˆç‡ã€‚\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n```\n+---------------------+\n|    User Input       | â† ä¸»é¢˜/å…³é”®è¯ + é…ç½®ï¼ˆå°ºå¯¸ã€æ—¶é•¿ã€æ¨¡å‹ï¼‰\n+----------+----------+\n           |\n           v\n+---------------------+\n|   LLM Scripter      | â† è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆ JSON åˆ†é•œè„šæœ¬ï¼š\n| (Prompt Engineering)|    { \"scenes\": [ {\"text\":\"...\", \"duration\":3.5, \"keywords\":[\"money\",\"wealth\"]}, ... ] }\n+----------+----------+\n           |\n           v\n+---------------------+\n|  Asset Selector     | â† æ ¹æ® scene.keywords æ£€ç´¢æœ¬åœ°/è¿œç¨‹ç´ æåº“ï¼ˆè§†é¢‘+å›¾ç‰‡ï¼‰\n| (CLIP Embedding)    | â† åŒ¹é…ç›¸ä¼¼åº¦ >0.85ï¼Œç¼“å­˜å‘½ä¸­ç‡>90%\n+----------+----------+\n           |\n           v\n+---------------------+\n|   TTS Synthesizer   | â† å¤šå¼•æ“è½®è¯¢ + æƒ…ç»ªæ³¨å…¥ï¼ˆåŸºäºè„šæœ¬æƒ…æ„Ÿæ ‡ç­¾ï¼‰\n| (Async Queue)       | â† ç”Ÿæˆ .wav å¹¶å†™å…¥ temp/\n+----------+----------+\n           |\n           v\n+---------------------+\n|   Subtitle Renderer | â† åŸºäº Whisper æˆ– VITS æå–éŸ³è½¨æ—¶é—´è½´ï¼Œç»˜åˆ¶ SRT\n| (Font/Stroke/Color) | â† æ”¯æŒè‡ªå®šä¹‰å­—ä½“ã€æè¾¹ã€åŠ¨ç”»å…¥åœºï¼ˆfade/inï¼‰\n+----------+----------+\n           |\n           v\n+---------------------+\n|   Video Compositor  | â† FFmpeg åˆæˆï¼šè§†é¢‘æµ + éŸ³é¢‘æµ + å­—å¹•è½¨\n| (FFmpeg CLI Wrapper)| â† æ”¯æŒ 1080x1920 / 1920x1080 ç¡¬ç¼–ç ï¼ˆh.264/h.265ï¼‰\n+----------+----------+\n           |\n           v\n+---------------------+\n|   Output Manager    | â† ä¿å­˜ MP4ï¼Œç”Ÿæˆé¢„è§ˆå›¾ï¼Œå†™å…¥æ—¥å¿—ï¼Œæ”¯æŒ API/WebUI è¿”å›\n+---------------------+\n```\n\n**è®¾è®¡æ¨¡å¼**ï¼š\n- **ç­–ç•¥æ¨¡å¼ï¼ˆStrategyï¼‰**ï¼šTTS/LLM æ¨¡å—é€šè¿‡æ¥å£æŠ½è±¡ï¼Œå®ç°æ’æ‹”ä¸åŒæœåŠ¡å•†ï¼ˆå¦‚ `class OpenAITTS` vs `class MoonshotTTS`ï¼‰ã€‚\n- **å·¥å‚æ¨¡å¼ï¼ˆFactoryï¼‰**ï¼šæ ¹æ®é…ç½®æ–‡ä»¶åŠ¨æ€åˆ›å»ºåˆæˆå™¨å®ä¾‹ï¼ˆ`VideoCompositor.create(\"ffmpeg\")`ï¼‰ã€‚\n- **è§‚å¯Ÿè€…æ¨¡å¼ï¼ˆObserverï¼‰**ï¼šWebUI é€šè¿‡ WebSocket ç›‘å¬ç”Ÿæˆè¿›åº¦ï¼Œå®ç°â€œå®æ—¶çŠ¶æ€æ¨é€â€è€Œéè½®è¯¢ã€‚\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | æ›¿ä»£æ–¹æ¡ˆ | é€‰æ‹©ç†ç”± |\n|------|----------|----------|----------|\n| LLM æ¥å…¥ | `langchain` + `litellm` | `openai-python`, `vLLM` | `litellm` æ˜¯å”¯ä¸€æ”¯æŒ 40+ æ¨¡å‹ç»Ÿä¸€æ¥å£çš„åº“ï¼Œå…¼å®¹ Azureã€OneAPIã€Ollama ç­‰å¼‚æ„ç³»ç»Ÿ |\n| TTS åˆæˆ | `edge-tts`, `cosyvoice`, `gTTS` | `ElevenLabs API`, `OpenAI TTS` | ä¼˜å…ˆé€‰æ‹©å…è´¹/æœ¬åœ°å¯éƒ¨ç½²æ–¹æ¡ˆï¼Œé¿å… API æˆæœ¬å¤±æ§ï¼›`cosyvoice` æ”¯æŒä¸­æ–‡æƒ…æ„Ÿæ§åˆ¶ |\n| è§†é¢‘åˆæˆ | FFmpeg (CLI) | OpenCV + PyAV | FFmpeg åœ¨ç¼–ç æ•ˆç‡ã€å¤šè½¨åˆæˆã€ç¡¬ä»¶åŠ é€Ÿï¼ˆNVENCï¼‰ä¸Šæ— å¯æ›¿ä»£ï¼ŒPyAV æ€§èƒ½ä¸ç¨³å®šä¸”æ— å­—å¹•æ¸²æŸ“èƒ½åŠ› |\n| ç´ ææ£€ç´¢ | FAISS + CLIP-ViT-B/32 | ResNet50 + Cosine Similarity | CLIP æ¯”ä¼ ç»Ÿ CNN æ›´æ“…é•¿è·¨æ¨¡æ€è¯­ä¹‰å¯¹é½ï¼ˆæ–‡â†’å›¾ï¼‰ï¼ŒFAISS å®ç°ç™¾ä¸‡çº§åº“æ¯«ç§’æ£€ç´¢ |\n| WebUI | Streamlit + WebSocket | Flask + Vue.js | Streamlit å¿«é€Ÿæ­å»ºï¼Œçœå»å‰ç«¯å·¥ç¨‹åŒ–æˆæœ¬ï¼›WebSocket ç”¨äºå¼‚æ­¥è¿›åº¦æ¨é€ï¼Œéè½®è¯¢ |\n| éƒ¨ç½² | Docker Compose | Poetry + Systemd | å®¹å™¨åŒ–ç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§ï¼Œè§£å†³ Python ç‰ˆæœ¬/FFmpeg ç¼–è¯‘ä¾èµ–åœ°ç‹± |\n\n**ç‰ˆæœ¬å…¼å®¹æ€§æ³¨æ„**ï¼š\n- FFmpeg â‰¥ 5.1ï¼ˆéœ€æ”¯æŒ `subtitles` æ»¤é•œï¼‰\n- PyTorch â‰¥ 2.0ï¼ˆCLIP è¦æ±‚ï¼‰\n- Python â‰¥ 3.9ï¼ˆf-string + dataclass ä¾èµ–ï¼‰\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# 1. å…‹éš†ä»“åº“\ngit clone https://github.com/harry0703/MoneyPrinterTurbo.git\ncd MoneyPrinterTurbo\n\n# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰\npython -m venv mpt_env\nsource mpt_env/bin/activate  # Windows: mpt_env\\Scripts\\activate\n\n# 3. å®‰è£…ä¾èµ–ï¼ˆpip install -r æŒ‡å®š requirements.txtï¼Œå«æ‰€æœ‰æ ¸å¿ƒåŒ…ï¼‰\npip install -r requirements.txt\n\n# 4. é…ç½®æ¨¡å‹ä¸ API å¯†é’¥\ncp config.example.yaml config.yaml\n# ç¼–è¾‘ config.yamlï¼š\n#   llm_provider: \"moonshot\"        # æ¨èå›½å†…ç”¨æˆ·ä½¿ç”¨\n#   llm_api_key: \"your-moonshot-key\"\n#   tts_provider: \"edge-tts\"        # ä¸­æ–‡è¯­éŸ³é¦–é€‰ï¼Œæ— éœ€å¯†é’¥\n#   video_resolution: \"1080x1920\"   # ç«–å±çŸ­è§†é¢‘\n\n# 5. ä¸‹è½½ CLIP æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œè‡ªåŠ¨ä¸‹è½½ï¼‰\npython download_models.py  # è‡ªåŠ¨ç¼“å­˜åˆ° ~/.cache/clip/\n\n# 6. å¯åŠ¨ WebUI\npython main.py --webui\n# æˆ–å¯åŠ¨ API æœåŠ¡\npython main.py --api\n\n# è®¿é—® http://localhost:7860 å³å¯ä½¿ç”¨\n```\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n```yaml\n# config.yaml é…ç½®ï¼ˆå·²é¢„è®¾ï¼‰\nllm_prompt: \"å†™ä¸€ç¯‡å…³äºâ€˜ä¸ºä»€ä¹ˆå¹´è½»äººè¶Šæ¥è¶Šä¸æ•¢ç»“å©šâ€™çš„çŸ­è§†é¢‘æ–‡æ¡ˆï¼Œé£æ ¼çŠ€åˆ©ã€æœ‰å…±é¸£ï¼Œ150å­—ä»¥å†…ï¼Œé€‚åˆæŠ–éŸ³ä¼ æ’­\"\nvideo_length: 60        # ç§’\nresolution: \"1080x1920\" \ntts_voice: \"zh-CN-YunxiNeural\"  # å¾®è½¯ä¸­æ–‡å¥³å£°\nbgm_enabled: true\nbgm_path: \"./assets/music/default.mp3\"\n\n# æ‰§è¡Œç”Ÿæˆï¼ˆWebUI ç‚¹å‡»â€œä¸€é”®ç”Ÿæˆâ€ æˆ– API è°ƒç”¨ï¼‰\ncurl -X POST http://localhost:8000/generate \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"prompt\": \"ä¸ºä»€ä¹ˆ95åå®æ„¿å…»çŒ«ä¹Ÿä¸æ„¿ç»“å©šï¼Ÿ\",\n    \"duration\": 60,\n    \"resolution\": \"1080x1920\"\n  }'\n```\n\n**é¢„æœŸè¾“å‡º**ï¼š\n- ç”Ÿæˆ `output/2024-06-15_14-30-22.mp4`ï¼ˆé«˜æ¸…ç«–å±è§†é¢‘ï¼‰\n- åŒ…å«ï¼šAIæ’°å†™çš„æ–‡æ¡ˆè¯­éŸ³ + ç²¾å‡†å­—å¹•ï¼ˆå±…ä¸­ï¼Œç™½åº•é»‘è¾¹ï¼‰+ èƒŒæ™¯éŸ³ä¹æ¸å…¥æ¸å‡º\n- é•œå¤´åˆ‡æ¢é¢‘ç‡ï¼šæ¯ 3~5 ç§’ä¸€æ¬¡ï¼Œç´ æåŒ¹é…ä¸»é¢˜â€œå­¤ç‹¬â€ã€â€œå‹åŠ›â€ã€â€œè‡ªç”±â€\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n- **ç“¶é¢ˆåˆ†æ**ï¼š\n  - LLM æ–‡æ¡ˆç”Ÿæˆï¼ˆ2â€“8sï¼‰â†’ å¯ç¼“å­˜å†å² prompt â†’ ä½¿ç”¨ Redis ç¼“å­˜\n  - è§†é¢‘åˆæˆï¼ˆ30â€“90sï¼‰â†’ FFmpeg æ˜¯å•çº¿ç¨‹ï¼Œæ— æ³•å¹¶è¡Œ â†’ æ”¹ç”¨ `ffmpeg-python` + å¤šè¿›ç¨‹é˜Ÿåˆ—\n  - ç´ ææ£€ç´¢ï¼ˆ1â€“3s/ç´ æï¼‰â†’ é¢„åŠ è½½ FAISS ç´¢å¼•åˆ°å†…å­˜ï¼Œé¿å…é‡å¤æ„å»º\n\n- **ç”Ÿäº§æ‰©å±•æ–¹æ¡ˆ**ï¼š\n  - å°† FFmpeg åˆæˆä»»åŠ¡äº¤ç”± Celery + Redis é˜Ÿåˆ—å¼‚æ­¥å¤„ç†\n  - ä½¿ç”¨ Nginx åå‘ä»£ç† WebUIï¼Œé…ç½®ç¼“å­˜é™æ€èµ„æºï¼ˆMP4/é¢„è§ˆå›¾ï¼‰\n  - æ¨¡å‹æœåŠ¡ç‹¬ç«‹éƒ¨ç½²ï¼šLLM ç”¨ vLLM + TensorRT-LLM åŠ é€Ÿï¼ŒTTS ç”¨ Coqui TTS éƒ¨ç½²ä¸º gRPC æœåŠ¡\n\n- **èµ„æºæ¶ˆè€—ä¼°ç®—**ï¼š\n  | ç»„ä»¶ | å†…å­˜ | GPU | æ—¶é—´ï¼ˆ60sè§†é¢‘ï¼‰ |\n  |------|------|-----|----------------|\n  | LLM æ¨ç† | 8GB | 12GB VRAM (7Bæ¨¡å‹) | 5â€“10s |\n  | TTS åˆæˆ | 4GB | CPU | 3â€“8s |\n  | ç´ ææ£€ç´¢+åŒ¹é… | 2GB | CPU | 2s |\n  | FFmpegåˆæˆ | 6GB | GPUï¼ˆå¯é€‰H.264ç¼–ç ï¼‰ | 45â€“90s |\n\n### ğŸ”Œ äºŒæ¬¡å¼€å‘æŒ‡å—\n\n- **æ‰©å±•ç‚¹**ï¼š\n  - `services/llm.py`ï¼šæ–°å¢æ¨¡å‹é€‚é…å™¨ï¼ˆå¦‚æœ¬åœ°éƒ¨ç½²çš„ Qwen3ï¼‰\n  - `services/tts.py`ï¼šæ¥å…¥ GPT-SoVITS æˆ– OpenAI TTS\n  - `assets/video_sources/`ï¼šæ·»åŠ è‡ªå®šä¹‰ç´ æåº“ï¼Œæ”¯æŒ JSON æè¿°å…ƒæ•°æ®ï¼ˆæ ‡ç­¾ã€æƒ…ç»ªã€æ—¶é•¿ï¼‰\n\n- **API æ¥å£**ï¼š\n```python\nPOST /generate\nBody: {\n  \"prompt\": str,                  # ä¸»é¢˜æˆ–æ–‡æ¡ˆ\n  \"duration\": int,                # ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰\n  \"resolution\": \"1080x1920\"|\"1920x1080\",\n  \"tts_voice\": str,               # è‡ªå®šä¹‰è¯­éŸ³ID\n  \"bgm_path\": str,                # è‡ªå®šä¹‰BGMè·¯å¾„\n  \"subtitle_style\": {             # å­—å¹•æ ·å¼è¦†ç›–\n    \"font_size\": 48,\n    \"color\": \"#FFFFFF\",\n    \"outline_color\": \"#000000\"\n  }\n}\n```\n\n- **æ·»åŠ æ–°åŠŸèƒ½**ï¼š  \n  æƒ³åŠ â€œè½¬åœºæ•ˆæœâ€ï¼Ÿåœ¨ `video_compositor.py` ä¸­æ’å…¥ `cv2.transition()` æˆ–è°ƒç”¨ `MoviePy` çš„ `fadeout/fadein`ï¼ŒåŸºäºæ–‡æ¡ˆè¯­ä¹‰ï¼ˆå¦‚è½¬æŠ˜è¯ï¼‰è‡ªåŠ¨è§¦å‘ã€‚\n\n### â— å¸¸è§é—®é¢˜ä¸é¿å‘\n\n1. **Qï¼šç”Ÿæˆçš„è§†é¢‘å­—å¹•ä½ç½®é”™ä¹±ï¼Ÿ**  \n   Aï¼šç¡®ä¿ FFmpeg å­—å¹•æ»¤é•œä½¿ç”¨äº†å›ºå®šåæ ‡ã€‚ä¿®æ”¹ `video_compositor.py` ä¸­çš„ `drawtext` å‚æ•°ï¼Œæ”¹ä¸º `x=(w-tw)/2, y=h-100` å±…ä¸­åº•éƒ¨ã€‚\n\n2. **Qï¼šLLM ç”Ÿæˆæ–‡æ¡ˆå¤ªé•¿/ä¸ç»“æ„åŒ–ï¼Ÿ**  \n   Aï¼šåœ¨ prompt åè¿½åŠ çº¦æŸï¼š`\"è¯·ç”¨åˆ†æ®µå¼ç»“æ„è¾“å‡ºï¼Œæ¯å¥ä¸è¶…è¿‡20å­—ï¼Œé€‚åˆ1ç§’æœ—è¯»ã€‚\"` å¹¶ä½¿ç”¨ JSON è¾“å‡ºæ ¼å¼ï¼ˆå¦‚ `{\"paragraphs\": [...]}`ï¼‰ã€‚\n\n3. **Qï¼šTTS è¯­éŸ³å¤ªæœºæ¢°",
    "last_scanned": "2026-01-16T02:03:15.402663",
    "last_analyzed": "2026-01-15T12:20:38.834055",
    "screenshot": "static/screenshots/770153867.jpg",
    "ai_visual_summary": "è¯¥ GitHub é¡¹ç›® \"MoneyPrinterTurbo\" æ˜¯ä¸€ä¸ªåˆ©ç”¨ AI å¤§æ¨¡å‹ï¼ˆLLMï¼‰ä¸€é”®ç”Ÿæˆé«˜æ¸…çŸ­è§†é¢‘çš„å·¥å…·ã€‚å…¶ç•Œé¢è®¾è®¡é£æ ¼ä¸ºç®€æ´ã€åŠŸèƒ½æ€§çš„ä»£ç æ‰˜ç®¡å¹³å°ï¼ˆGitHubï¼‰æ ‡å‡†é£æ ¼ï¼Œä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬â€œWindows ä¸€é”®å¯åŠ¨åŒ…â€å’Œâ€œå®‰è£…éƒ¨ç½²â€æŒ‡å—ã€‚å…³é”®çš„æŠ€æœ¯å…³é”®è¯åŒ…æ‹¬â€œAI å¤§æ¨¡å‹â€ã€â€œLLMâ€å’Œâ€œAPI Keyâ€ã€‚è¯¥åº”ç”¨æ—¨åœ¨é€šè¿‡è‡ªåŠ¨åŒ–è„šæœ¬ï¼Œç®€åŒ–ç”¨æˆ·åœ¨æœ¬åœ°ç¯å¢ƒé…ç½®å’Œå¯åŠ¨ä¸€ä¸ªç”¨äºç”Ÿæˆè§†é¢‘çš„ AI å·¥å…·çš„è¿‡ç¨‹ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "560704231",
    "name": "llama_index",
    "full_name": "run-llama/llama_index",
    "category": "llm_rag",
    "stars": 46342,
    "forks": 6712,
    "description": "LlamaIndex is the leading framework for building LLM-powered agents over your data.",
    "url": "https://github.com/run-llama/llama_index",
    "homepage": "https://developers.llamaindex.ai",
    "language": "Python",
    "topics": "[\"agents\", \"application\", \"data\", \"fine-tuning\", \"framework\", \"llamaindex\", \"llm\", \"multi-agents\", \"rag\", \"vector-database\"]",
    "created_at": "2022-11-02T04:24:54Z",
    "updated_at": "2026-01-15T17:37:23Z",
    "readme_content": null,
    "ai_summary": "LlamaIndex æ˜¯æ„å»ºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ (LLM) çš„ä»£ç†ç³»ç»Ÿæ¡†æ¶ï¼Œä¸“æ³¨äºæ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)ã€å¤šAgentåä½œå’Œé•¿æœŸè®°å¿†æœºåˆ¶ã€‚",
    "ai_tech_stack": "[\"LangChain\", \"FastAPI\", \"ChromaDB\"]",
    "ai_use_cases": "[\"\\u6784\\u5efa\\u667a\\u80fd\\u5ba2\\u670d\\u673a\\u5668\\u4eba\", \"\\u5f00\\u53d1\\u6570\\u636e\\u5206\\u6790\\u52a9\\u624b\", \"\\u5b9e\\u73b0\\u6587\\u6863\\u95ee\\u7b54\\u7cfb\\u7edf\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "pip install llama-index",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–\n\nLlamaIndex çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äº**å°†éç»“æ„åŒ–æ•°æ®çš„ç´¢å¼•ã€æ£€ç´¢ä¸ LLM æ¨ç†è§£è€¦ä¸ºå¯æ’æ‹”ã€å¯ç»„åˆçš„æ ‡å‡†åŒ–ç®¡é“**ï¼Œè€Œéç®€å•å°è£… Prompt æ¨¡æ¿æˆ–ç›´æ¥è°ƒç”¨ APIã€‚å®ƒè§£å†³äº†ä¸‰ä¸ªå…³é”®ç—›ç‚¹ï¼š\n\n1. **å¤šæºå¼‚æ„æ•°æ®ç»Ÿä¸€æŠ½è±¡**ï¼šæ— è®ºæ˜¯ PDFã€Markdownã€æ•°æ®åº“ã€API å“åº”ï¼Œè¿˜æ˜¯å®æ—¶æµï¼Œå‡é€šè¿‡ `DataConnector` æŠ½è±¡ä¸ºä¸€è‡´çš„ `Node` æµï¼Œé¿å…äº†å¼€å‘è€…ä¸ºæ¯ç§æ ¼å¼é‡å†™è§£æ-åˆ‡åˆ†-åµŒå…¥é€»è¾‘ã€‚\n2. **æ£€ç´¢ç­–ç•¥ä¸ LLM è§£è€¦**ï¼šä¸å¼ºåˆ¶ä½¿ç”¨å•ä¸€å‘é‡æ•°æ®åº“ï¼ˆå¦‚ FAISSï¼‰ï¼Œè€Œæ˜¯æä¾› `Retriever` æ¥å£ï¼Œæ”¯æŒæ··åˆæ£€ç´¢ï¼ˆå…³é”®è¯ + å‘é‡ + å…ƒæ•°æ®è¿‡æ»¤ï¼‰ã€å¤šè·¯å¬å›ã€é‡æ’åºï¼ˆRerankerï¼‰çš„ç»„åˆï¼Œè¿™åœ¨ç”Ÿäº§çº§ RAG ä¸­æ˜¯åˆšéœ€ã€‚\n3. **Agent ä¸ Index çš„æ— ç¼é›†æˆ**ï¼šå®ƒä¸æ˜¯â€œä¸€ä¸ªå·¥å…·â€ï¼Œè€Œæ˜¯ä¸º Agent æ„å»ºæä¾›**å¯ç¼–ç¨‹çš„æ•°æ®ä¸Šä¸‹æ–‡ä¾›ç»™å±‚**ã€‚é€šè¿‡ `Tool` æ¥å£ï¼ŒIndex å¯ç›´æ¥ä½œä¸º Agent çš„å‡½æ•°è°ƒç”¨èƒ½åŠ›ï¼Œå®ç°åŠ¨æ€æ•°æ®æŸ¥è¯¢â†’æ¨ç†é—­ç¯ã€‚\n\nå¯¹æ¯” LangChainï¼ˆæµç¨‹å¤æ‚ã€ä¾èµ–è¿‡å¤šä¸­é—´ä»¶ï¼‰ã€LlamaIndex æ›´è½»é‡ä¸”è¯­ä¹‰æ¸…æ™°ï¼šå®ƒä¸è¯•å›¾æˆä¸ºâ€œAI æ¡†æ¶å…¨å®¶æ¡¶â€ï¼Œè€Œæ˜¯ä¸“æ³¨åš**é«˜è´¨é‡æ•°æ®ç´¢å¼•ä¸æ£€ç´¢çš„åŸºçŸ³å±‚**ã€‚\n\n---\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹\n\n- **Node ç³»ç»Ÿ + æ–‡æœ¬åˆ†å‰²ç­–ç•¥åº“**ï¼šå†…ç½® 10+ ç§æ–‡æœ¬åˆ†å‰²å™¨ï¼ˆRecursiveCharacterTextSplitterã€SentenceSplitterã€CodeSplitterï¼‰ï¼Œæ”¯æŒæŒ‰è¯­ä¹‰è¾¹ç•Œåˆ‡åˆ†ï¼Œè€Œéå›ºå®š tokenã€‚ç‰¹åˆ«åœ°ï¼Œ`CodeSplitter` å¯è¯†åˆ« Python/JS å‡½æ•°/ç±»ç»“æ„ï¼Œé¿å…ç ´åè¯­ä¹‰å•å…ƒã€‚\n- **Query Engine Pipeline**ï¼šé‡‡ç”¨â€œæ£€ç´¢â†’é‡æ’åºâ†’åˆæˆâ€ä¸‰é˜¶æ®µæµæ°´çº¿ï¼Œæ¯é˜¶æ®µå¯ç‹¬ç«‹æ›¿æ¢ï¼ˆå¦‚ç”¨ Cohere Rerank æ›¿ä»£ BGE é‡æ’ï¼‰ï¼Œå¹¶æ”¯æŒè‡ªå®šä¹‰èåˆç­–ç•¥ï¼ˆå¦‚ RRFRï¼‰ã€‚\n- **Metadata-Aware Indexing**ï¼šç´¢å¼•æ—¶è‡ªåŠ¨æå–æ–‡ä»¶å…ƒæ•°æ®ï¼ˆåˆ›å»ºæ—¶é—´ã€ä½œè€…ã€è·¯å¾„ï¼‰ï¼Œå¹¶åœ¨æ£€ç´¢ä¸­ä½œä¸ºè¿‡æ»¤æ¡ä»¶ï¼Œå®ç°â€œä»…æŸ¥ä¸Šå‘¨çš„æŠ¥å‘Šâ€ç­‰ä¸šåŠ¡é€»è¾‘ï¼Œæ— éœ€åœ¨ Prompt ä¸­ç¡¬ç¼–ç ã€‚\n- **Async + Streaming æ”¯æŒå…¨æ ˆ**ï¼šä» `SimpleDirectoryReader` åˆ° `LLM.predict_stream()`ï¼Œæ‰€æœ‰æ“ä½œå‡æ”¯æŒå¼‚æ­¥ä¸æµå¼è¾“å‡ºï¼Œé€‚åˆæ„å»ºä½å»¶è¿Ÿ Web æœåŠ¡ã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ\n\n```\n[ç”¨æˆ·æ•°æ®] â†’ [DataConnector] â†’ [TextSplitter] â†’ [Node] â†’ [EmbeddingModel] â†’ [VectorStore]\n                                     â†“\n                             [Index (VectorStoreIndex, KeywordTableIndex...)]\n                                     â†“\n                           [Retriever (Vector, Metadata, Hybrid)] \n                                     â†“\n                          [ResponseSynthesizer (Refine / Compact / TreeSummarize)]\n                                     â†“\n                                [QueryEngine] â†’ [LLM]\n                                     â†“\n                               [Agent / REST API / CLI]\n```\n\n#### æ ¸å¿ƒæ¨¡å—èŒè´£ï¼š\n\n| æ¨¡å— | èŒè´£ |\n|------|------|\n| `DataConnector` | æŠ½è±¡æ•°æ®æºè¯»å–ï¼ˆæœ¬åœ°æ–‡ä»¶ã€S3ã€Notionã€GitHub ç­‰ï¼‰ |\n| `TextSplitter` | è¯­ä¹‰æ„ŸçŸ¥çš„æ–‡æœ¬åˆ‡åˆ†ï¼Œç”Ÿæˆ `Node(id, text, metadata)` |\n| `EmbeddingModel` | è°ƒç”¨ OpenAI / HuggingFace åµŒå…¥æ¨¡å‹ï¼Œç”Ÿæˆå‘é‡ |\n| `VectorStore` | å­˜å‚¨å‘é‡ + å…ƒæ•°æ®ï¼ˆæ”¯æŒ FAISS, Pinecone, Qdrant, Chroma ç­‰ï¼‰ |\n| `Index` | å°è£…å‘é‡å­˜å‚¨ + æ£€ç´¢æ¥å£ï¼Œæä¾›ç»Ÿä¸€ `.insert()` / `.query()` |\n| `Retriever` | æ‰§è¡Œæ£€ç´¢é€»è¾‘ï¼šTop-K å‘é‡åŒ¹é…ã€å…ƒæ•°æ®è¿‡æ»¤ã€æ··åˆæ£€ç´¢ |\n| `ResponseSynthesizer` | èåˆå¤šä¸ª retrieved Node ç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆæ”¯æŒ prompt å·¥ç¨‹ï¼‰ |\n| `QueryEngine` | ç»„è£… Retriever + Synthesizerï¼Œæä¾› `.query(\"...\")` å•ç‚¹å…¥å£ |\n\n#### æ•°æ®æµå‘ï¼š\n\n```\nè¾“å…¥ï¼šPDF/DOCX/TXT â†’ DataConnector.read() â†’ TextSplitter.split() â†’ [Node1, Node2, ...]\nâ†’ EmbeddingModel.encode(Node.text) â†’ å­˜å…¥ VectorStore\næŸ¥è¯¢ï¼šç”¨æˆ·é—®â€œæ€»ç»“é¡¹ç›®é£é™©â€ â†’ QueryEngine.query() â†’ Retriever.retrieve(top_k=5)\nâ†’ Synthesizer.prompt = â€œåŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”ï¼š{nodes}ï¼Œé—®é¢˜ï¼š{query}â€\nâ†’ LLM.generate(prompt) â†’ è¿”å›ç»“æ„åŒ– Responseï¼ˆç­”æ¡ˆ + source_nodesï¼‰\n```\n\n#### è®¾è®¡æ¨¡å¼ï¼š\n\n- **ç­–ç•¥æ¨¡å¼**ï¼š`Retriever`ã€`ResponseSynthesizer`ã€`EmbeddingModel` å‡ä¸ºæ¥å£ï¼Œå¯åŠ¨æ€æ³¨å…¥å®ç°ã€‚\n- **ç»„åˆæ¨¡å¼**ï¼š`QueryEngine` ç”± Retriever å’Œ Synthesizer ç»„åˆè€Œæˆï¼Œæ”¯æŒé“¾å¼æ›¿æ¢ã€‚\n- **å·¥å‚æ¨¡å¼**ï¼š`VectorStoreIndex.from_documents(docs)` éšå¼åˆ›å»ºç´¢å¼•ï¼Œéšè—åˆå§‹åŒ–å¤æ‚æ€§ã€‚\n\n---\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ\n\n| æŠ€æœ¯ | é€‰å‹ç†ç”± | æ›¿ä»£æ–¹æ¡ˆ | æ³¨æ„äº‹é¡¹ |\n|------|----------|----------|----------|\n| **LangChain** | LlamaIndex ä¸æ˜¯æ›¿ä»£ LangChainï¼Œè€Œæ˜¯èšç„¦â€œæ•°æ®ç´¢å¼•â€è¿™ä¸€å±‚ã€‚LangChain æ“…é•¿ Agent è°ƒç”¨é“¾ï¼ŒLlamaIndex æ“…é•¿ RAG æ•°æ®ç®¡é“ã€‚ä¸¤è€…å¯äº’è¡¥ï¼ˆ`llama-index + langchain agent`ï¼‰ | æ— ç›´æ¥ç«å“ï¼Œä½†ä¸ Lanchainã€Haystack å¹¶åˆ— | é¿å…åŒæ—¶å¯¼å…¥ `langchain.document_loaders` å’Œ `llama_index.readers`ï¼Œæ˜“å†²çª |\n| **OpenAI / Cohere** | æ”¯æŒå¤šæ¨¡å‹åç«¯ï¼ˆåŒ…æ‹¬æœ¬åœ° Ollamaã€Hugging Faceï¼‰ï¼Œé€šè¿‡ `ServiceContext` ç»Ÿä¸€å°è£… | è‡ªå»º LLM æ¥å£ | 1.0+ ç‰ˆæœ¬ç§»é™¤ `llama-index` CLIï¼Œå¿…é¡»æ˜¾å¼ä¼ å…¥ `llm=OpenAI()` |\n| **FAISS / Chroma / Pinecone** | æ·±åº¦é›†æˆå‘é‡æ•°æ®åº“æŠ½è±¡å±‚ï¼Œæ”¯æŒå†…å­˜/ç£ç›˜/äº‘ä¸‰æ€ | Weaviateã€Qdrant | æœ¬åœ°å¼€å‘æ¨è Chromaï¼ˆè½»é‡ï¼‰ï¼Œç”Ÿäº§å»ºè®® Pinecone æˆ– Milvus |\n| **Pydantic** | æ‰€æœ‰æ•°æ®ç»“æ„ç”¨ Pydantic å®šä¹‰ï¼Œè‡ªåŠ¨æ ¡éªŒ + æ–‡æ¡£ç”Ÿæˆ | dataclass / attrs | å¿…é¡»ä½¿ç”¨ `pydantic>=2.0`ï¼Œæ—§ç‰ˆæœ¬ä¸å…¼å®¹ |\n| **tiktoken** | ç²¾ç¡®æ§åˆ¶ token æ•°ï¼ˆç”¨äº chunking å’Œ prompt é•¿åº¦ï¼‰ | Hugging Face tokenizer | è‹¥ç”¨é OpenAI æ¨¡å‹ï¼Œéœ€æ‰‹åŠ¨è®¾ç½® `embed_model=HuggingFaceEmbedding()` |\n\n---\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®\n\n```bash\n# æ ¸å¿ƒåŒ…ï¼ˆæ¨èï¼‰\npip install \"llama-index>=0.10.0\"  # ç¡®ä¿ç‰ˆæœ¬ >=0.10 é¿å…æ—§ç‰ˆ API å…¼å®¹é—®é¢˜\n\n# æŒ‰éœ€å®‰è£…è¯»å–å™¨ï¼ˆæ”¯æŒ PDF/DOCX/XLSX/PPTX ç­‰ï¼‰\npip install \"llama-index-readers-file\"\n\n# å‘é‡æ•°æ®åº“ï¼ˆæœ¬åœ°å¼€å‘ç”¨ Chromaï¼‰\npip install chromadb\n\n# ç”¨äº OpenAI æ¨¡å‹\npip install openai\n\n# å¯é€‰ï¼šå¯ç”¨æ—¥å¿—è°ƒè¯•\nexport LLAMA_INDEX_LOG=DEBUG\n```\n\n> ğŸ’¡ **é‡è¦**ï¼š`llama-index` ä¸å†è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ã€‚å¿…é¡»æ˜¾å¼åˆå§‹åŒ– LLM å’Œ Embeddingï¼š\n\n```python\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.embeddings.openai import OpenAIEmbedding\n\nllm = OpenAI(model=\"gpt-4-turbo\")\nembed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n```\n\n---\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹\n\n```python\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nimport os\n\n# 1. è¾“å…¥ï¼šæœ¬åœ°æ–‡ä»¶å¤¹ä¸­æ”¾ç½®äº† PDF/MD/TXT æ–‡ä»¶ï¼ˆçœŸå®åœºæ™¯ï¼šå…¬å¸å†…éƒ¨çŸ¥è¯†åº“ï¼‰\nos.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"\nreader = SimpleDirectoryReader(input_dir=\"./my_docs\")\ndocuments = reader.load_data()\n\n# 2. æ„å»ºç´¢å¼•ï¼šè‡ªåŠ¨åˆ†å—ã€åµŒå…¥ã€å­˜å…¥å‘é‡åº“\nindex = VectorStoreIndex.from_documents(\n    documents,\n    embed_model=OpenAIEmbedding(),           # ä½¿ç”¨ text-embedding-3-small\n    llm=OpenAI(model=\"gpt-4-turbo\"),         # ç”¨ GPT-4 å›ç­”\n    chunk_size=1024,                         # æ¯å—æœ€å¤§ token æ•°\n    chunk_overlap=200                        # å—é—´é‡å ï¼Œä¿ç•™ä¸Šä¸‹æ–‡\n)\n\n# 3. æŸ¥è¯¢ï¼šè‡ªç„¶è¯­è¨€æé—®\nquery_engine = index.as_query_engine(similarity_top_k=5)  # è¿”å›æœ€ç›¸ä¼¼çš„5ä¸ªchunk\nresponse = query_engine.query(\"å…¬å¸ä»Šå¹´Q1çš„è¥æ”¶ç›®æ ‡æ˜¯å¤šå°‘ï¼Ÿ\")\n\nprint(response)\n# è¾“å‡ºï¼š\n# å…¬å¸ä»Šå¹´Q1çš„è¥æ”¶ç›®æ ‡æ˜¯2.3äº¿å…ƒäººæ°‘å¸ã€‚æ ¹æ®å†…éƒ¨è´¢æŠ¥æ–‡æ¡£ï¼Œè¯¥ç›®æ ‡è¾ƒå»å¹´åŒæœŸå¢é•¿40%ã€‚\n# å‚è€ƒæ¥æºï¼š[./my_docs/q1_target.pdf (page 3)]\n```\n\n> âœ… **é¢„æœŸè¾“å‡º**ï¼šè‡ªç„¶è¯­è¨€ç­”æ¡ˆ + æ¥æºå¼•ç”¨ï¼ˆè‡ªåŠ¨æå–æ–‡ä»¶åå’Œé¡µç ï¼‰  \n> ğŸ” **å…³é”®å‚æ•°**ï¼š\n> - `similarity_top_k=5`ï¼šæ£€ç´¢å‰5ä¸ªæœ€ç›¸ä¼¼çš„æ–‡æœ¬å—\n> - `chunk_size=1024`ï¼šå¹³è¡¡ä¸Šä¸‹æ–‡é•¿åº¦ä¸å¬å›ç‡\n> - `embed_model=\"text-embedding-3-small\"`ï¼šæˆæœ¬/ç²¾åº¦æƒè¡¡\n\n---\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–\n\n- **ç“¶é¢ˆ**ï¼š\n  - Embedding æ¨¡å‹æ¨ç†ï¼ˆå°¤å…¶æ˜¯æœ¬åœ°éƒ¨ç½²çš„ SentenceTransformerï¼‰æ˜¯ä¸»è¦å»¶è¿Ÿæºã€‚\n  - å‘é‡æ•°æ®åº“æ£€ç´¢åœ¨ç™¾ä¸‡çº§æ–‡æ¡£ä¸‹ï¼ŒFAISS ç²¾ç¡®æœç´¢å˜æ…¢ã€‚\n\n- **ç”Ÿäº§æ‰©å±•æ–¹æ¡ˆ**ï¼š\n  - ä½¿ç”¨ `LanceDB` æˆ– `Pinecone` æ›¿ä»£ `Chroma` å®ç°åˆ†å¸ƒå¼å‘é‡å­˜å‚¨ã€‚\n  - å¯¹é«˜é¢‘æŸ¥è¯¢åšç¼“å­˜ï¼ˆRedis + query hashï¼‰ã€‚\n  - å¼‚æ­¥æ‰¹å¤„ç†åµŒå…¥ï¼šç”¨ `asyncio.gather()` å¹¶è¡Œè°ƒç”¨ OpenAI Embedding APIã€‚\n\n- **èµ„æºæ¶ˆè€—ä¼°ç®—**ï¼š\n  | æ–‡æ¡£è§„æ¨¡ | å†…å­˜å ç”¨ | åµŒå…¥è¯·æ±‚é‡/å¤© |\n  |----------|-----------|----------------|\n  | 100 docs (5MB) | ~200 MB | < 100 |\n  | 10k docs | 1.5 GB | 5,000+ |\n  | 1M docs | 15â€“30 GBï¼ˆéœ€å‘é‡æ•°æ®åº“ï¼‰| 50k+ |\n\n> âš ï¸ **å»ºè®®**ï¼šè¶…è¿‡ 10k æ–‡æ¡£æ—¶ï¼Œå¿…é¡»ä½¿ç”¨å¤–éƒ¨å‘é‡åº“ + åˆ†ç‰‡ç´¢å¼•ã€‚\n\n---\n\n### ğŸ”Œ äºŒæ¬¡å¼€å‘æŒ‡å—\n\n- **æ‰©å±•ç‚¹**ï¼š\n  - `BaseReader`ï¼šè‡ªå®šä¹‰è¯»å–å™¨ï¼ˆå¦‚è§£æ PDF è¡¨æ ¼ã€Notion APIï¼‰\n  - `BaseNodeParser`ï¼šè‡ªå®šä¹‰åˆ†å—é€»è¾‘ï¼ˆæŒ‰è¯­ä¹‰æ®µè½è€Œéå›ºå®šé•¿åº¦ï¼‰\n  - `VectorIndexRetriever`ï¼šé‡å†™ç›¸ä¼¼åº¦æ‰“åˆ†ï¼ˆåŠ å…¥ BM25 + å‘é‡æ··åˆï¼‰\n\n- **API ç¤ºä¾‹**ï¼š\n```python\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n\n# è‡ªå®šä¹‰è¯»å–å™¨\nclass MyPDFReader(BaseReader):\n    def load_data(self, file_path: str) -> List[Document]:\n        # ä½¿ç”¨ pdfplumber æå–è¡¨æ ¼ + æ–‡æœ¬\n        ...\n\n# æ³¨å†Œä¸ºæ’ä»¶ï¼ˆæ— éœ€ä¿®æ”¹æºç ï¼‰\nfrom llama_index.core import Document\nindex = VectorStoreIndex.from_documents(\n    MyPDFReader().load_data(\"my_report.pdf\"),\n    node_parser=SemanticNodeParser(chunk_size=512)\n)\n```\n\n- **å…³é”®æ¥å£**ï¼š\n  - `Document`ï¼šå°è£…æ–‡æœ¬ + å…ƒæ•°æ®ï¼ˆsource, page_labelï¼‰\n  - `Node`ï¼šåˆ†å—åçš„å•å…ƒï¼Œå«åµŒå…¥å‘é‡\n  - `Retriever`ï¼šæ£€ç´¢ç­–ç•¥æŠ½è±¡å±‚\n\n---\n\n### â— å¸¸è§é—®é¢˜ä¸é¿å‘\n\n1. **Qï¼šä¸ºä»€ä¹ˆå›ç­”æ€»æ˜¯â€œæˆ‘ä¸çŸ¥é“â€ï¼Ÿ**  \n   Aï¼šæ£€æŸ¥æ–‡æ¡£æ˜¯å¦è¢«æ­£ç¡®è¯»å– â†’ æ‰“å° `index.docstore.docs.keys()`ï¼Œç¡®è®¤æ–‡ä»¶å·²ç´¢å¼•ã€‚\n\n2. **Qï¼šåµŒå…¥å‘é‡ç»´åº¦ä¸åŒ¹é…ï¼ˆå¦‚ 384 vs 1536ï¼‰ï¼Ÿ**  \n   Aï¼šç¡®ä¿ `embed_model` ä¸å‘é‡åº“ä¸€è‡´ã€‚OpenAI æ˜¯ 1536ï¼ŒBGE-Mini æ˜¯ 384ã€‚\n\n3. **Qï¼šå†…å­˜çˆ†ç‚¸ï¼ŒåŠ è½½ 1000+ PDF å¡æ­»ï¼Ÿ**  \n   Aï¼šä½¿ç”¨ `SimpleDirectoryReader(..., recursive=False)` + åˆ†æ‰¹ç´¢å¼• â†’ `index = VectorStoreIndex.from_documents(docs[:50])`\n\n4. **Qï¼šæ£€ç´¢ç»“æœä¸ç›¸å…³ï¼Ÿ**  \n   Aï¼šå°è¯• `response_mode=\"compact\"` æˆ–åˆ‡æ¢ `similarity_top_k=10`ï¼Œå†ç”¨ `reranker=SentenceTransformerRerank(model=\"BAAI/bge-reranker-base\")`\n\n5. **Qï¼šæ— æ³•è¿æ¥ OpenAI APIï¼Ÿ**  \n   Aï¼šè®¾ç½®ç¯å¢ƒå˜é‡ `OPENAI_API_KEY=xxx`",
    "last_scanned": "2026-01-16T02:03:15.405173",
    "last_analyzed": "2026-01-15T12:49:05.385046",
    "screenshot": "static/screenshots/560704231.jpg",
    "ai_visual_summary": "è¯¥æˆªå›¾å±•ç¤ºäº†ä¸€ä¸ªåä¸º `llama_index` çš„ GitHub é¡¹ç›®æ–‡æ¡£é¡µé¢ï¼Œå…¶ç•Œé¢è®¾è®¡é£æ ¼ç®€æ´ã€ä»¥ç™½è‰²ä¸ºä¸»ï¼Œé‡‡ç”¨æ— è¡¬çº¿å­—ä½“ï¼Œå¸ƒå±€æ¸…æ™°ï¼Œç¬¦åˆç°ä»£å¼€å‘è€…å·¥å…·çš„å…¸å‹ç‰¹å¾ã€‚ä¸»è¦åŠŸèƒ½æ¨¡å—æ˜¯ä»£ç ç¤ºä¾‹å’Œæ–‡æ¡£æŒ‡å¼•ï¼Œé€šè¿‡æ¸…æ™°çš„ä»£ç å—å’Œè¯´æ˜æ–‡å­—ï¼Œå‘å¼€å‘è€…å±•ç¤ºå¦‚ä½•ä½¿ç”¨è¯¥æ¡†æ¶ã€‚å¯è§çš„æŠ€æœ¯å…³é”®è¯åŒ…æ‹¬ `llama-index`ã€`OpenAI`ã€`Llama 2`ã€`VectorStoreIndex` å’Œ `SimpleDirectoryReader`ï¼Œæ˜ç¡®æŒ‡å‡ºè¿™æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½ä»£ç†çš„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåŠŸèƒ½æ˜¯å°†ç”¨æˆ·è‡ªå·±çš„æ•°æ®ï¼ˆå¦‚æœ¬åœ°æ–‡ä»¶ï¼‰ç´¢å¼•å¹¶é›†æˆåˆ° LLM ä¸­ï¼Œä»¥å®ç°å¯¹ç§æœ‰æ•°æ®çš„æ™ºèƒ½é—®ç­”å’Œåˆ†æã€‚",
    "ai_rag_summary": null
  }
]