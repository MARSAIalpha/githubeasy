[
  {
    "id": "658928958",
    "name": "ollama",
    "full_name": "ollama/ollama",
    "category": "multimodal",
    "stars": 159507,
    "forks": 14164,
    "description": "Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.",
    "url": "https://github.com/ollama/ollama",
    "homepage": "https://ollama.com",
    "language": "Go",
    "topics": "[\"deepseek\", \"gemma\", \"gemma3\", \"gemma3n\", \"go\", \"golang\", \"gpt-oss\", \"llama\", \"llama2\", \"llama3\", \"llava\", \"llm\", \"llms\", \"mistral\", \"ollama\", \"phi4\", \"qwen\"]",
    "created_at": "2023-06-26T19:39:32Z",
    "updated_at": "2026-01-15T17:50:28Z",
    "readme_content": null,
    "ai_summary": "Ollama æ˜¯ä¸€ä¸ªå¼€æºå·¥å…·ï¼Œç”¨äºåœ¨æœ¬åœ°è½»æ¾éƒ¨ç½²å’Œè¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPTã€Llamaã€DeepSeek-R1 ç­‰ï¼‰ï¼Œè§£å†³äº†ä¼ ç»Ÿå¤§æ¨¡å‹æœåŠ¡ä¾èµ–äº‘ç«¯APIä¸”æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚",
    "ai_tech_stack": "[\"Go\", \"Docker\", \"REST API\"]",
    "ai_use_cases": "[\"\\u4e2a\\u4eba\\u5f00\\u53d1\\u8005\\u5feb\\u901f\\u96c6\\u6210\\u672c\\u5730\\u5927\\u6a21\\u578b\\u5230\\u5e94\\u7528/\\u5de5\\u5177\\u4e2d\", \"\\u4f01\\u4e1a\\u7528\\u6237\\u964d\\u4f4e\\u5bf9\\u5546\\u4e1a\\u4e91API\\u7684\\u4f9d\\u8d56\\uff0c\\u5b9e\\u73b0\\u79c1\\u6709\\u5316\\u90e8\\u7f72\", \"\\u7814\\u7a76\\u4eba\\u5458\\u4fbf\\u6377\\u6d4b\\u8bd5\\u548c\\u5b9e\\u9a8c\\u5404\\u79cd\\u5f00\\u6e90\\u8bed\\u8a00\\u6a21\\u578b\"]",
    "ai_difficulty": 2,
    "ai_quick_start": "1. ä¸‹è½½å¯¹åº”å¹³å°å®‰è£…åŒ…ï¼ˆmacOS: dmgï¼›Windows: exeï¼›Linux: curl å®‰è£…è„šæœ¬ï¼‰\n2. è¿è¡Œå‘½ä»¤ `ollama run gemma3` å³å¯å¯åŠ¨èŠå¤©ç•Œé¢",
    "ai_tutorial": "å½“ç„¶å¯ä»¥ï¼ä¸‹é¢æ˜¯ä¸€ä»½**ä¸ºé›¶åŸºç¡€ç”¨æˆ·é‡èº«å®šåˆ¶ã€æåº¦è¯¦ç»†ã€ä¿å§†çº§å…¥é—¨æ•™ç¨‹**ï¼Œä¸“ä¸º Ollama é¡¹ç›®æ‰“é€ ã€‚æˆ‘ä¼šç”¨æœ€ç”Ÿæ´»åŒ–çš„æ¯”å–»ã€æœ€æ¸…æ™°çš„æ­¥éª¤ï¼Œè®©ä½ å³ä½¿ä»æ²¡ç¢°è¿‡ä»£ç ï¼Œä¹Ÿèƒ½ä¸€åˆ†é’Ÿå†…è·‘èµ·ä¸€ä¸ªAIèŠå¤©æœºå™¨äººï¼\n\n---\n\n### ğŸ¯ ä¸€å¥è¯äº†è§£è¿™ä¸ªé¡¹ç›®\n\n> **Ollama å°±åƒä½ ç”µè„‘ä¸Šçš„â€œAIåº”ç”¨å•†åº—â€â€”â€”ä½ åªéœ€è¦ç‚¹ä¸€ä¸‹ï¼Œå°±èƒ½ä¸‹è½½å¹¶è¿è¡ŒåƒGPTã€Llamaã€Gemmaè¿™æ ·çš„è¶…çº§å¤§è„‘ï¼Œä¸ç”¨æ‡‚æŠ€æœ¯ï¼Œä¹Ÿä¸ç”¨ä¸Šäº‘ï¼Œå…¨éƒ¨åœ¨ä½ è‡ªå·±ç”µè„‘é‡Œè·‘ï¼**\n\nå°±åƒä½ æ‰‹æœºé‡Œè£…å¾®ä¿¡ã€æŠ–éŸ³ä¸€æ ·ï¼Œç°åœ¨ä½ å¯ä»¥ç›´æ¥åœ¨ç”µè„‘é‡Œè£…ä¸€ä¸ªâ€œä¼šèŠå¤©çš„AIâ€ï¼Œè€Œä¸”å®Œå…¨å…è´¹ã€ç§å¯†ã€ä¸è”ç½‘ä¹Ÿèƒ½ç”¨ï¼\n\n---\n\n### ğŸ’¡ æ ¸å¿ƒæ¦‚å¿µæ‰«ç›²ï¼ˆç”¨ç”Ÿæ´»æ¯”å–»ç†è§£ï¼‰\n\n#### 1. ä»€ä¹ˆæ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Ÿ\n> **å°±åƒä¸€ä¸ªè¯»è¿‡å…¨ç½‘æ‰€æœ‰ä¹¦çš„å¤©æ‰å­¦ç”Ÿ**  \nå®ƒä¸æ˜¯é è®°å¿†ç­”æ¡ˆï¼Œè€Œæ˜¯é€šè¿‡â€œçœ‹â€äº†æµ·é‡æ–‡å­—ï¼ˆæ¯”å¦‚ç»´åŸºç™¾ç§‘ã€å°è¯´ã€ä»£ç ï¼‰ï¼Œå­¦ä¼šäº†æ€ä¹ˆè¯´è¯ã€å†™æ–‡ç« ã€è§£é¢˜ã€‚ä½ é—®å®ƒâ€œæ˜å¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿâ€ï¼Œå®ƒä¸æ˜¯æŸ¥å¤©æ°”é¢„æŠ¥ï¼Œæ˜¯æ ¹æ®å®ƒè¯»è¿‡çš„æ— æ•°ç¯‡æ°”è±¡æŠ¥é“ï¼Œâ€œçŒœâ€å‡ºæœ€å¯èƒ½çš„å›ç­”ã€‚\n\n#### 2. ä»€ä¹ˆæ˜¯æœ¬åœ°è¿è¡Œï¼ˆLocal Inferenceï¼‰ï¼Ÿ\n> **å°±åƒä½ åœ¨è‡ªå·±å®¶å¨æˆ¿åšé¥­ï¼Œè€Œä¸æ˜¯ç‚¹å¤–å–**  \nä»¥å‰AIéƒ½åœ¨â€œäº‘ç«¯æœåŠ¡å™¨â€ä¸Šè·‘ï¼ˆæ¯”å¦‚ChatGPTï¼‰ï¼Œä½ é—®é—®é¢˜è¦ä¼ åˆ°ç½‘ä¸Šï¼Œç­‰å®ƒå›ç­”ã€‚Ollamaè®©ä½ æŠŠæ•´ä¸ªAIå¤§è„‘â€œæ¬å›å®¶â€ï¼Œåœ¨ä½ è‡ªå·±çš„ç”µè„‘é‡Œè¿è¡Œâ€”â€”æ›´å¿«ã€æ›´ç§å¯†ã€ä¸ç”¨ä»˜é’±ã€ä¹Ÿä¸æ€•æ•°æ®è¢«å·ã€‚\n\n#### 3. ä»€ä¹ˆæ˜¯æ¨¡å‹å¤§å°ï¼ˆ7B, 12B, 405Bï¼‰ï¼Ÿ\n> **å°±åƒæ‰‹æœºå†…å­˜ä¸åŒï¼Œèƒ½è£…çš„APPä¹Ÿä¸åŒ**  \n- â€œ7Bâ€ = å°è„‘ç“œï¼ˆ70äº¿ä¸ªç¥ç»å…ƒï¼‰ï¼Œé€‚åˆæ™®é€šèŠå¤©ï¼Œè·‘åœ¨æ™®é€šç”µè„‘ä¸Šã€‚  \n- â€œ405Bâ€ = è¶…çº§å¤§è„‘ï¼ˆ4050äº¿ä¸ªç¥ç»å…ƒï¼‰ï¼Œåƒå®‡å®™çº§AIï¼Œéœ€è¦è¶…ç®—æ‰èƒ½è·‘ï¼Œä½ å®¶ç”¨çš„ç¬”è®°æœ¬æ ¹æœ¬å¸¦ä¸åŠ¨ï¼  \nâ†’ é€‰æ¨¡å‹å°±åƒé€‰æ‰‹æœºï¼šå°å†…å­˜å¤Ÿç”¨æ—¥å¸¸ï¼Œå¤§å†…å­˜èƒ½æ‰“æ¸¸æˆä½†è´µè¿˜è´¹ç”µã€‚\n\n#### 4. ä»€ä¹ˆæ˜¯ GGUF / Safetensorsï¼Ÿ\n> **å°±åƒä¸åŒæ ¼å¼çš„ç”µå­ä¹¦ï¼ˆEPUB vs PDFï¼‰**  \nAIå¤§è„‘ä¸æ˜¯ç›´æ¥å­˜æˆâ€œç¨‹åºâ€ï¼Œè€Œæ˜¯å­˜æˆä¸€ç§ç‰¹æ®Šæ–‡ä»¶ã€‚GGUF æ˜¯ Ollama æœ€çˆ±ç”¨çš„ä¸€ç§æ ¼å¼ï¼ŒåƒMP3æ˜¯éŸ³ä¹çš„é€šç”¨æ ¼å¼ä¸€æ ·ã€‚Safetensors æ˜¯å¦ä¸€ç§æ›´å®‰å…¨çš„æ ¼å¼ï¼Œç±»ä¼¼åŠ å¯†ç‰ˆPDFã€‚\n\n#### 5. Modelfile æ˜¯ä»€ä¹ˆï¼Ÿ\n> **å°±åƒä½ ç»™AIå†™çš„â€œè¯´æ˜ä¹¦â€**  \nä½ æƒ³è®©AIè¯»ä¸€æœ¬ä½ è‡ªå·±ä¸‹è½½çš„ä¹¦ï¼ˆæ¯”å¦‚ã€Šçº¢æ¥¼æ¢¦ã€‹ï¼‰ï¼Œä½†Ollamaä¸çŸ¥é“æ€ä¹ˆç”¨å®ƒï¼Ÿä½ å°±å†™ä¸ª `Modelfile` æ–‡ä»¶å‘Šè¯‰å®ƒï¼šâ€œå˜¿ï¼Œè¿™æœ¬ã€Šçº¢æ¥¼æ¢¦ã€‹æ˜¯æˆ‘æ–°ä¹°çš„ï¼Œè¯·æŠŠå®ƒè£…è¿›ä½ çš„å¤§è„‘é‡Œï¼â€\n\n---\n\n### ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡ï¼ˆä¿å§†çº§ï¼šä»é›¶å¼€å§‹ï¼‰\n\n> âœ… ä½ ä¸éœ€è¦å®‰è£… Pythonã€Node.jsã€Dockerï¼  \n> âš ï¸ Ollama æ˜¯ä¸€ä¸ª**ç‹¬ç«‹ç¨‹åº**ï¼Œå®ƒè‡ªå·±æ‰“åŒ…å¥½æ‰€æœ‰ä¸œè¥¿â€”â€”ä½ åªè¦ä¸‹è½½å®ƒå°±è¡Œï¼\n\n#### âœ… ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥ä½ çš„ç”µè„‘æ˜¯å¦ç¬¦åˆè¦æ±‚\n| é¡¹ç›® | æœ€ä½è¦æ±‚ | æ¨è |\n|------|----------|------|\n| æ“ä½œç³»ç»Ÿ | Windows 10 / macOS 12+ / Linux (64ä½) | ç°ä»£ç³»ç»Ÿéƒ½è¡Œ |\n| å†…å­˜ï¼ˆRAMï¼‰ | è‡³å°‘ 8GB | å»ºè®® 16GB+ï¼ˆè·‘7Bæ¨¡å‹ï¼‰ |\n| ç¡¬ç›˜ç©ºé—´ | è‡³å°‘ 50GBç©ºé—² | å»ºè®® 100GB+ï¼ˆå¤šæ¨¡å‹ä¼šå å¾ˆå¤šï¼‰ |\n| CPU | æ”¯æŒ x86_64 æˆ– Apple Silicon (M1/M2) | M1/M2èŠ¯ç‰‡è¿è¡Œæ›´å¿« |\n\n> ğŸ’¡ å¦‚æœä½ çš„ç”µè„‘æ˜¯2018å¹´åçš„ï¼ŒåŸºæœ¬éƒ½èƒ½è·‘ï¼\n\n#### âœ… ç¬¬äºŒæ­¥ï¼šä¸‹è½½å¹¶å®‰è£… Ollamaï¼ˆå¤åˆ¶ç²˜è´´å³å¯ï¼‰\n\næ ¹æ®ä½ ç”¨çš„æ“ä½œç³»ç»Ÿï¼Œé€‰ä¸‹é¢**ä¸€æ¡å‘½ä»¤**æ‰§è¡Œï¼š\n\n---\n\n##### ğŸ macOS ç”¨æˆ·ï¼š\nç›´æ¥å»å®˜ç½‘ä¸‹è½½ `.dmg` æ–‡ä»¶ï¼š  \nğŸ‘‰ [https://ollama.com/download/Ollama.dmg](https://ollama.com/download/Ollama.dmg)\n\nåŒå‡»æ‰“å¼€ â†’ æ‹–æ‹½åˆ°â€œåº”ç”¨ç¨‹åºâ€æ–‡ä»¶å¤¹ â†’ æ‰“å¼€å®ƒï¼Œè‡ªåŠ¨å®‰è£…å®Œæˆï¼\n\n---\n\n##### ğŸ’» Windows ç”¨æˆ·ï¼š\nç›´æ¥å»å®˜ç½‘ä¸‹è½½ `.exe` å®‰è£…åŒ…ï¼š  \nğŸ‘‰ [https://ollama.com/download/OllamaSetup.exe](https://ollama.com/download/OllamaSetup.exe)\n\nåŒå‡»è¿è¡Œ â†’ ç‚¹â€œä¸‹ä¸€æ­¥â€ç›´åˆ°å®Œæˆ â†’ é‡å¯ç”µè„‘ï¼ˆå»ºè®®ï¼ï¼‰\n\n---\n\n##### ğŸ§ Linux ç”¨æˆ·ï¼š\næ‰“å¼€ç»ˆç«¯ï¼ˆTerminalï¼‰ï¼Œå¤åˆ¶ç²˜è´´ä¸‹é¢è¿™æ¡å‘½ä»¤ï¼š\n\n```bash\n# ä¸‹è½½å¹¶è‡ªåŠ¨å®‰è£… Ollamaï¼ˆä¸€è¡Œæå®šï¼‰\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n> âœ… è¿™æ¡å‘½ä»¤ä¼šï¼š  \n> 1. è‡ªåŠ¨ä¸‹è½½æœ€æ–°ç‰ˆOllama  \n> 2. å®‰è£…åˆ°ç³»ç»Ÿè·¯å¾„  \n> 3. è®¾ç½®å¥½ç¯å¢ƒå˜é‡  \n\nå®‰è£…å®Œæˆåï¼Œ**é‡å¯ç»ˆç«¯**ï¼ˆå…³é—­å†æ‰“å¼€ï¼‰ï¼Œè®©è®¾ç½®ç”Ÿæ•ˆã€‚\n\n---\n\n#### âœ… ç¬¬ä¸‰æ­¥ï¼šéªŒè¯æ˜¯å¦å®‰è£…æˆåŠŸ\n\nåœ¨ç»ˆç«¯é‡Œè¾“å…¥ï¼š\n\n```bash\nollama --version\n```\n\nâœ… å¦‚æœçœ‹åˆ°ç±»ä¼¼ï¼š\n```\nOllama version is 0.3.10\n```\nâ†’ **æ­å–œä½ ï¼å®‰è£…æˆåŠŸï¼**\n\nâŒ å¦‚æœæç¤º `command not found` â†’ è¯´æ˜æ²¡è£…å¥½ï¼Œé‡å¯ç”µè„‘å†è¯•ä¸€æ¬¡ï¼Œæˆ–æ‰‹åŠ¨æ‰§è¡Œï¼š\n\n```bash\nsource ~/.bashrc   # Linux/macOS Bashç”¨æˆ·\n# æˆ–\nsource ~/.zshrc    # macOS Zshç”¨æˆ·ï¼ˆM1/M2é»˜è®¤ï¼‰\n```\n\n---\n\n### ğŸ“¦ å®‰è£…æ­¥éª¤ï¼ˆå¤åˆ¶ç²˜è´´å³å¯ï¼‰\n\næˆ‘ä»¬ä¸ç”¨å…‹éš†ä»£ç ã€ä¸è£…ä¾èµ–ï¼Ollama æœ¬èº«å°±æ˜¯â€œå¼€ç®±å³ç”¨â€çš„ã€‚\n\n#### âœ… ç¬¬ä¸€æ­¥ï¼šä¸‹è½½å¹¶è¿è¡Œä¸€ä¸ªAIæ¨¡å‹ï¼ˆæ¯”å¦‚ Gemma 3ï¼Œ1Bå°ç‰ˆæœ¬ï¼‰\n\n```bash\n# ä¸‹è½½å¹¶å¯åŠ¨ä¸€ä¸ªè¶…è½»é‡çº§AIå¤§è„‘ï¼ˆGemma 3ï¼Œä»…815MBï¼‰\nollama run gemma3:1b\n```\n\n> ğŸ’¡ è¿™æ˜¯**ç¬¬ä¸€æ¬¡ä¸‹è½½**ï¼Œå¯èƒ½ä¼šèŠ±å‡ åˆ†é’Ÿï¼ˆå–å†³äºç½‘é€Ÿï¼‰ï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼ï¼š\n```\npulling manifest...\npulling 9c2a7e4d0f61... 100%\nextracting... done\nsuccess!\n```\n\n#### âœ… ç¬¬äºŒæ­¥ï¼šå¼€å§‹èŠå¤©ï¼\n\nå½“ä½ çœ‹åˆ°æç¤ºç¬¦ `>>>` å‡ºç°æ—¶ï¼Œä½ å°±å¯ä»¥å¼€å§‹é—®é—®é¢˜äº†ï¼š\n\n```text\n>>> ä½ å¥½ï¼ä½ èƒ½å‘Šè¯‰æˆ‘å¤ªé˜³ä¸ºä»€ä¹ˆæ˜¯é»„è‰²çš„å—ï¼Ÿ\n```\n\nAIä¼šå›ç­”ï¼š\n```\nå¤ªé˜³çœ‹èµ·æ¥æ˜¯é»„è‰²çš„ï¼Œæ˜¯å› ä¸ºåœ°çƒå¤§æ°”å±‚æ•£å°„äº†é˜³å…‰ä¸­çš„è“è‰²å…‰â€¦â€¦\n```\n\n> âœ… ç°åœ¨ä½ å°±æ‹¥æœ‰äº†ä¸€ä¸ª**å®Œå…¨æœ¬åœ°è¿è¡Œã€å…è´¹ã€ç§å¯†ã€æ— å¹¿å‘Šçš„AIåŠ©æ‰‹ï¼**\n\n#### âœ… ç¬¬ä¸‰æ­¥ï¼šé€€å‡ºå¯¹è¯\n\nè¾“å…¥ `exit` æˆ–æŒ‰ `Ctrl + D` å³å¯é€€å‡ºã€‚\n\n---\n\n### ğŸ® ç¬¬ä¸€æ¬¡ä½¿ç”¨æ¼”ç¤ºï¼ˆå±å¹•æ“ä½œæè¿°ï¼‰\n\n> ğŸ‘‰ è¯·è·Ÿç€ä¸‹é¢æ¯ä¸€æ­¥ï¼Œåƒç©æ¸¸æˆä¸€æ ·æ“ä½œï¼š\n\n1. **æ‰“å¼€ä½ çš„ç”µè„‘ç»ˆç«¯**  \n   - Windowsï¼šæŒ‰ `Win + R` â†’ è¾“å…¥ `cmd` â†’ å›è½¦  \n   - macOSï¼šæ‰“å¼€â€œåº”ç”¨ç¨‹åºâ€â†’â€œå®ç”¨å·¥å…·â€â†’â€œç»ˆç«¯â€\n\n2. **è¾“å…¥å‘½ä»¤å¯åŠ¨AI**\n   ```bash\n   ollama run gemma3:1b\n   ```\n   ï¼ˆç­‰å¾…å‡ ç§’ï¼Œç›´åˆ°çœ‹åˆ° `>>>` å‡ºç°ï¼‰\n\n3. **ä½ é—®å®ƒä¸€ä¸ªé—®é¢˜**  \n   åœ¨ `>>>` åé¢æ‰“ï¼š\n   ```\n   ç”¨ä¸€å¥è¯å‘Šè¯‰æˆ‘ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ\n   ```\n\n4. **æŒ‰ä¸‹å›è½¦é”®**\n\n5. **ç­‰å¾…AIå›ç­”ï¼**  \n   å®ƒå¯èƒ½ä¼šè¯´ï¼š\n   > â€œäººå·¥æ™ºèƒ½æ˜¯è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½è¡Œä¸ºçš„æŠ€æœ¯ï¼Œæ¯”å¦‚å­¦ä¹ ã€æ¨ç†ã€è¯†åˆ«å›¾åƒæˆ–ç†è§£è¯­è¨€ã€‚â€\n\n6. **ç»§ç»­èŠï¼**\n   ```\n   >>> é‚£æˆ‘æ€ä¹ˆæ‰èƒ½å­¦ä¼šç¼–ç¨‹ï¼Ÿ\n   ```\n\n7. **ä½ æƒ³ç»“æŸå¯¹è¯ï¼Ÿ**\n   è¾“å…¥ï¼š\n   ```\n   exit\n   ```\n   â†’ ç»ˆç«¯å›åˆ°æ™®é€šçŠ¶æ€ã€‚\n\n> âœ… æ­å–œä½ ï¼ä½ åˆšåˆšå®Œæˆäººç”Ÿç¬¬ä¸€æ¬¡â€œæœ¬åœ°AIèŠå¤©â€ï¼\n\n---\n\n### âš™ï¸ å¸¸ç”¨é…ç½®è¯´æ˜ï¼ˆæ”¹äº†ä¼šæ€æ ·ï¼Ÿï¼‰\n\n| é…ç½®é¡¹ | ä½œç”¨ | æ”¹äº†ä¼šæ€æ · |\n|--------|------|-------------|\n| `ollama run gemma3` vs `ollama run gemma3:1b` | é»˜è®¤ä¸‹è½½â€œå¤§æ¨¡å‹â€è¿˜æ˜¯â€œå°æ¨¡å‹â€ | `gemma3` æ˜¯4Bï¼Œå 3.3GBï¼›`:1b` æ˜¯1Bï¼Œä»…815MBã€‚å°æ¨¡å‹å¿«ä½†å›ç­”ç®€å•ï¼Œå¤§æ¨¡å‹èªæ˜ä½†æ…¢ã€åƒå†…å­˜ |\n| `ollama pull llama3:8b` | æ‰‹åŠ¨ä¸‹è½½æŸä¸ªæ¨¡å‹ï¼ˆä¸å¯åŠ¨ï¼‰ | ä½ å¯ä»¥æå‰ä¸‹è½½å¥½å¤šä¸ªæ¨¡å‹ï¼Œæƒ³ç”¨å“ªä¸ªå°±è·‘å“ªä¸ª |\n| `ollama list` | æŸ¥çœ‹å·²ä¸‹è½½çš„æ¨¡å‹åˆ—è¡¨ | çœ‹ä½ ç”µè„‘é‡Œå­˜äº†å“ªäº›AIå¤§è„‘ |\n| `ollama rm llama3:8b` | åˆ é™¤ä¸€ä¸ªæ¨¡å‹é‡Šæ”¾ç©ºé—´ | å¦‚æœç¡¬ç›˜ä¸å¤Ÿç”¨äº†ï¼Œåˆ æ‰ä¸ç”¨çš„æ¨¡å‹ï¼ |\n| `ollama create mybot -f Modelfile` | åˆ›å»ºè‡ªå®šä¹‰AIï¼ˆæ¯”å¦‚åŠ è¯´æ˜ä¹¦ï¼‰ | ä½ å¯ä»¥è®©AIâ€œè®°ä½â€ä½ æ˜¯å®ƒçš„ä¸»äººã€å®ƒåªèƒ½è®²ä¸­æ–‡ç­‰ |\n\n> ğŸ’¡ å°æŠ€å·§ï¼šæƒ³æ¢æ¨¡å‹ï¼Ÿç›´æ¥è¾“å…¥ï¼š\n```bash\nollama run llama3.1\n```\nâ†’ å®ƒä¼šè‡ªåŠ¨ä¸‹è½½å¹¶å¯åŠ¨æ–°çš„AIï¼Œä¸ç”¨å…³æ‰ç»ˆç«¯ï¼\n\n---\n\n### â— æ–°æ‰‹å¿…çœ‹çš„å‘ï¼ˆ90%äººä¼šè¸©ï¼ï¼‰\n\n#### ğŸ”´ å‘1ï¼š**â€œå‘½ä»¤ä¸è¯†åˆ«â€æˆ– â€œollama: command not foundâ€**\n- âœ… **åŸå› **ï¼šå®‰è£…åæ²¡é‡å¯ç»ˆç«¯\n- ğŸ’¡ è§£å†³ï¼šå…³é—­ç»ˆç«¯ â†’ é‡æ–°æ‰“å¼€ â†’ å†è¾“ `ollama --version`\n\n#### ğŸ”´ å‘2ï¼š**ä¸‹è½½æ¨¡å‹å¡ä½ã€æŠ¥é”™â€œFailed to pull modelâ€**\n- âœ… **åŸå› **ï¼šç½‘ç»œä¸ç¨³å®šï¼ˆå›½å†…ç”¨æˆ·è®¿é—®OllamaæœåŠ¡å™¨æ…¢ï¼‰\n- ğŸ’¡ è§£å†³ï¼š\n  - ä½¿ç”¨ä»£ç†ï¼ˆå¦‚æœä½ æœ‰ï¼‰\n  - æˆ–è€…æ”¹ç”¨é•œåƒæºï¼ˆæ¨èï¼‰ï¼š\n    ```bash\n    export OLLAMA_HOST=https://ollama.mirror.example.com\n    ```\n    ï¼ˆç›®å‰å®˜æ–¹æš‚æ— å…¬å¼€é•œåƒï¼Œå¯å…³æ³¨ [https://github.com/ollama/ollama](https://github.com/ollama/ollama) è·å–æœ€æ–°æ–¹æ¡ˆï¼‰\n\n#### ğŸ”´ å‘3ï¼š**ç”µè„‘å¡é¡¿ã€é£æ‰‡ç‹‚è½¬**\n- âœ… **åŸå› **ï¼šä½ é€‰äº†å¤ªå¤§çš„æ¨¡å‹ï¼ˆæ¯”å¦‚ `llama3.1:405b`ï¼‰ï¼Œä½ çš„ç”µè„‘å¸¦ä¸åŠ¨ï¼\n- ğŸ’¡ è§£å†³ï¼š\n  - ç«‹åˆ»æŒ‰ `Ctrl + C` ç»ˆæ­¢ç¨‹åº\n  - æ”¹ç”¨å°æ¨¡å‹ï¼š`gemma3:1b` æˆ– `phi4-mini`\n  - æŸ¥çœ‹å†…å­˜ä½¿ç”¨ï¼šä»»åŠ¡ç®¡ç†å™¨ï¼ˆWindowsï¼‰æˆ–æ´»åŠ¨ç›‘è§†å™¨ï¼ˆMacï¼‰\n\n#### ğŸ”´ å‘4ï¼š**æƒ³æ¢æ¨¡å‹ï¼Œä½†æ—§çš„è¿˜åœ¨è·‘**\n- âœ… **åŸå› **ï¼šä½ æ²¡å…³æ‰ä¹‹å‰çš„ç»ˆç«¯çª—å£\n- ğŸ’¡ è§£å†³ï¼š\n  - æŒ‰ `Ctrl + C` å…³é—­å½“å‰å¯¹è¯\n  - å†è¿è¡Œæ–°çš„æ¨¡å‹å‘½ä»¤\n\n#### ğŸ”´ å‘5ï¼š**ç¡¬ç›˜ç©ºé—´ä¸å¤Ÿäº†ï¼**\n- âœ… **åŸå› **ï¼šæ¯ä¸ªæ¨¡å‹éƒ½å å‡ GBï¼Œä½ ä¸‹äº†3ä¸ªå°±20Gæ²¡äº†\n- ğŸ’¡ è§£å†³ï¼š\n  ```bash\n  ollama list        # çœ‹çœ‹å­˜äº†å“ªäº›\n  ollama rm gemma3   # åˆ é™¤ä¸ç”¨çš„æ¨¡å‹é‡Šæ”¾ç©ºé—´\n  ```\n\n---\n\n### ğŸš€ è¿›é˜¶å­¦ä¹ è·¯å¾„\n\nå­¦å®Œè¿™ä¸€æ­¥ï¼Œä½ å·²ç»æŒæ¡äº†**æœ¬åœ°AIè¿è¡Œçš„æ ¸å¿ƒæŠ€èƒ½**ï¼æ¥ä¸‹æ¥ä½ å¯ä»¥ï¼š\n\n#### âœ… ç¬¬1æ­¥ï¼šå°è¯•æ›´å¤šæ¨¡å‹ï¼ˆä»æ˜“åˆ°éš¾ï¼‰\n| æ¨¡å‹ | æ¨èç†ç”± |\n|------|----------|\n| `gemma3:1b` | æœ€è½»é‡ï¼Œé€‚åˆæ–°æ‰‹ç»ƒæ‰‹ |\n| `phi4-mini` | å¾®è½¯å‡ºå“ï¼Œä¸­æ–‡å›ç­”å¥½ |\n| `llama3.2:1b` | Metaå‡ºå“ï¼Œå…¨çƒæœ€æµè¡Œ |\n| `deepseek-r1` | ä¸­æ–‡èƒ½åŠ›è¶…å¼ºï¼æ¨èå›½å†…ç”¨æˆ· |\n\n#### âœ… ç¬¬2æ­¥ï¼šç”¨ Python è°ƒç”¨ä½ çš„AIï¼ˆå†™ç¨‹åºè‡ªåŠ¨é—®é—®é¢˜ï¼‰\n- å®‰è£…åº“ï¼š\n  ```bash\n  pip install ollama\n  ```\n- å†™ä¸ªè„šæœ¬ï¼š\n  ```python\n  import ollama\n\n  response = ollama.chat(model='gemma3:1b', messages=[\n    {'role': 'user', 'content': 'ä¸ºä»€ä¹ˆå¤©ç©ºæ˜¯è“è‰²çš„ï¼Ÿ'}\n  ])\n  print(response['message']['content'])\n  ```\n\n#### âœ… ç¬¬3æ­¥ï¼šæ­å»ºè‡ªå·±çš„AIèŠå¤©ç½‘é¡µï¼ˆWeb UIï¼‰\n- æ¨èå·¥å…·ï¼š[Open WebUI](https://github.com/open-webui/open-webui)\n- å®ƒèƒ½è®©ä½ ç”¨æµè§ˆå™¨è®¿é—®ä½ çš„Ollamaï¼Œåƒç”¨å¾®ä¿¡ä¸€æ ·æ–¹ä¾¿ï¼\n\n#### âœ… ç¬¬4æ­¥ï¼šè®©AIå¸®ä½ å†™ä»£ç ã€ç¿»è¯‘æ–‡æ¡£ã€æ€»ç»“è®ºæ–‡\n- è¯•è¯•é—®ï¼š\n  ```\n  æŠŠè¿™æ®µè‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼šâ€œHello, world!â€\n  ```\n  ```\n  å†™ä¸€ä¸ªPythonç¨‹åºæ‰“å°â€œæˆ‘çˆ±ä½ â€\n  ```\n\n#### âœ… ç¬¬5æ­¥ï¼šåŠ å…¥ç¤¾åŒºï¼Œäº¤æœ‹å‹ï¼\n- Discord: https://discord.gg/",
    "last_scanned": "2026-01-16T02:05:31.819289",
    "last_analyzed": "2026-01-15T03:44:48.596826",
    "screenshot": "static/screenshots/658928958.jpg",
    "ai_visual_summary": "è¯¥ç•Œé¢æ˜¯ GitHub ä¸Šåä¸º `ollama` çš„å¼€æºé¡¹ç›®é¡µé¢ï¼Œå…¶è®¾è®¡é£æ ¼ç®€æ´ã€åŠŸèƒ½åˆ†åŒºæ¸…æ™°ï¼Œç¬¦åˆ GitHub çš„æ ‡å‡†ç•Œé¢ã€‚ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬ä»£ç æµè§ˆã€æäº¤å†å²ã€åˆ†æ”¯ç®¡ç†ã€ä»¥åŠé¡¹ç›®ä¿¡æ¯æ¦‚è§ˆã€‚å¯è§çš„æŠ€æœ¯å…³é”®è¯åŒ…æ‹¬ `gpt-oss`ã€`DeepSeek-R1`ã€`Gemma 3`ã€`llama`ã€`llama2`ã€`llama3`ã€`phi4` ç­‰ï¼Œè¡¨æ˜è¯¥é¡¹ç›®ä¸“æ³¨äºéƒ¨ç½²å’Œè¿è¡Œå¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ã€‚ç»“åˆé¡¹ç›®æè¿°â€œGet up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other modelsâ€ï¼Œå¯ä»¥åˆ¤æ–­è¯¥åº”ç”¨æ˜¯ä¸€ä¸ªç”¨äºæœ¬åœ°æˆ–ç§æœ‰ç¯å¢ƒä¸­å¿«é€Ÿéƒ¨ç½²å’Œè¿è¡Œå¼€æºå¤§è¯­è¨€æ¨¡å‹çš„å·¥å…·ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "155220641",
    "name": "transformers",
    "full_name": "huggingface/transformers",
    "category": "multimodal",
    "stars": 155116,
    "forks": 31740,
    "description": "ğŸ¤— Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
    "url": "https://github.com/huggingface/transformers",
    "homepage": "https://huggingface.co/transformers",
    "language": "Python",
    "topics": "[\"audio\", \"deep-learning\", \"deepseek\", \"gemma\", \"glm\", \"hacktoberfest\", \"llm\", \"machine-learning\", \"model-hub\", \"natural-language-processing\", \"nlp\", \"pretrained-models\", \"python\", \"pytorch\", \"pytorch-transformers\", \"qwen\", \"speech-recognition\", \"transformer\", \"vlm\"]",
    "created_at": "2018-10-29T13:56:00Z",
    "updated_at": "2026-01-15T17:49:09Z",
    "readme_content": null,
    "ai_summary": "Hugging Face Transformers æ˜¯ä¸€ä¸ªåŸºäº Python çš„æ¨¡å‹å®šä¹‰æ¡†æ¶ï¼Œä¸“æ³¨äºæ„å»ºå…ˆè¿›çš„æ–‡æœ¬ã€è§†è§‰ã€éŸ³é¢‘åŠå¤šæ¨¡æ€ Transformer æ¶æ„æ¨¡å‹ï¼Œå¹¶æ”¯æŒè®­ç»ƒå’Œæ¨ç†ã€‚",
    "ai_tech_stack": "[\"Python\", \"PyTorch\"]",
    "ai_use_cases": "[\"\\u81ea\\u7136\\u8bed\\u8a00\\u5904\\u7406\\uff08NLP\\uff09\\u4efb\\u52a1\", \"\\u8ba1\\u7b97\\u673a\\u89c6\\u89c9\\u8bc6\\u522b\\u4e0e\\u751f\\u6210\", \"\\u8bed\\u97f3\\u8bc6\\u522b\\u4e0e\\u5408\\u6210\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "å®‰è£…åï¼Œé€šè¿‡è¿è¡Œ `python -m transformers` å³å¯å¿«é€Ÿä½“éªŒæ ¸å¿ƒåŠŸèƒ½ã€‚",
    "ai_tutorial": "å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸€ä»½ä¸º**é›¶åŸºç¡€ç”¨æˆ·**ç²¾å¿ƒè®¾è®¡çš„ã€ŠHugging Face Transformers å…¥é—¨ä¿å§†çº§æ•™ç¨‹ã€‹ï¼Œç”¨æœ€é€šä¿—çš„è¯­è¨€ã€ç”Ÿæ´»åŒ–çš„æ¯”å–»å’Œå¯å¤åˆ¶çš„æ“ä½œæ­¥éª¤ï¼Œå¸¦ä½ ä»â€œå®Œå…¨ä¸æ‡‚â€åˆ°â€œè·‘é€šç¬¬ä¸€ä¸ªAIæ¨¡å‹â€ï¼Œå…¨ç¨‹æ— é—¨æ§›ï¼\n\n---\n\n### ğŸ¯ ä¸€å¥è¯äº†è§£è¿™ä¸ªé¡¹ç›®  \n> **å®ƒå°±åƒæ˜¯ä¸€ä¸ªâ€œAIæ¨¡å‹ä¹é«˜ç§¯æœ¨ç®±â€â€”â€”ä½ ä¸ç”¨è‡ªå·±é€ è½®å­ï¼Œç›´æ¥æ‹¿ç°æˆçš„ã€è¶…å¼ºçš„AIæ¨¡å‹ï¼ˆæ¯”å¦‚èƒ½å†™è¯—ã€ç¿»è¯‘ã€çœ‹å›¾è¯´è¯çš„ï¼‰ï¼Œåƒæ­ç§¯æœ¨ä¸€æ ·æ‹¼èµ·æ¥ç”¨ï¼**\n\n---\n\n### ğŸ’¡ æ ¸å¿ƒæ¦‚å¿µæ‰«ç›²ï¼ˆç”¨ç”Ÿæ´»ä¾‹å­ç§’æ‡‚ï¼‰\n\n#### 1. ä»€ä¹ˆæ˜¯ Transformerï¼Ÿ  \n> ğŸ§  **å°±åƒä¸€ä¸ªâ€œè¶…çº§æ³¨æ„åŠ›å­¦éœ¸â€**ï¼š  \nä½ è¯»ä¸€æœ¬ä¹¦æ—¶ï¼Œä¸ä¼šä¸€å­—ä¸€å¥æ­»è®°ç¡¬èƒŒï¼Œè€Œæ˜¯ä¼šé‡ç‚¹è®°ä½å…³é”®è¯ã€å‰åå¥çš„å…³ç³»ã€‚æ¯”å¦‚ï¼šâ€œæ˜¨å¤©æˆ‘å»äº†å…¬å›­ï¼Œçœ‹åˆ°ä¸€åªç‹—åœ¨è¿½çƒã€‚â€â€”â€”ä½ ç«‹åˆ»çŸ¥é“â€œç‹—â€å’Œâ€œçƒâ€æœ‰å…³ç³»ï¼Œè€Œä¸æ˜¯å»è®°ç¬¬7ä¸ªå­—æ˜¯â€œçš„â€ã€‚Transformer å°±æ˜¯è®©AIä¹Ÿè¿™æ ·â€œä¸“æ³¨å…³é”®ä¿¡æ¯â€ï¼Œå®ƒèƒ½çœ‹æ‡‚é•¿å¥å­ã€ææ¸…ä¸Šä¸‹æ–‡ï¼Œæ‰€ä»¥ç°åœ¨æ‰€æœ‰å¤§æ¨¡å‹ï¼ˆæ¯”å¦‚ChatGPTï¼‰éƒ½é å®ƒã€‚\n\n#### 2. ä»€ä¹ˆæ˜¯ Hugging Face Transformersï¼Ÿ  \n> ğŸ§© **å°±åƒä¸€ä¸ªâ€œAIæ¨¡å‹è¶…å¸‚â€**ï¼š  \nä½ ä¸ç”¨è‡ªå·±ä»é›¶å†™ä¸€ä¸ªä¼šè¯´è¯çš„æœºå™¨äººã€‚Hugging Face æŠŠæˆåƒä¸Šä¸‡ä¸ªå·²ç»è®­ç»ƒå¥½çš„AIæ¨¡å‹ï¼ˆæ¯”å¦‚ä¸­æ–‡é—®ç­”ã€è‹±æ–‡ç¿»è¯‘ã€è¯­éŸ³è¯†åˆ«ï¼‰éƒ½æ”¾åœ¨ç½‘ä¸Šï¼Œä½ å¯ä»¥åƒé€›æ·˜å®ä¸€æ ·ï¼Œé€‰ä¸€ä¸ªâ€œæƒ…æ„Ÿåˆ†ææ¨¡å‹â€ã€â€œæ–‡ç”Ÿå›¾æ¨¡å‹â€ï¼Œä¸‹è½½ä¸‹æ¥ç›´æ¥ç”¨ï¼`transformers` å°±æ˜¯è¿™ä¸ªè¶…å¸‚çš„â€œè´­ç‰©è½¦+è¯´æ˜ä¹¦â€ã€‚\n\n#### 3. ä»€ä¹ˆæ˜¯æ¨ç†ï¼ˆInferenceï¼‰å’Œè®­ç»ƒï¼ˆTrainingï¼‰ï¼Ÿ  \n> ğŸ³ **æ¨ç† = ç…®é¥­ï¼Œè®­ç»ƒ = å­¦åšé¥­**ï¼š  \n- **è®­ç»ƒ**ï¼šä½ èŠ±äº†ä¸‰ä¸ªæœˆæ¯å¤©ç»ƒç‚’èœï¼Œå°äº†1000é“èœï¼Œç»ˆäºå­¦ä¼šåšå®«ä¿é¸¡ä¸ â†’ è¿™æ˜¯â€œè®­ç»ƒæ¨¡å‹â€ã€‚  \n- **æ¨ç†**ï¼šä½ ç°åœ¨é—­ç€çœ¼ç›éƒ½èƒ½ç‚’å‡ºä¸€ç›˜å®Œç¾çš„å®«ä¿é¸¡ä¸ â†’ è¿™å°±æ˜¯ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ¥â€œå›ç­”é—®é¢˜â€ã€â€œç¿»è¯‘å¥å­â€ï¼Œå«â€œæ¨ç†â€ã€‚  \n`transformers` æ—¢æ”¯æŒä½ ç›´æ¥ç”¨åˆ«äººåšå¥½çš„èœï¼ˆæ¨ç†ï¼‰ï¼Œä¹Ÿæ”¯æŒä½ é‡æ–°å­¦ç‚’æ–°èœï¼ˆè®­ç»ƒï¼‰ã€‚\n\n#### 4. ä»€ä¹ˆæ˜¯æ¨¡å‹ï¼ˆModelï¼‰ï¼Ÿ  \n> ğŸ“š **å°±åƒä¸€ä¸ªèƒŒäº†10äº¿å¥è¯çš„â€œè¶…çº§å­¦éœ¸â€**ï¼š  \nå®ƒä¸æ˜¯äººï¼Œè€Œæ˜¯ä¸€ä¸ªæ•°å­¦å…¬å¼ç»„æˆçš„â€œå¤§è„‘â€ã€‚ä½ é—®å®ƒï¼šâ€œå·´é»åœ¨å“ªä¸ªå›½å®¶ï¼Ÿâ€ å®ƒä¸æ˜¯ä¸Šç½‘æŸ¥ï¼Œè€Œæ˜¯é ä¹‹å‰â€œè¯»è¿‡â€çš„æµ·é‡æ–‡æœ¬ï¼Œè‡ªå·±çŒœå‡ºæœ€å¯èƒ½çš„ç­”æ¡ˆâ€”â€”æ¯”å¦‚â€œæ³•å›½â€ã€‚\n\n#### 5. ä»€ä¹ˆæ˜¯ Hugging Face Hubï¼Ÿ  \n> ğŸŒ **å°±åƒ GitHub + YouTube + App Store çš„åˆä½“**ï¼š  \nè¿™é‡Œå­˜æ”¾ç€å…¨ä¸–ç•Œå¼€å‘è€…ä¸Šä¼ çš„AIæ¨¡å‹ï¼ˆè¶…è¿‡40ä¸‡ä¸ªï¼ï¼‰ï¼Œä½ å¯ä»¥ä¸‹è½½ã€åˆ†äº«ã€è®¨è®ºã€‚ä½ ç”¨çš„æ¯ä¸€ä¸ªæ¨¡å‹ï¼Œå‡ ä¹éƒ½æ¥è‡ªè¿™é‡Œã€‚\n\n---\n\n### ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡ï¼ˆä¿å§†çº§ï¼Œä»é›¶å¼€å§‹ï¼‰\n\n> âœ… å‡è®¾ä½ çš„ç”µè„‘æ˜¯å…¨æ–°çš„ Windows/Mac/Linuxï¼Œæ²¡è£…è¿‡ä»»ä½•ç¼–ç¨‹å·¥å…·ï¼\n\n#### 1. å®‰è£… Pythonï¼ˆå¿…é¡»ï¼ï¼‰\n- æ‰“å¼€æµè§ˆå™¨ â†’ è®¿é—®å®˜ç½‘ï¼šhttps://www.python.org/downloads/\n- ä¸‹è½½ **Python 3.9 æˆ– 3.10**ï¼ˆä¸è¦é€‰ 3.12+ï¼Œç›®å‰æœ‰äº›åº“è¿˜ä¸å…¼å®¹ï¼‰\n- âœ… **å…³é”®æ­¥éª¤**ï¼šå®‰è£…æ—¶ä¸€å®šè¦å‹¾é€‰ `Add Python to PATH`ï¼  \n  ï¼ˆè¿™ä¸ªé€‰é¡¹è®©ç”µè„‘çŸ¥é“ä½ è£…äº† Pythonï¼‰\n\nğŸ‘‰ éªŒè¯æ˜¯å¦æˆåŠŸï¼š  \næ‰“å¼€å‘½ä»¤è¡Œï¼ˆWindowsæŒ‰ `Win + R` â†’ è¾“å…¥ `cmd` â†’ å›è½¦ï¼‰  \nè¾“å…¥ï¼š\n```bash\npython --version\n```\nâœ… åº”è¯¥çœ‹åˆ°ç±»ä¼¼ï¼š`Python 3.10.8`\n\n> â— å¦‚æœæŠ¥é”™â€œä¸æ˜¯å†…éƒ¨æˆ–å¤–éƒ¨å‘½ä»¤â€ï¼Œè¯´æ˜æ²¡åŠ  PATHã€‚å¸è½½é‡è£…ï¼Œ**ä¸€å®šè¦å‹¾é€‰é‚£ä¸ªé€‰é¡¹ï¼**\n\n#### 2. å®‰è£… pipï¼ˆPythonåŒ…ç®¡ç†å™¨ï¼‰\n- Python 3.4+ è‡ªå¸¦ pipï¼Œä¸ç”¨å•ç‹¬è£…ã€‚\n- éªŒè¯ï¼š\n```bash\npip --version\n```\nâœ… åº”è¯¥çœ‹åˆ° `pip XX.XX.X`\n\n> ğŸš« å¦‚æœæŠ¥é”™ï¼šç”¨è¿™ä¸ªå‘½ä»¤ä¿®å¤ï¼š\n```bash\npython -m ensurepip --upgrade\n```\n\n#### 3. å®‰è£… Gitï¼ˆå¯é€‰ä½†æ¨èï¼‰\n- ä¸‹è½½ï¼šhttps://git-scm.com/download  \n- å®‰è£…æ—¶å…¨éƒ¨é»˜è®¤ä¸‹ä¸€æ­¥å³å¯ã€‚\n- éªŒè¯ï¼š\n```bash\ngit --version\n```\nâœ… æ˜¾ç¤º `git version 2.xx.x`\n\n---\n\n### ğŸ“¦ å®‰è£…æ­¥éª¤ï¼ˆå¤åˆ¶ç²˜è´´å³å¯ï¼ï¼‰\n\n> âš ï¸ æ‰€æœ‰å‘½ä»¤åœ¨ **å‘½ä»¤è¡Œç»ˆç«¯** ä¸­æ‰§è¡Œï¼ˆWindowsï¼šcmd æˆ– PowerShellï¼›Mac/Linuxï¼šTerminalï¼‰\n\n```bash\n# ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºä¸€ä¸ªé¡¹ç›®æ–‡ä»¶å¤¹ï¼ˆä½ è‡ªå·±çš„â€œAIå®éªŒå®¤â€ï¼‰\nmkdir my-ai-project\ncd my-ai-project\n\n# ç¬¬äºŒæ­¥ï¼šåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆé˜²æ­¢æ±¡æŸ“ä½ çš„ç”µè„‘ç³»ç»Ÿï¼‰\npython -m venv env\n\n# ç¬¬ä¸‰æ­¥ï¼šæ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼ˆé‡è¦ï¼æ¯æ¬¡æ‰“å¼€æ–°ç»ˆç«¯éƒ½è¦æ‰§è¡Œè¿™ä¸€æ­¥ï¼‰\n# Windows:\nenv\\Scripts\\activate\n# Mac/Linux:\nsource env/bin/activate\n\n# ç¬¬å››æ­¥ï¼šå®‰è£… Hugging Face Transformers å’Œ PyTorchï¼ˆæ ¸å¿ƒå¼•æ“ï¼‰\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\npip install transformers datasets sentencepiece tokenizers\n\n# âœ… è¯´æ˜ï¼š\n# - torchï¼šAIæ¨¡å‹çš„â€œå¤§è„‘â€è¿ç®—å¼•æ“ï¼Œç±»ä¼¼æ±½è½¦å‘åŠ¨æœº\n# - transformersï¼šHugging Face çš„æ ¸å¿ƒåº“ï¼ŒåŒ…å«æ‰€æœ‰æ¨¡å‹\n# - datasetsï¼šåŠ è½½è®­ç»ƒæ•°æ®ç”¨çš„å·¥å…·åŒ…ï¼ˆæ¯”å¦‚ä¸­æ–‡é—®ç­”æ•°æ®ï¼‰\n```\n\n> ğŸ’¡ **å°è´´å£«**ï¼š  \n> å¦‚æœä½ ç”µè„‘æ˜¯ Apple M1/M2 èŠ¯ç‰‡ï¼Œè¯·æ”¹ç”¨ï¼š\n```bash\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n```\nï¼ˆMèŠ¯ç‰‡ç›®å‰ä¸æ”¯æŒCUDAåŠ é€Ÿï¼Œç”¨CPUä¹Ÿå®Œå…¨å¤Ÿç”¨ï¼ï¼‰\n\n---\n\n### ğŸ® ç¬¬ä¸€æ¬¡ä½¿ç”¨æ¼”ç¤ºï¼ˆ30ç§’è·‘é€šä¸€ä¸ªAIé—®ç­”æœºå™¨äººï¼ï¼‰\n\n> ğŸ’¬ æˆ‘ä»¬æ¥è®© AI å›ç­”ï¼šâ€œä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿâ€\n\n#### æ­¥éª¤ä¸€ï¼šæ–°å»ºä¸€ä¸ª Python æ–‡ä»¶\nåœ¨ä½ çš„ `my-ai-project` æ–‡ä»¶å¤¹é‡Œï¼Œå³é”® â†’ æ–°å»ºæ–‡ä»¶ â†’ å‘½åä¸º `ask_ai.py`\n\n#### æ­¥éª¤äºŒï¼šå¤åˆ¶ç²˜è´´è¿™æ®µä»£ç ï¼ˆåˆ«æ”¹ï¼ï¼‰\n```python\nfrom transformers import pipeline\n\n# 1. åŠ è½½ä¸€ä¸ªå·²ç»è®­ç»ƒå¥½çš„ä¸­æ–‡é—®ç­”æ¨¡å‹ï¼ˆæ¥è‡ª Hugging Face Hubï¼‰\nqa_pipeline = pipeline(\"question-answering\", model=\"bert-base-chinese\")\n\n# 2. å‡†å¤‡ä¸€æ®µæ–‡æœ¬ï¼ˆAIçš„â€œçŸ¥è¯†åº“â€ï¼‰\ncontext = \"ä¸­å›½çš„é¦–éƒ½æ˜¯åŒ—äº¬ã€‚åŒ—äº¬æ˜¯ä¸­åäººæ°‘å…±å’Œå›½çš„æ”¿æ²»ã€æ–‡åŒ–å’Œå›½é™…äº¤å¾€ä¸­å¿ƒã€‚\"\n\n# 3. æé—®ï¼\nquestion = \"ä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ\"\nresult = qa_pipeline(question=question, context=context)\n\n# 4. è¾“å‡ºç­”æ¡ˆ\nprint(\"é—®é¢˜ï¼š\", question)\nprint(\"ç­”æ¡ˆï¼š\", result['answer'])\nprint(\"ä¿¡å¿ƒåˆ†æ•°ï¼š\", round(result['score'], 4))\n```\n\n#### æ­¥éª¤ä¸‰ï¼šè¿è¡Œå®ƒï¼\nåœ¨ç»ˆç«¯ä¸­ï¼ˆç¡®ä¿ä½ å·²æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼‰ï¼š\n```bash\npython ask_ai.py\n```\n\n#### âœ… ä½ ä¼šçœ‹åˆ°è¾“å‡ºï¼š\n```\né—®é¢˜ï¼š ä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ\nç­”æ¡ˆï¼š åŒ—äº¬\nä¿¡å¿ƒåˆ†æ•°ï¼š 0.9876\n```\n\n> ğŸ‰ æ­å–œï¼ä½ åˆšåˆšç”¨ä¸€ä¸ªAIæ¨¡å‹ï¼Œå›ç­”äº†ä¸€ä¸ªçœŸå®é—®é¢˜ï¼  \n> å®ƒä¸æ˜¯ä»ç½‘ä¸Šæœçš„â€”â€”å®ƒæ˜¯â€œè¯»è¿‡â€å¾ˆå¤šä¸­æ–‡èµ„æ–™åè‡ªå·±æ¨ç†å‡ºæ¥çš„ï¼\n\n---\n\n### âš™ï¸ å¸¸ç”¨é…ç½®è¯´æ˜ï¼ˆæ”¹ä¸€æ”¹ï¼Œæ•ˆæœå¤§ä¸åŒï¼‰\n\n| å‚æ•° | é»˜è®¤å€¼ | æ”¹äº†ä¼šæ€æ ·ï¼Ÿ |\n|------|--------|--------------|\n| `model=\"bert-base-chinese\"` | ä¸­æ–‡é—®ç­”æ¨¡å‹ | æ¢æˆ `\"deepset/roberta-base-squad2\"` â†’ æ›´å‡†ä½†åªæ”¯æŒè‹±æ–‡ |\n| `device=\"cpu\"` | ç”¨CPUè®¡ç®— | æ”¹æˆ `device=0`ï¼ˆæœ‰NVIDIAæ˜¾å¡ï¼‰â†’ é€Ÿåº¦æå‡10å€ï¼ |\n| `top_k=1` | åªè¿”å›ä¸€ä¸ªç­”æ¡ˆ | æ”¹æˆ `top_k=3` â†’ è¿”å›ä¸‰ä¸ªå¯èƒ½çš„ç­”æ¡ˆï¼Œé€‰æœ€é è°±çš„ |\n| `max_length=512` | æœ€é•¿æ”¯æŒ512ä¸ªå­— | å¢å¤§å¯è¯»æ›´é•¿æ–‡ç« ï¼ˆå¦‚è®ºæ–‡ï¼‰ï¼Œä½†æ›´æ…¢ |\n\n> ğŸ’¡ **å°æŠ€å·§**ï¼šæƒ³ç”¨è‹±æ–‡æ¨¡å‹ï¼Ÿè¯•è¯•ï¼š\n```python\nqa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n```\n\n---\n\n### â— æ–°æ‰‹å¿…çœ‹çš„å‘ï¼ˆè¡€æ³ªæ€»ç»“ï¼ï¼‰\n\n#### ğŸ”´ å‘1ï¼š`ModuleNotFoundError: No module named 'transformers'`\n> âœ… è§£å†³ï¼šä½ æ²¡æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼  \næ¯æ¬¡æ‰“å¼€æ–°ç»ˆç«¯ï¼Œå…ˆè¿è¡Œï¼š\n```bash\ncd my-ai-project\nenv\\Scripts\\activate   # Windows\nsource env/bin/activate # Mac/Linux\n```\n\n#### ğŸ”´ å‘2ï¼š`CUDA out of memory` æˆ– `GPU not detected`\n> âœ… è§£å†³ï¼šä½ æ²¡è£…æ˜¾å¡é©±åŠ¨æˆ–ç”¨çš„æ˜¯ç¬”è®°æœ¬é›†æˆæ˜¾å¡ã€‚  \nâ†’ **æ”¹ç”¨CPUæ¨¡å¼**ï¼Œåœ¨ä»£ç é‡ŒåŠ ï¼š\n```python\nqa_pipeline = pipeline(\"question-answering\", model=\"bert-base-chinese\", device=-1)\n```\n`device=-1` è¡¨ç¤ºå¼ºåˆ¶ç”¨ CPUï¼Œè™½ç„¶æ…¢ç‚¹ï¼Œä½†èƒ½è·‘ï¼\n\n#### ğŸ”´ å‘3ï¼šä¸‹è½½æ¨¡å‹å¤ªæ…¢/å¤±è´¥ï¼ˆå¢™å¤–èµ„æºï¼‰\n> âœ… è§£å†³ï¼šæ¢å›½å†…é•œåƒæºï¼  \nåœ¨ `ask_ai.py` æœ€å‰é¢åŠ ï¼š\n```python\nimport os\nos.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"  # ç¦ç”¨ç»Ÿè®¡\n# å¦‚æœä½ åœ¨ä¸­å›½ï¼Œå»ºè®®ä½¿ç”¨æ¸…åæºï¼ˆéœ€ç§‘å­¦ä¸Šç½‘æ‰èƒ½ä¸‹è½½æ¨¡å‹ï¼‰\n# å¦åˆ™è€å¿ƒç­‰å¾…â€¦â€¦æœ‰æ—¶è¦5-10åˆ†é’Ÿã€‚\n```\n\n#### ğŸ”´ å‘4ï¼š`pip install` æŠ¥é”™â€œssl certificate verify failedâ€\n> âœ… è§£å†³ï¼šç”¨è¿™ä¸ªå‘½ä»¤ç»•è¿‡è¯ä¹¦ï¼š\n```bash\npip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org transformers\n```\n\n#### ğŸ”´ å‘5ï¼šPythonç‰ˆæœ¬å¤ªé«˜ï¼ˆ3.12+ï¼‰æŠ¥é”™\n> âœ… è§£å†³ï¼šå¸è½½å½“å‰ Pythonï¼Œé‡è£… **3.10.x**ï¼ˆæœ€ç¨³å®šï¼‰ï¼Œåˆ«è´ªæ–°ï¼\n\n---\n\n### ğŸš€ è¿›é˜¶å­¦ä¹ è·¯å¾„ï¼ˆå­¦å®Œè¿™ä¸ªä¹‹åï¼Œä½ è¯¥å¾€å“ªèµ°ï¼Ÿï¼‰\n\n| é˜¶æ®µ | å­¦ä»€ä¹ˆ | ä¸ºä»€ä¹ˆ |\n|------|--------|--------|\n| âœ… ç¬¬ä¸€æ­¥ï¼šæŒæ¡åŸºç¡€æ¨ç† | ç†Ÿç»ƒä½¿ç”¨ `pipeline()` åŠ è½½æ¨¡å‹ | èƒ½ç”¨å°±èµ¢äº†ï¼å…ˆä¼šç”¨å†å­¦åŸç† |\n| ğŸ”œ ç¬¬äºŒæ­¥ï¼šæ¢æ¨¡å‹ | å°è¯• Hugging Face ä¸Šçš„å…¶ä»–æ¨¡å‹ï¼š<br>Â· `gpt2-chinese`ï¼ˆå†™è¯—ï¼‰<br>Â· `facebook/bart-large-cnn`ï¼ˆæ‘˜è¦ï¼‰<br>Â· `openai/whisper-small`ï¼ˆè¯­éŸ³è½¬æ–‡å­—ï¼‰ | æ„Ÿå—ä¸åŒAIçš„èƒ½åŠ› |\n| ğŸ”œ ç¬¬ä¸‰æ­¥ï¼šè‡ªå·±è®­ç»ƒæ¨¡å‹ | å­¦ä¹  `Trainer API`ï¼Œç”¨ä½ çš„æ•°æ®å¾®è°ƒä¸€ä¸ªé—®ç­”æ¨¡å‹ | ä»â€œä½¿ç”¨è€…â€å˜æˆâ€œåˆ›é€ è€…â€ |\n| ğŸŒ ç¬¬å››æ­¥ï¼šéƒ¨ç½²æˆç½‘é¡µ | ç”¨ `Gradio` åšä¸ªç½‘é¡µç•Œé¢ï¼Œè®©æœ‹å‹ä¹Ÿèƒ½é—®AIé—®é¢˜ | æŠŠä½ çš„AIå˜æˆå°å·¥å…·ï¼ |\n| ğŸ§  ç¬¬äº”æ­¥ï¼šå­¦ Transformers åŸç† | çœ‹è®ºæ–‡ã€ŠAttention is All You Needã€‹+ Bç«™è§†é¢‘è®²è§£ | æ‡‚äº†åŸç†ï¼Œä½ å°±æ˜¯å¤§ç¥ |\n\n> ğŸ’¡ æ¨èå­¦ä¹ èµ„æºï¼š\n- å®˜æ–¹æ–‡æ¡£ï¼ˆä¸­æ–‡ï¼‰ï¼šhttps://huggingface.co/docs/transformers/zh\n- Hugging Face è¯¾ç¨‹ï¼ˆå…è´¹ï¼ï¼‰ï¼šhttps://huggingface.co/course/chapter1\n- ä¸­æ–‡æ•™ç¨‹Bç«™æœç´¢ï¼šâ€œHugging Face å…¥é—¨â€\n\n---\n\n### ğŸŒŸ æœ€åé€ä½ ä¸€å¥è¯ï¼š\n\n> **â€œAI ä¸æ˜¯é­”æ³•ï¼Œè€Œæ˜¯å·¥å…·ã€‚è€Œ Hugging Face Transformersï¼Œå°±æ˜¯é‚£ä¸ªè®©ä½ ä¸ç”¨å­¦ç”µå·¥ã€ä¸ä¹°å‘ç”µæœºï¼Œæ’ä¸Šç”µæºå°±èƒ½ç‚¹äº®æ•´ä¸ªåŸå¸‚çš„å¼€å…³ã€‚â€**\n\nä½ ç°åœ¨ï¼Œå·²ç»æ˜¯èƒ½ç”¨ AI æ¨¡å‹çš„äººäº†ï¼  \nä¸‹ä¸€æ­¥ï¼Œå»è¯•è¯•è®©å®ƒå¸®ä½ å†™ä¸€å°æƒ…ä¹¦ï¼Ÿç¿»è¯‘ä¸€å°è‹±æ–‡é‚®ä»¶ï¼Ÿæˆ–è€…â€¦â€¦ç”»ä¸€å¼ çŒ«ï¼Ÿ\n\nğŸš€ **ä½ å·²ç»ç«™åœ¨äº†AIæ—¶ä»£çš„å…¥å£ã€‚æ¬¢è¿æ¥åˆ°æœªæ¥ã€‚**",
    "last_scanned": "2026-01-16T02:05:31.820907",
    "last_analyzed": "2026-01-15T03:47:14.047910",
    "screenshot": "static/screenshots/155220641.jpg",
    "ai_visual_summary": "è¯¥ç•Œé¢æ˜¯ GitHub ä¸Šä¸€ä¸ªåä¸º `transformers` çš„å¼€æºé¡¹ç›®é¡µé¢ï¼Œç”± `huggingface` ç»´æŠ¤ã€‚å…¶ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬ä»£ç ä»“åº“ã€é—®é¢˜è·Ÿè¸ªã€æ‹‰å–è¯·æ±‚ã€é¡¹ç›®ç®¡ç†å’Œæ´»åŠ¨æ—¥å¿—ã€‚ä»å¯è§çš„â€œAboutâ€éƒ¨åˆ†æè¿°å’Œæ ‡ç­¾ï¼ˆå¦‚ `pytorch`, `transformer`, `natural-language-processing`, `deep-learning`ï¼‰å¯ä»¥åˆ¤æ–­ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå’Œè®­ç»ƒæ–‡æœ¬ã€è§†è§‰ã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ¡†æ¶ï¼Œæ ¸å¿ƒåŠŸèƒ½æ˜¯æ¨¡å‹å®šä¹‰å’Œç®¡ç†ã€‚è¯¥åº”ç”¨çš„ UI è®¾è®¡é£æ ¼ç®€æ´ã€ç°ä»£ï¼Œä»¥ä¿¡æ¯å¯†åº¦é«˜ã€åŠŸèƒ½åˆ†åŒºæ˜ç¡®ä¸ºç‰¹ç‚¹ï¼Œæ˜¯å…¸å‹çš„å¼€å‘è€…å·¥å…·ç½‘ç«™ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "42751014",
    "name": "clipboard.js",
    "full_name": "zenorocha/clipboard.js",
    "category": "multimodal",
    "stars": 34185,
    "forks": 3935,
    "description": ":scissors: Modern copy to clipboard. No Flash. Just 3kb gzipped :clipboard:",
    "url": "https://github.com/zenorocha/clipboard.js",
    "homepage": "https://clipboardjs.com",
    "language": "JavaScript",
    "topics": "[\"clipboard\", \"javascript\"]",
    "created_at": "2015-09-18T23:04:55Z",
    "updated_at": "2026-01-15T14:23:23Z",
    "readme_content": null,
    "ai_summary": "clipboard.js æ˜¯ä¸€ä¸ªè½»é‡çº§ JavaScript åº“ï¼Œç”¨äºå®ç°ç°ä»£ç½‘é¡µä¸Šçš„å¤åˆ¶åˆ°å‰ªè´´æ¿åŠŸèƒ½ã€‚å®ƒä¸ä¾èµ– Flash æˆ–ä»»ä½•è‡ƒè‚¿çš„æ¡†æ¶ï¼Œå¹¶é€šè¿‡ HTML5 æ•°æ®å±æ€§ç®€åŒ–äº†ä½¿ç”¨æ–¹å¼ã€‚",
    "ai_tech_stack": "[\"JavaScript\", \"DOM \\u64cd\\u4f5c\"]",
    "ai_use_cases": "[\"\\u5feb\\u901f\\u590d\\u5236\\u6587\\u672c\\u5185\\u5bb9\", \"\\u652f\\u6301\\u8de8\\u6d4f\\u89c8\\u5668\\u517c\\u5bb9\\u6027\\uff08\\u5982 Chrome\\u3001Firefox \\u7b49\\uff09\", \"\\u524d\\u7aef\\u8868\\u5355\\u6216\\u8f93\\u5165\\u6846\\u64cd\\u4f5c\"]",
    "ai_difficulty": 1,
    "ai_quick_start": "npm install clipboard --save",
    "ai_tutorial": "### ğŸ¯ æ ¸å¿ƒä»·å€¼ & å·®å¼‚åŒ–  \nclipboard.js çš„æ ¸å¿ƒå·®å¼‚åŒ–åœ¨äºï¼š**ä»¥ 3KB çš„ä½“ç§¯ï¼Œå®ç°äº†æ— ä¾èµ–ã€æ—  Flashã€å£°æ˜å¼ API çš„è·¨æµè§ˆå™¨å‰ªè´´æ¿æ“ä½œ**ï¼Œåœ¨ 2015 å¹´ Flash æ­»äº¡å‰å¤•ç²¾å‡†å¡«è¡¥äº†â€œè½»é‡çº§åŸç”Ÿå‰ªè´´æ¿äº¤äº’â€çš„ç©ºç™½ã€‚ç›¸æ¯”å½“æ—¶ä¸»æµæ–¹æ¡ˆï¼ˆå¦‚ ZeroClipboard åŸºäº Flashï¼‰ã€æˆ–åæ¥çš„ Clipboard APIï¼ˆéœ€ HTTPSã€æƒé™ç”³è¯·ã€ä¸æ”¯æŒ IEï¼‰ï¼Œå®ƒé€šè¿‡**è¯­ä¹‰åŒ– HTML å±æ€§ + äº‹ä»¶å§”æ‰˜ + ä¼˜é›…é™çº§**ï¼Œåœ¨ä¸ä¾èµ–æ¡†æ¶çš„å‰æä¸‹ï¼Œè®©å¼€å‘è€…ç”¨ä¸‰è¡Œä»£ç è§£å†³è·¨æµè§ˆå™¨å…¼å®¹æ€§å™©æ¢¦ã€‚å…¶ä»·å€¼ä¸æ˜¯æŠ€æœ¯å…ˆè¿›æ€§ï¼Œè€Œæ˜¯**æç®€ä¸»ä¹‰å·¥ç¨‹å“²å­¦çš„èƒœåˆ©**ï¼šç”¨æœ€å°æˆæœ¬è§£å†³æœ€å¤§é‡çš„â€œä½é˜¶ä½†é«˜é¢‘â€äº¤äº’éœ€æ±‚ã€‚\n\n### ğŸ”¥ æŠ€æœ¯äº®ç‚¹  \n- **äº‹ä»¶å§”æ‰˜ + é™æ€é€‰æ‹©å™¨ç¼“å­˜**ï¼šä»…ç»‘å®šä¸€ä¸ªå…¨å±€ `click` ä»£ç†ç›‘å¬å™¨ï¼ˆè€Œéæ¯ä¸ªæŒ‰é’®ç‹¬ç«‹ç›‘å¬ï¼‰ï¼Œé€šè¿‡ `event.target.closest('[data-clipboard-target]')` åŠ¨æ€åŒ¹é…è§¦å‘å…ƒç´ ï¼Œå†…å­˜å ç”¨æ’å®š O(1)ï¼Œæ”¯æŒåŠ¨æ€ DOM æ’å…¥ã€‚  \n- **æ™ºèƒ½ç›®æ ‡è§£æ**ï¼šè‡ªåŠ¨è¯†åˆ« `data-clipboard-target` çš„ CSS é€‰æ‹©å™¨ã€ID æˆ–å…ƒç´ å¼•ç”¨ï¼Œå¹¶å…¼å®¹ `<input>`/`<textarea>` çš„ `.select()` + `document.execCommand('copy')` æµè§ˆå™¨å…¼å®¹æ¨¡å¼ï¼Œæ— éœ€æ‰‹åŠ¨èšç„¦æˆ–é€‰ä¸­ã€‚  \n- **ä¼˜é›…é™çº§ä¸é”™è¯¯éš”ç¦»**ï¼šå¯¹ä¸æ”¯æŒ `execCommand` çš„ç¯å¢ƒï¼ˆå¦‚æ—§ Safariï¼‰é™é»˜å¤±è´¥ï¼Œä¸æŠ›å¼‚å¸¸ï¼›å¯¹æ— æ•ˆç›®æ ‡å…ƒç´ è‡ªåŠ¨è·³è¿‡ï¼Œä¸å½±å“å…¶ä»–ç»„ä»¶è¿è¡Œã€‚  \n- **é›¶æ„å»ºä¾èµ–**ï¼šæºç ç›´æ¥æš´éœ² `dist/clipboard.min.js`ï¼Œæ— éœ€ Webpack/Babelï¼Œé€‚é…ä»»æ„é¡¹ç›®ï¼ˆä» jQuery æ—¶ä»£åˆ°ç°ä»£æ¡†æ¶ï¼‰ï¼Œé™ä½é›†æˆé—¨æ§›ã€‚\n\n### ğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†æ  \n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   ClipboardJS        â”‚ â† å…¥å£ç±»ï¼Œå•ä¾‹æ¨¡å¼å®ä¾‹åŒ–\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Delegate           â”‚ â† æ ¸å¿ƒï¼šå…¨å±€äº‹ä»¶ç›‘å¬å™¨ï¼ˆclickï¼‰\nâ”‚  - listens to: [data-clipboard-action], [data-clipboard-target] |\nâ”‚  - uses: closest(), matches() for target matching              |\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Action             â”‚ â† æ“ä½œæŠ½è±¡ï¼šCopy / Cut\nâ”‚  - copy(): selectText() â†’ execCommand('copy')                 |\nâ”‚  - cut():  selectText() â†’ execCommand('cut')                  |\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   TextResolver       â”‚ â† è§£ææ–‡æœ¬æºï¼šä» attribute / target element / fallback\nâ”‚  - getTarget(): querySelector() + .value/.textContent         |\nâ”‚  - getText(): data-clipboard-text æˆ– fallback                 |\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Feedback           â”‚ â† å¯é€‰ï¼šæä¾› success/error äº‹ä»¶ï¼ˆéæ ¸å¿ƒï¼‰\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**æ•°æ®æµå‘**ï¼š  \n`HTML å…ƒç´ ç‚¹å‡» â†’ ä»£ç†ç›‘å¬å™¨æ•è· â†’ åŒ¹é… data-clipboard-* å±æ€§ â†’ è§£æç›®æ ‡å…ƒç´ æˆ–æ–‡æœ¬ â†’ æ‰§è¡Œ select() + execCommand('copy/cut') â†’ è§¦å‘ success/error äº‹ä»¶`\n\n### ğŸ”§ æŠ€æœ¯æ ˆæ·±åº¦è§£æ  \n- **åŸç”Ÿ DOM APIï¼ˆ`querySelector`, `execCommand`, `select()`ï¼‰**ï¼š  \n  å”¯ä¸€ä¾èµ–ã€‚é€‰æ‹©å®ƒä»¬æ˜¯å› ä¸ºï¼š  \n  - æ‰€æœ‰ç°ä»£æµè§ˆå™¨æ”¯æŒï¼ˆIE9+ï¼‰ï¼Œæ— éœ€ polyfillï¼›  \n  - `execCommand('copy')` æ˜¯å½“æ—¶å”¯ä¸€è·¨å¹³å°æ ‡å‡†ï¼ˆç›´åˆ° 2018 å¹´ Clipboard API æˆç†Ÿï¼‰ï¼›  \n  - æ›¿ä»£æ–¹æ¡ˆå¦‚ `navigator.clipboard.writeText()` éœ€ HTTPS + ç”¨æˆ·æ‰‹åŠ¿ï¼Œä¸” IE å®Œå…¨ä¸æ”¯æŒã€‚  \n- **æ— å¤–éƒ¨ä¾èµ–**ï¼š  \n  ä¸ä½¿ç”¨ jQueryã€Lodash ç­‰ï¼Œé¿å…ä½“ç§¯è†¨èƒ€å’Œç‰ˆæœ¬å†²çªï¼Œç¬¦åˆâ€œ3KBâ€æ ¸å¿ƒæ‰¿è¯ºã€‚  \n- **å…¼å®¹æ€§ç­–ç•¥**ï¼š  \n  å¯¹ `execCommand` å¤±è´¥å›é€€åˆ° `alert()` æç¤ºï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼ï¼‰ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹ã€‚\n\n### ğŸ“¦ å®‰è£…ä¸é…ç½®  \n```bash\n# npm å®‰è£…ï¼ˆæ¨èï¼‰\nnpm install clipboard --save\n\n# æˆ–ç›´æ¥ä¸‹è½½ç”Ÿäº§ç¯å¢ƒæ–‡ä»¶\ncurl -O https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js\n```\n\nHTML å¼•å…¥ï¼š\n```html\n<!-- æ”¾åœ¨ </body> å‰ï¼Œç¡®ä¿ DOM å·²åŠ è½½ -->\n<script src=\"node_modules/clipboard/dist/clipboard.min.js\"></script>\n```\n\nåˆå§‹åŒ–ï¼ˆES5ï¼‰ï¼š\n```js\n// ä¸ºæ‰€æœ‰ .btn å…ƒç´ ç»‘å®šå¤åˆ¶åŠŸèƒ½\nnew ClipboardJS('.btn');\n```\n\n### ğŸ® ä½¿ç”¨ç¤ºä¾‹  \n**åœºæ™¯**ï¼šä¸€é”®å¤åˆ¶ GitHub ä»“åº“åœ°å€ï¼Œæ”¯æŒå¤åˆ¶ä¸å‰ªåˆ‡ä¸¤ç§æ“ä½œã€‚\n\n```html\n<!-- ç›®æ ‡å…ƒç´  -->\n<input id=\"repo-url\" value=\"https://github.com/zenorocha/clipboard.js.git\" readonly>\n\n<!-- å¤åˆ¶æŒ‰é’® -->\n<button class=\"btn\" data-clipboard-target=\"#repo-url\">\n  Copy URL\n</button>\n\n<!-- å‰ªåˆ‡æ–‡æœ¬æ¡†å†…å®¹ï¼ˆä»…å¯¹ input/textarea ç”Ÿæ•ˆï¼‰ -->\n<textarea id=\"code-snippet\">console.log('Hello World');</textarea>\n<button class=\"btn\" data-clipboard-action=\"cut\" data-clipboard-target=\"#code-snippet\">\n  Cut Code\n</button>\n\n<!-- ç›´æ¥å¤åˆ¶é™æ€æ–‡æœ¬ -->\n<button class=\"btn\" data-clipboard-text=\"Static text to copy\">\n  Copy Static Text\n</button>\n```\n\n**é¢„æœŸè¾“å‡º**ï¼š  \nç‚¹å‡»æŒ‰é’®åï¼Œç›®æ ‡å†…å®¹è¢«å†™å…¥ç³»ç»Ÿå‰ªè´´æ¿ï¼Œç”¨æˆ·å¯ç²˜è´´ï¼ˆCtrl+Vï¼‰ã€‚\n\n### âš¡ æ€§èƒ½ä¸ä¼˜åŒ–  \n- **æ€§èƒ½ç“¶é¢ˆ**ï¼šæ— ã€‚å•ä¸ªå…¨å±€äº‹ä»¶ç›‘å¬å™¨ + é€‰æ‹©å™¨åŒ¹é…ï¼ˆ`closest()`ï¼‰ä¸º O(n) ä½† n æå°ï¼ˆé€šå¸¸<10ï¼‰ï¼Œå†…å­˜å ç”¨ <5KBï¼Œæ¯«ç§’çº§åˆå§‹åŒ–ã€‚  \n- **ç”Ÿäº§ç¯å¢ƒæ‰©å±•**ï¼š  \n  - æ”¯æŒ SSR/SSG æ¡†æ¶ï¼ˆå¦‚ Next.js/VuePressï¼‰ï¼šåœ¨ `mounted` æˆ– `useEffect` ä¸­å®ä¾‹åŒ–ï¼›  \n  - åŠ¨æ€ç»„ä»¶ï¼šä½¿ç”¨ `new ClipboardJS(element)` æ‰‹åŠ¨ç»‘å®šï¼Œé¿å… selector åŒ¹é…å¼€é”€ï¼›  \n  - å¤§é‡å…ƒç´ åœºæ™¯ï¼šç”¨ `data-clipboard-text` æ›¿ä»£ `data-clipboard-target`ï¼Œå‡å°‘ DOM æŸ¥è¯¢ã€‚  \n- **èµ„æºæ¶ˆè€—**ï¼š  \n  å¯åŠ¨åå†…å­˜å ç”¨çº¦ 10â€“20KBï¼ˆå«äº‹ä»¶ç›‘å¬å™¨å’Œç¼“å­˜ï¼‰ï¼ŒCPU æ— æŒç»­è´Ÿè½½ã€‚\n\n### ğŸ”Œ äºŒæ¬¡å¼€å‘æŒ‡å—  \n**æ‰©å±•ç‚¹**ï¼š  \n1. **è‡ªå®šä¹‰æ–‡æœ¬è§£æå™¨**ï¼šé‡å†™ `TextResolver` çš„ `getText()` æ–¹æ³•ï¼Œæ”¯æŒä» JSONã€API åŠ¨æ€è·å–ã€‚  \n2. **æ–°å¢æ“ä½œç±»å‹**ï¼šåœ¨ `Action` ç±»ä¸­æ·»åŠ  `data-clipboard-action=\"move\"`ï¼Œå®ç°â€œå¤åˆ¶å¹¶æ¸…ç©ºæºâ€ã€‚  \n3. **äº‹ä»¶é’©å­å¢å¼º**ï¼šç›‘å¬ `success`/`error` äº‹ä»¶ï¼Œé›†æˆ Toast æç¤ºæˆ– Analyticsï¼š\n\n```js\nconst clipboard = new ClipboardJS('.btn');\n\nclipboard.on('success', (e) => {\n  e.trigger.textContent = 'Copied!';\n  setTimeout(() => { e.trigger.textContent = 'Copy'; }, 2000);\n});\n```\n\n**API æ¥å£**ï¼š  \n- `new ClipboardJS(selector: string | Element | NodeListOf<Element>, options?: Options)`  \n- `options` æ”¯æŒï¼š`container`, `text`, `target`, `action`ï¼ˆå¯è¦†ç›– HTML å±æ€§ï¼‰  \n- äº‹ä»¶ï¼š`success(e)`, `error(e)`ï¼Œe åŒ…å« `trigger`, `text`, `action`\n\n### â— å¸¸è§é—®é¢˜ä¸é¿å‘  \n1. **â€œä¸ºä»€ä¹ˆå¤åˆ¶å¤±è´¥ï¼Ÿâ€** â†’ æ£€æŸ¥æ˜¯å¦åœ¨ HTTP é¡µé¢ï¼ˆé HTTPSï¼‰ï¼Œæ—§æµè§ˆå™¨ä¸æ”¯æŒ `execCommand` åœ¨éç”¨æˆ·äº¤äº’ä¸­è°ƒç”¨ã€‚  \n2. **â€œdata-clipboard-target ä¸ç”Ÿæ•ˆâ€** â†’ ç¡®ä¿ç›®æ ‡å…ƒç´ å­˜åœ¨ä¸” ID æ­£ç¡®ï¼Œå¦‚ `#foo` è€Œé `foo`ï¼›é¿å…ä½¿ç”¨åŠ¨æ€ç”Ÿæˆçš„ IDï¼ˆå¦‚ Vue/React çš„éšæœº idï¼‰ã€‚  \n3. **â€œå¤šä¸ªæŒ‰é’®ç»‘å®šååªæœ‰ç¬¬ä¸€ä¸ªæœ‰æ•ˆâ€** â†’ æ²¡æœ‰é”€æ¯æ—§å®ä¾‹ã€‚ä½¿ç”¨ `.destroy()` å†é‡å»ºï¼š`clipboard.destroy(); clipboard = new ClipboardJS(...)`ã€‚  \n4. **â€œåœ¨ React/Vue ä¸­æŠ¥é”™ï¼šCannot read property â€˜querySelectorâ€™ of nullâ€** â†’ ç»„ä»¶æœªæŒ‚è½½æ—¶å°±æ‰§è¡Œäº† `new ClipboardJS`ï¼Œç§»åˆ° `useEffect`/`mounted` ä¸­ã€‚  \n5. **â€œå¤åˆ¶åæ²¡æœ‰è§†è§‰åé¦ˆâ€** â†’ é»˜è®¤æ—  UI åé¦ˆï¼Œéœ€æ‰‹åŠ¨ç›‘å¬ `success/error` äº‹ä»¶æ·»åŠ æç¤ºï¼ˆå¦‚ CSS åŠ¨ç”»æˆ– Toastï¼‰ã€‚  \n6. **â€œåœ¨ iOS Safari ä¸Šæ— æ•ˆâ€** â†’ iOS éœ€ç”¨æˆ·æ‰‹åŠ¿è§¦å‘ä¸”ä»…æ”¯æŒ `<input>`/`<textarea>` çš„ `.select()` + `execCommand`ï¼Œæ–‡æœ¬æ¡†å¿…é¡»æœ‰ focusã€‚\n\n### ğŸš€ è¿›é˜¶å­¦ä¹ è·¯å¾„  \n- å­¦ä¹ ç°ä»£ Clipboard APIï¼š`navigator.clipboard.writeText()` â€”â€” äº†è§£æƒé™æ¨¡å‹ã€å¼‚æ­¥æ€§ä¸å®‰å…¨é™åˆ¶ã€‚  \n- ç ”ç©¶ **react-clipboard.js**ï¼ˆåŸºäº clipboard.js çš„ React å°è£…ï¼‰â†’ æŒæ¡ç»„ä»¶åŒ–å°è£…æŠ€å·§ã€‚  \n- å®ç°ä¸€ä¸ªâ€œè·¨å¹³å°å‰ªè´´æ¿ç®¡ç†å™¨â€ï¼šç»“åˆ Web API + Electron + Native Modulesï¼Œæ”¯æŒ PC/Mac/iOS/Android äº’é€šã€‚  \n- æ·±å…¥é˜…è¯» [MDN execCommand æ–‡æ¡£](https://developer.mozilla.org/en-US/docs/Web/API/Document/execCommand) â†’ ç†è§£æµè§ˆå™¨å†å²é—ç•™æœºåˆ¶ã€‚  \n- å¯¹æ¯” **Copy-to-clipboard**ï¼ˆ2019 å¹´åä¸»æµæ–¹æ¡ˆï¼‰ä¸ clipboard.js çš„æ¶æ„æ¼”è¿›ï¼Œç†è§£â€œè½»é‡ vs åŠŸèƒ½å®Œå¤‡â€çš„æƒè¡¡å“²å­¦ã€‚",
    "last_scanned": "2026-01-16T02:05:31.821972",
    "last_analyzed": "2026-01-15T20:26:10.623235",
    "screenshot": "static/screenshots/42751014.jpg",
    "ai_visual_summary": "è¯¥æˆªå›¾å±•ç¤ºäº†ä¸€ä¸ªåä¸º `clipboard.js` çš„ GitHub é¡¹ç›®æ–‡æ¡£é¡µé¢ï¼Œå…¶è®¾è®¡é£æ ¼ç®€æ´ã€ç°ä»£ï¼Œä»¥ç™½è‰²ä¸ºä¸»èƒŒæ™¯ï¼Œé…ä»¥ç°è‰²å’Œè“è‰²çš„ç‚¹ç¼€ï¼Œç¬¦åˆ GitHub å®˜æ–¹çš„ UI è®¾è®¡è§„èŒƒã€‚ç•Œé¢ä¸»è¦åŠŸèƒ½æ¨¡å—åŒ…æ‹¬é¡¹ç›®æè¿°ã€æ ¸å¿ƒåŠŸèƒ½ç¤ºä¾‹ï¼ˆå¦‚â€œCut to clipboardâ€ã€â€œCopy to clipboardâ€ï¼‰å’Œä»£ç ç‰‡æ®µå±•ç¤ºï¼Œæ—¨åœ¨æ¸…æ™°åœ°è¯´æ˜å¦‚ä½•ä½¿ç”¨è¯¥åº“ã€‚å¯è§çš„æŠ€æœ¯å…³é”®è¯åŒ…æ‹¬ `clipboard.js`ã€`data-clipboard-action`ã€`data-clipboard-target` å’Œ `data-clipboard-text`ï¼Œè¿™äº›è¡¨æ˜è¯¥åº”ç”¨æ˜¯ä¸€ä¸ªç”¨äºåœ¨ç½‘é¡µä¸­å®ç°â€œå¤åˆ¶åˆ°å‰ªè´´æ¿â€åŠŸèƒ½çš„ JavaScript åº“ï¼Œå®ƒåˆ©ç”¨ HTML å±æ€§å’ŒåŸç”Ÿ APIï¼Œæ— éœ€ Flashï¼Œå¼ºè°ƒè½»é‡ï¼ˆ3kb gzipï¼‰å’Œæ˜“ç”¨æ€§ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "321960447",
    "name": "CLIP",
    "full_name": "openai/CLIP",
    "category": "multimodal",
    "stars": 32279,
    "forks": 3883,
    "description": "CLIP (Contrastive Language-Image Pretraining),  Predict the most relevant text snippet given an image",
    "url": "https://github.com/openai/CLIP",
    "homepage": "",
    "language": "Jupyter Notebook",
    "topics": "[\"deep-learning\", \"machine-learning\"]",
    "created_at": "2020-12-16T11:24:42Z",
    "updated_at": "2026-01-15T14:24:58Z",
    "readme_content": null,
    "ai_summary": "CLIPæ˜¯ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œé€šè¿‡é¢„è®­ç»ƒåœ¨å¤§é‡å›¾åƒ-æ–‡æœ¬å¯¹ä¸Šï¼Œèƒ½å¤Ÿç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¹¶ç”Ÿæˆä¸è¾“å…¥å›¾åƒæœ€ç›¸å…³çš„æ–‡æœ¬æè¿°ã€‚å…¶æ ¸å¿ƒç‰¹ç‚¹æ˜¯ç»“åˆäº†è§†è§‰Transformeræ¶æ„å’Œå…ˆè¿›çš„tokenizationæŠ€æœ¯ï¼Œå¹¶åˆ©ç”¨é›¶æ ·æœ¬è¿ç§»èƒ½åŠ›å®ç°æ— éœ€é¢å¤–æ ‡æ³¨æ•°æ®å³å¯å®Œæˆå¤šç§ä¸‹æ¸¸ä»»åŠ¡ã€‚",
    "ai_tech_stack": "[\"PyTorch\", \"torchvision\", \"ViT\\u67b6\\u6784\"]",
    "ai_use_cases": "[\"\\u56fe\\u50cf\\u5185\\u5bb9\\u7406\\u89e3\\uff08\\u5982\\u7ed9\\u56fe\\u7247\\u751f\\u6210\\u63cf\\u8ff0\\uff09\", \"\\u8de8\\u6a21\\u6001\\u641c\\u7d22\\u4e0e\\u5339\\u914d\\uff08\\u5c06\\u6587\\u672c\\u6620\\u5c04\\u5230\\u56fe\\u50cf\\u7279\\u5f81\\u7a7a\\u95f4\\uff09\", \"\\u96f6\\u6837\\u672c\\u8bc6\\u522b\\u6280\\u672f\\u5f00\\u53d1\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "pip install ftfy regex tqdm && pip install git+https://github.com/openai/CLIP.git",
    "ai_tutorial": "# CLIP\n\nCLIP (Contrastive Language-Image Pretraining),  Predict the most relevant text snippet given an image",
    "last_scanned": "2026-01-16T02:05:31.821972",
    "last_analyzed": "2026-01-15T23:33:51.819349",
    "screenshot": "static/screenshots/321960447.jpg",
    "ai_visual_summary": "è¯¥ç•Œé¢æ˜¯ GitHub ä¸Š CLIP é¡¹ç›®æ–‡æ¡£çš„æˆªå›¾ï¼Œé‡‡ç”¨ç®€æ´çš„å•æ å¸ƒå±€ï¼Œä»¥ä»£ç å—å’Œè¯´æ˜æ–‡å­—ä¸ºä¸»ï¼ŒåŠŸèƒ½æ¨¡å—åŒ…æ‹¬æ ¸å¿ƒ API æ¥å£è¯´æ˜å’Œé›¶æ ·æœ¬é¢„æµ‹ç¤ºä¾‹ã€‚å…³é”®æŠ€æœ¯å…³é”®è¯æœ‰ `CLIP`ã€`Contrastive Language-Image Pretraining`ã€`PyTorch`ã€`torchvision` å’Œ `CIFAR-100`ã€‚ä»å†…å®¹çœ‹ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¤šæ¨¡æ€å­¦ä¹ çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤Ÿæ ¹æ®è¾“å…¥çš„å›¾åƒé¢„æµ‹æœ€ç›¸å…³çš„æ–‡æœ¬æè¿°ï¼Œå®ç°å›¾åƒ-æ–‡æœ¬çš„è¯­ä¹‰åŒ¹é…ã€‚",
    "ai_rag_summary": null
  },
  {
    "id": "629102662",
    "name": "LLaVA",
    "full_name": "haotian-liu/LLaVA",
    "category": "multimodal",
    "stars": 24315,
    "forks": 2701,
    "description": "[NeurIPS'23 Oral] Visual Instruction Tuning (LLaVA) built towards GPT-4V level capabilities and beyond.",
    "url": "https://github.com/haotian-liu/LLaVA",
    "homepage": "https://llava.hliu.cc",
    "language": "Python",
    "topics": "[\"chatbot\", \"chatgpt\", \"foundation-models\", \"gpt-4\", \"instruction-tuning\", \"llama\", \"llama-2\", \"llama2\", \"llava\", \"multi-modality\", \"multimodal\", \"vision-language-model\", \"visual-language-learning\"]",
    "created_at": "2023-04-17T16:13:11Z",
    "updated_at": "2026-01-15T14:27:54Z",
    "readme_content": null,
    "ai_summary": "åŸºäºè§†è§‰æŒ‡ä»¤è°ƒæ•´æŠ€æœ¯çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLMMï¼‰ï¼Œä¸“æ³¨äºå›¾åƒå’Œè§†é¢‘ç†è§£ä¸ç”Ÿæˆä»»åŠ¡ï¼Œæ”¯æŒGPT-4Vçº§åˆ«çš„èƒ½åŠ›ï¼Œå¹¶å…·å¤‡è·¨æ¨¡å‹é€‚é…æ€§ã€‚",
    "ai_tech_stack": "[\"Python\", \"transformers\", \"accelerate\", \"torch\", \"PIL/\\u56fe\\u50cf\\u5904\\u7406\"]",
    "ai_use_cases": "[\"\\u89c6\\u89c9\\u95ee\\u7b54\\uff08Visual Question Answering\\uff09\", \"\\u591a\\u6a21\\u6001\\u5bf9\\u8bdd\\u7cfb\\u7edf\\u96c6\\u6210\", \"AI \\u89c6\\u89c9\\u5185\\u5bb9\\u751f\\u6210\\u5de5\\u5177\\u5f00\\u53d1\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "git clone https://github.com/haotian-liu/LLaVA.git && pip install -r requirements.txt && python3 -m llava.eval.model --model-path /path/to/model",
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.822878",
    "last_analyzed": "2026-01-16T02:22:28.397442",
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "918932603",
    "name": "UI-TARS-desktop",
    "full_name": "bytedance/UI-TARS-desktop",
    "category": "multimodal",
    "stars": 23767,
    "forks": 2305,
    "description": "The Open-Source Multimodal AI Agent Stack: Connecting Cutting-Edge AI Models and Agent Infra",
    "url": "https://github.com/bytedance/UI-TARS-desktop",
    "homepage": "https://agent-tars.com",
    "language": "TypeScript",
    "topics": "[\"agent\", \"agent-tars\", \"browser-use\", \"computer-use\", \"cowork\", \"gui-agent\", \"gui-operator\", \"mcp\", \"mcp-server\", \"multimodal\", \"tars\", \"ui-tars\", \"vision\", \"vlm\"]",
    "created_at": "2025-01-19T09:04:43Z",
    "updated_at": "2026-01-15T18:04:32Z",
    "readme_content": null,
    "ai_summary": "åŸºäºå­—èŠ‚è·³åŠ¨TARSå¤šæ¨¡æ€AI Agentæ¡†æ¶å¼€å‘çš„æ¡Œé¢åº”ç”¨ï¼Œæä¾›æœ¬åœ°/è¿œç¨‹å›¾å½¢åŒ–äº¤äº’ç•Œé¢ï¼Œé›†æˆè®¡ç®—æœºæ“ä½œã€æµè§ˆå™¨æ§åˆ¶ç­‰å¤šåŠŸèƒ½è‡ªåŠ¨åŒ–å·¥å…·",
    "ai_tech_stack": "[\"React\", \"Electron\", \"Node.js\", \"TypeScript\", \"UI-TARS\\u6a21\\u578b\"]",
    "ai_use_cases": "[\"\\u684c\\u9762\\u7ea7\\u4efb\\u52a1\\u81ea\\u52a8\\u6267\\u884c\", \"\\u8de8\\u8bbe\\u5907\\u534f\\u540c\\u64cd\\u4f5c\", \"\\u7f51\\u9875\\u8868\\u5355\\u667a\\u80fd\\u586b\\u5145\", \"\\u8fdc\\u7a0b\\u670d\\u52a1\\u5668\\u8c03\\u8bd5\\u8f85\\u52a9\", \"\\u591a\\u5a92\\u4f53\\u5185\\u5bb9\\u5206\\u6790\\u5904\\u7406\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "npm install && npm start -- -m <model-path>",
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.823411",
    "last_analyzed": "2026-01-16T02:25:42.015728",
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "740303686",
    "name": "sglang",
    "full_name": "sgl-project/sglang",
    "category": "multimodal",
    "stars": 22461,
    "forks": 4062,
    "description": "SGLang is a high-performance serving framework for large language models and multimodal models.",
    "url": "https://github.com/sgl-project/sglang",
    "homepage": "https://docs.sglang.io/",
    "language": "Python",
    "topics": "[\"attention\", \"blackwell\", \"cuda\", \"deepseek\", \"diffusion\", \"glm\", \"gpt-oss\", \"inference\", \"llama\", \"llm\", \"minimax\", \"moe\", \"qwen\", \"qwen-image\", \"reinforcement-learning\", \"transformer\", \"vlm\", \"wan\"]",
    "created_at": "2024-01-08T04:15:52Z",
    "updated_at": "2026-01-15T17:29:49Z",
    "readme_content": null,
    "ai_summary": "é«˜æ€§èƒ½å¤§å‹è¯­è¨€æ¨¡å‹ä¸å¤šæ¨¡æ€æ¨¡å‹çš„æœåŠ¡æ¡†æ¶ï¼Œé‡‡ç”¨åˆ†å¸ƒå¼æ¨ç†ä¼˜åŒ–æŠ€æœ¯å®ç°ä½å»¶è¿Ÿé«˜ååé‡",
    "ai_tech_stack": "[\"LangChain\", \"FastAPI\", \"JAX\", \"PyTorch\"]",
    "ai_use_cases": "[\"\\u5728\\u7ebfLLM API\\u670d\\u52a1\\u90e8\\u7f72\", \"\\u804a\\u5929\\u673a\\u5668\\u4eba\\u5e26\\u56fe\\u50cf\\u751f\\u6210\\u529f\\u80fd\", \"\\u5927\\u89c4\\u6a21\\u89c6\\u9891/\\u56fe\\u7247\\u751f\\u6210\\u52a0\\u901f\"]",
    "ai_difficulty": 4,
    "ai_quick_start": "python -m sgl.serve --model-path /path/to/model",
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.823951",
    "last_analyzed": "2026-01-16T02:28:56.613076",
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "240315046",
    "name": "serve",
    "full_name": "jina-ai/serve",
    "category": "multimodal",
    "stars": 21820,
    "forks": 2239,
    "description": "â˜ï¸ Build multimodal AI applications with cloud-native stack",
    "url": "https://github.com/jina-ai/serve",
    "homepage": "https://jina.ai/serve",
    "language": "Python",
    "topics": "[\"cloud-native\", \"cncf\", \"deep-learning\", \"docker\", \"fastapi\", \"framework\", \"generative-ai\", \"grpc\", \"jaeger\", \"kubernetes\", \"llmops\", \"machine-learning\", \"microservice\", \"mlops\", \"multimodal\", \"neural-search\", \"opentelemetry\", \"orchestration\", \"pipeline\", \"prometheus\"]",
    "created_at": "2020-02-13T17:04:44Z",
    "updated_at": "2026-01-14T03:15:11Z",
    "readme_content": null,
    "ai_summary": "åŸºäºäº‘åŸç”Ÿæ¶æ„çš„AIæœåŠ¡æ¡†æ¶ï¼Œæ”¯æŒå¤šæ¨¡æ€æ•°æ®å¤„ç†ã€gRPC/HTTP/WebSocketåè®®é€šä¿¡ä»¥åŠä¼ä¸šçº§éƒ¨ç½²ï¼ˆKubernetes/Docker Composeï¼‰ï¼Œé€šè¿‡å†…ç½®Executor Hubå’Œä¸€é”®å¼äº‘å¹³å°é›†æˆç®€åŒ–å¼€å‘æµç¨‹ã€‚",
    "ai_tech_stack": "[\"Python\", \"gRPC\", \"Docker\", \"Kubernetes\", \"DocArray\", \"Cloud-Native\"]",
    "ai_use_cases": "[\"\\u6784\\u5efa\\u591a\\u6a21\\u6001AI API\\u670d\\u52a1\\uff08\\u6587\\u672c\\u3001\\u56fe\\u50cf\\u7b49\\uff09\", \"\\u4f01\\u4e1a\\u7ea7\\u6a21\\u578b\\u90e8\\u7f72\\u4e0e\\u7ba1\\u7406\\u5e73\\u53f0\\u96c6\\u6210\", \"\\u4f4e\\u4ee3\\u7801/\\u65e0\\u4ee3\\u7801RAG\\u7cfb\\u7edf\\u642d\\u5efa\"]",
    "ai_difficulty": 3,
    "ai_quick_start": "pip install jina && python -m serve --deployment=Deployment(name='my-ai-service')",
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.825013",
    "last_analyzed": "2026-01-16T02:31:11.695098",
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "849239437",
    "name": "Qwen3-VL",
    "full_name": "QwenLM/Qwen3-VL",
    "category": "multimodal",
    "stars": 17787,
    "forks": 1521,
    "description": "Qwen3-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud.",
    "url": "https://github.com/QwenLM/Qwen3-VL",
    "homepage": "",
    "language": "Jupyter Notebook",
    "topics": "[]",
    "created_at": "2024-08-29T08:30:38Z",
    "updated_at": "2026-01-15T17:39:37Z",
    "readme_content": null,
    "ai_summary": "Qwen3-VL æ˜¯é˜¿é‡Œå·´å·´äº‘å¼€å‘çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç³»åˆ—ï¼Œä¸“æ³¨äºå°†è§†è§‰ä¸è¯­è¨€èƒ½åŠ›ç»“åˆï¼Œæ”¯æŒæ–‡æœ¬ç”Ÿæˆã€å›¾åƒç†è§£åŠè·¨æ¨¡æ€ä»»åŠ¡ï¼›åŸºäº Transformer æ¶æ„å’Œæ³¨æ„åŠ›æœºåˆ¶å®ç°é«˜æ•ˆå¤šæ¨¡æ€å¤„ç†ï¼Œå¹¶æä¾›æµå¼å“åº”åŠŸèƒ½ã€‚",
    "ai_tech_stack": "[\"PyTorch\", \"Hugging Face Transformers\", \"Jupyter Notebook\", \"CLIP (\\u89c6\\u89c9\\u7f16\\u7801\\u5668)\", \"DeepSpeed/FSDP\"]",
    "ai_use_cases": "[\"\\u56fe\\u50cf\\u63cf\\u8ff0\\u751f\\u6210\", \"\\u89c6\\u89c9\\u95ee\\u7b54\\u7cfb\\u7edf\\uff08VQA\\uff09\", \"\\u8de8\\u6a21\\u6001\\u6587\\u6863\\u5206\\u6790\\u4e0e\\u603b\\u7ed3\", \"\\u591a\\u6a21\\u6001\\u5bf9\\u8bdd\\u673a\\u5668\\u4eba\"]",
    "ai_difficulty": 5,
    "ai_quick_start": "jupyter notebook --kernel python3 && pip install torch transformers clip",
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.825540",
    "last_analyzed": "2026-01-16T02:49:33.949490",
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "874559208",
    "name": "Janus",
    "full_name": "deepseek-ai/Janus",
    "category": "multimodal",
    "stars": 17664,
    "forks": 2234,
    "description": "Janus-Series: Unified Multimodal Understanding and Generation Models",
    "url": "https://github.com/deepseek-ai/Janus",
    "homepage": "",
    "language": "Python",
    "topics": "[\"any-to-any\", \"foundation-models\", \"llm\", \"multimodal\", \"unified-model\", \"vision-language-pretraining\"]",
    "created_at": "2024-10-18T03:48:16Z",
    "updated_at": "2026-01-15T13:45:44Z",
    "readme_content": null,
    "ai_summary": "Janus æ˜¯ä¸€ä¸ªç»Ÿä¸€å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆæ¨¡å‹ç³»åˆ—ï¼Œä¸“æ³¨äºæ•´åˆæ–‡æœ¬ã€å›¾åƒç­‰ä¸åŒæ¨¡æ€çš„èƒ½åŠ›ï¼Œæä¾›è·¨æ¨¡æ€äº¤äº’çš„æ ¸å¿ƒæŠ€æœ¯ç‰¹ç‚¹åœ¨äºå…¶Transformeræ¶æ„å’Œç«¯åˆ°ç«¯è®­ç»ƒæµç¨‹ï¼Œç‹¬ç‰¹ä¼˜åŠ¿æ˜¯å®ç°å•ä¸€æ¨¡å‹å¤„ç†å¤šç§è¾“å…¥è¾“å‡ºæ ¼å¼",
    "ai_tech_stack": "[\"PyTorch\", \"Hugging Face Transformers\", \"FastAPI\", \"ChromaDB/FAISS\"]",
    "ai_use_cases": "[\"\\u667a\\u80fd\\u5ba2\\u670d\\u591a\\u6a21\\u6001\\u4ea4\\u4e92\\u7cfb\\u7edf\", \"\\u8de8\\u5a92\\u4f53\\u5185\\u5bb9\\u521b\\u4f5c\\u4e0e\\u751f\\u6210\\u5de5\\u5177\", \"\\u6559\\u80b2\\u9886\\u57df\\u7684\\u591a\\u5a92\\u4f53\\u77e5\\u8bc6\\u95ee\\u7b54\\u5e73\\u53f0\"]",
    "ai_difficulty": 5,
    "ai_quick_start": "pip install -e . && python scripts/run_demo.py --device cuda",
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.826079",
    "last_analyzed": "2026-01-16T02:52:01.836422",
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "642642539",
    "name": "Awesome-Multimodal-Large-Language-Models",
    "full_name": "BradyFU/Awesome-Multimodal-Large-Language-Models",
    "category": "multimodal",
    "stars": 17188,
    "forks": 1103,
    "description": ":sparkles::sparkles:Latest Advances on Multimodal Large Language Models",
    "url": "https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models",
    "homepage": "",
    "language": null,
    "topics": "[\"chain-of-thought\", \"in-context-learning\", \"instruction-following\", \"instruction-tuning\", \"large-language-models\", \"large-vision-language-model\", \"large-vision-language-models\", \"multi-modality\", \"multimodal-chain-of-thought\", \"multimodal-in-context-learning\", \"multimodal-instruction-tuning\", \"multimodal-large-language-models\", \"visual-instruction-tuning\"]",
    "created_at": "2023-05-19T03:02:29Z",
    "updated_at": "2026-01-15T16:15:48Z",
    "readme_content": null,
    "ai_summary": "å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æŠ€æœ¯èµ„æºç´¢å¼•å¹³å°ï¼Œç³»ç»Ÿæ•´ç†è§†è§‰ä¸æ–‡æœ¬äº¤äº’ç ”ç©¶åŠåº”ç”¨æ¡ˆä¾‹",
    "ai_tech_stack": "[\"GitHub Pages\", \"Markdown\"]",
    "ai_use_cases": "[\"\\u7814\\u7a76\\u8005\\u67e5\\u9605\\u6700\\u65b0\\u8bba\\u6587\\u4e0e\\u5de5\\u5177\\u5f00\\u53d1\\u8fdb\\u5c55\", \"\\u5f00\\u53d1\\u8005\\u5feb\\u901f\\u5b9a\\u4f4d\\u53ef\\u7528\\u7684\\u5f00\\u6e90\\u591a\\u6a21\\u6001LLM\\u5b9e\\u73b0\\u65b9\\u6848\"]",
    "ai_difficulty": 1,
    "ai_quick_start": "git clone https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.git && cd awesome-multimodal-llms && hugo server -D",
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.826618",
    "last_analyzed": "2026-01-16T02:54:47.580230",
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "200722670",
    "name": "NeMo",
    "full_name": "NVIDIA-NeMo/NeMo",
    "category": "multimodal",
    "stars": 16566,
    "forks": 3287,
    "description": "A scalable generative AI framework built for researchers and developers working on Large Language Models, Multimodal, and Speech AI (Automatic Speech Recognition and Text-to-Speech)",
    "url": "https://github.com/NVIDIA-NeMo/NeMo",
    "homepage": "https://docs.nvidia.com/nemo-framework/user-guide/latest/overview.html",
    "language": "Python",
    "topics": "[\"asr\", \"deeplearning\", \"generative-ai\", \"machine-translation\", \"neural-networks\", \"speaker-diariazation\", \"speaker-recognition\", \"speech-synthesis\", \"speech-translation\", \"tts\"]",
    "created_at": "2019-08-05T20:16:42Z",
    "updated_at": "2026-01-15T14:05:41Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.827137",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "181436799",
    "name": "MNN",
    "full_name": "alibaba/MNN",
    "category": "multimodal",
    "stars": 13918,
    "forks": 2169,
    "description": "MNN is a blazing fast, lightweight deep learning framework, battle-tested by business-critical use cases in Alibaba. Full multimodal LLM Android App:[MNN-LLM-Android](./apps/Android/MnnLlmChat/README.md). MNN TaoAvatar Android - Local 3D Avatar Intelligence: apps/Android/Mnn3dAvatar/README.md",
    "url": "https://github.com/alibaba/MNN",
    "homepage": "http://www.mnn.zone/",
    "language": "C++",
    "topics": "[\"arm\", \"convolution\", \"deep-learning\", \"embedded-devices\", \"llm\", \"machine-learning\", \"ml\", \"mnn\", \"transformer\", \"vulkan\", \"winograd-algorithm\"]",
    "created_at": "2019-04-15T07:40:18Z",
    "updated_at": "2026-01-15T13:09:13Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.827668",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "390536799",
    "name": "open_clip",
    "full_name": "mlfoundations/open_clip",
    "category": "multimodal",
    "stars": 13241,
    "forks": 1225,
    "description": "An open source implementation of CLIP.",
    "url": "https://github.com/mlfoundations/open_clip",
    "homepage": "",
    "language": "Python",
    "topics": "[\"computer-vision\", \"contrastive-loss\", \"deep-learning\", \"language-model\", \"multi-modal-learning\", \"pretrained-models\", \"pytorch\", \"zero-shot-classification\"]",
    "created_at": "2021-07-28T23:24:39Z",
    "updated_at": "2026-01-15T13:40:53Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.828202",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "26850443",
    "name": "rust-clippy",
    "full_name": "rust-lang/rust-clippy",
    "category": "multimodal",
    "stars": 12815,
    "forks": 1880,
    "description": "A bunch of lints to catch common mistakes and improve your Rust code. Book: https://doc.rust-lang.org/clippy/",
    "url": "https://github.com/rust-lang/rust-clippy",
    "homepage": "https://rust-lang.github.io/rust-clippy/",
    "language": "Rust",
    "topics": "[\"lint\", \"rust\"]",
    "created_at": "2014-11-19T07:49:21Z",
    "updated_at": "2026-01-15T17:28:16Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.828738",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "157198623",
    "name": "clip-as-service",
    "full_name": "jina-ai/clip-as-service",
    "category": "multimodal",
    "stars": 12805,
    "forks": 2078,
    "description": "ğŸ„ Scalable embedding, reasoning, ranking for images and sentences with CLIP",
    "url": "https://github.com/jina-ai/clip-as-service",
    "homepage": "https://clip-as-service.jina.ai",
    "language": "Python",
    "topics": "[\"bert\", \"bert-as-service\", \"clip-as-service\", \"clip-model\", \"cross-modal-retrieval\", \"cross-modality\", \"deep-learning\", \"image2vec\", \"multi-modality\", \"neural-search\", \"onnx\", \"openai\", \"pytorch\", \"sentence-encoding\", \"sentence2vec\"]",
    "created_at": "2018-11-12T10:48:50Z",
    "updated_at": "2026-01-14T02:19:05Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.829277",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "673412924",
    "name": "ms-swift",
    "full_name": "modelscope/ms-swift",
    "category": "multimodal",
    "stars": 12181,
    "forks": 1137,
    "description": "Use PEFT or Full-parameter to CPT/SFT/DPO/GRPO 600+ LLMs (Qwen3, Qwen3-MoE, DeepSeek-R1, GLM4.5, InternLM3, Llama4, ...) and 300+ MLLMs (Qwen3-VL, Qwen3-Omni, InternVL3.5, Ovis2.5, GLM4.5v, Llava, Phi4, ...) (AAAI 2025).",
    "url": "https://github.com/modelscope/ms-swift",
    "homepage": "https://swift.readthedocs.io/zh-cn/latest/",
    "language": "Python",
    "topics": "[\"deepseek-r1\", \"embedding\", \"grpo\", \"internvl\", \"liger\", \"llama\", \"llama4\", \"llm\", \"lora\", \"megatron\", \"moe\", \"multimodal\", \"open-r1\", \"peft\", \"qwen3\", \"qwen3-next\", \"qwen3-omni\", \"qwen3-vl\", \"reranker\", \"sft\"]",
    "created_at": "2023-08-01T15:06:39Z",
    "updated_at": "2026-01-15T13:41:28Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.829787",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "528238131",
    "name": "LAVIS",
    "full_name": "salesforce/LAVIS",
    "category": "multimodal",
    "stars": 11116,
    "forks": 1090,
    "description": "LAVIS - A One-stop Library for Language-Vision Intelligence",
    "url": "https://github.com/salesforce/LAVIS",
    "homepage": "",
    "language": "Jupyter Notebook",
    "topics": "[\"deep-learning\", \"deep-learning-library\", \"image-captioning\", \"multimodal-datasets\", \"multimodal-deep-learning\", \"salesforce\", \"vision-and-language\", \"vision-framework\", \"vision-language-pretraining\", \"vision-language-transformer\", \"visual-question-anwsering\"]",
    "created_at": "2022-08-24T02:36:01Z",
    "updated_at": "2026-01-15T16:29:18Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.830328",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "714143245",
    "name": "self-operating-computer",
    "full_name": "OthersideAI/self-operating-computer",
    "category": "multimodal",
    "stars": 10096,
    "forks": 1391,
    "description": "A framework to enable multimodal models to operate a computer.",
    "url": "https://github.com/OthersideAI/self-operating-computer",
    "homepage": "https://www.hyperwriteai.com/self-operating-computer",
    "language": "Python",
    "topics": "[\"automation\", \"openai\", \"pyautogui\"]",
    "created_at": "2023-11-04T03:13:45Z",
    "updated_at": "2026-01-15T10:08:39Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.831379",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "479289739",
    "name": "rerun",
    "full_name": "rerun-io/rerun",
    "category": "multimodal",
    "stars": 9970,
    "forks": 619,
    "description": "An open source SDK for logging, storing, querying, and visualizing multimodal and multi-rate data",
    "url": "https://github.com/rerun-io/rerun",
    "homepage": "https://rerun.io/",
    "language": "Rust",
    "topics": "[\"computer-vision\", \"cpp\", \"multimodal\", \"python\", \"robotics\", \"rust\", \"visualization\"]",
    "created_at": "2022-04-08T07:30:05Z",
    "updated_at": "2026-01-15T17:44:39Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.831913",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "736272311",
    "name": "pipecat",
    "full_name": "pipecat-ai/pipecat",
    "category": "multimodal",
    "stars": 9837,
    "forks": 1626,
    "description": "Open Source framework for voice and multimodal conversational AI",
    "url": "https://github.com/pipecat-ai/pipecat",
    "homepage": "https://pipecat.ai",
    "language": "Python",
    "topics": "[\"ai\", \"chatbot-framework\", \"chatbots\", \"real-time\", \"voice\", \"voice-assistant\"]",
    "created_at": "2023-12-27T12:59:00Z",
    "updated_at": "2026-01-15T17:16:18Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.832445",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "47859258",
    "name": "xgo",
    "full_name": "goplus/xgo",
    "category": "multimodal",
    "stars": 9381,
    "forks": 562,
    "description": "XGo is a programming language that reads like plain English. But it's also incredibly powerful â€” it lets you leverage assets from C/C++, Go, Python, and JavaScript/TypeScript, creating a unified software engineering ecosystem. Our vision is to enable everyone to become a builder of the world.",
    "url": "https://github.com/goplus/xgo",
    "homepage": "https://xgo.dev",
    "language": "Go",
    "topics": "[\"ai-native\", \"data-science\", \"golang\", \"goplus\", \"low-code\", \"programming-language\", \"scientific-computing\", \"stem\", \"stem-education\", \"xgo\"]",
    "created_at": "2015-12-12T01:21:39Z",
    "updated_at": "2026-01-15T10:22:26Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.832974",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "144708327",
    "name": "gorse",
    "full_name": "gorse-io/gorse",
    "category": "multimodal",
    "stars": 9296,
    "forks": 849,
    "description": "Gorse open source recommender system engine supports multimodal content via embedding",
    "url": "https://github.com/gorse-io/gorse",
    "homepage": "https://gorse.io",
    "language": "Go",
    "topics": "[\"collaborative-filtering\", \"go\", \"knn\", \"machine-learning\", \"recommender-system\"]",
    "created_at": "2018-08-14T11:01:09Z",
    "updated_at": "2026-01-15T15:59:35Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.833503",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "736812439",
    "name": "moondream",
    "full_name": "vikhyat/moondream",
    "category": "multimodal",
    "stars": 9216,
    "forks": 718,
    "description": "tiny vision language model",
    "url": "https://github.com/vikhyat/moondream",
    "homepage": "https://moondream.ai",
    "language": "Python",
    "topics": "[]",
    "created_at": "2023-12-29T00:27:18Z",
    "updated_at": "2026-01-15T15:22:31Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.834011",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "99412308",
    "name": "seatunnel",
    "full_name": "apache/seatunnel",
    "category": "multimodal",
    "stars": 9049,
    "forks": 2159,
    "description": "SeaTunnel is a multimodal, high-performance, distributed, massive data integration tool.",
    "url": "https://github.com/apache/seatunnel",
    "homepage": "https://seatunnel.apache.org/",
    "language": "Java",
    "topics": "[\"apache\", \"batch\", \"cdc\", \"change-data-capture\", \"data-ingestion\", \"data-integration\", \"elt\", \"embeddings\", \"high-performance\", \"llm\", \"multimodal\", \"offline\", \"real-time\", \"streaming\"]",
    "created_at": "2017-08-05T09:14:47Z",
    "updated_at": "2026-01-15T18:02:37Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.834011",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "653496050",
    "name": "inference",
    "full_name": "xorbitsai/inference",
    "category": "multimodal",
    "stars": 8954,
    "forks": 787,
    "description": "Swap GPT for any LLM by changing a single line of code. Xinference lets you run open-source, speech, and multimodal models on cloud, on-prem, or your laptop â€” all through one unified, production-ready inference API.",
    "url": "https://github.com/xorbitsai/inference",
    "homepage": "https://inference.readthedocs.io",
    "language": "Python",
    "topics": "[\"artificial-intelligence\", \"chatglm\", \"deployment\", \"flan-t5\", \"gemma\", \"ggml\", \"glm4\", \"inference\", \"llama\", \"llama3\", \"llamacpp\", \"llm\", \"machine-learning\", \"mistral\", \"openai-api\", \"pytorch\", \"qwen\", \"vllm\", \"whisper\", \"wizardlm\"]",
    "created_at": "2023-06-14T07:05:04Z",
    "updated_at": "2026-01-15T15:31:59Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.835035",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "607441698",
    "name": "lancedb",
    "full_name": "lancedb/lancedb",
    "category": "multimodal",
    "stars": 8497,
    "forks": 705,
    "description": "Developer-friendly OSS embedded retrieval library for multimodal AI. Search More; Manage Less.",
    "url": "https://github.com/lancedb/lancedb",
    "homepage": "https://lancedb.com/docs",
    "language": "Rust",
    "topics": "[\"approximate-nearest-neighbor-search\", \"image-search\", \"nearest-neighbor-search\", \"recommender-system\", \"search-engine\", \"semantic-search\", \"similarity-search\", \"vector-database\"]",
    "created_at": "2023-02-28T01:15:17Z",
    "updated_at": "2026-01-15T17:47:01Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.836055",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "37778564",
    "name": "Clipy",
    "full_name": "Clipy/Clipy",
    "category": "multimodal",
    "stars": 8346,
    "forks": 714,
    "description": "Clipboard extension app for macOS.",
    "url": "https://github.com/Clipy/Clipy",
    "homepage": "https://clipy-app.com",
    "language": "Swift",
    "topics": "[\"clipboard\", \"clipboard-extension\", \"clipmenu\", \"macos\", \"swift\", \"xcode\"]",
    "created_at": "2015-06-20T17:21:24Z",
    "updated_at": "2026-01-15T13:27:08Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.836055",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "275118967",
    "name": "boxmot",
    "full_name": "mikel-brostrom/boxmot",
    "category": "multimodal",
    "stars": 7943,
    "forks": 1874,
    "description": "BoxMOT: Pluggable SOTA multi-object tracking modules modules for segmentation, object detection and pose estimation models",
    "url": "https://github.com/mikel-brostrom/boxmot",
    "homepage": "https://deepwiki.com/mikel-brostrom/boxmot",
    "language": "Python",
    "topics": "[\"boosttrack\", \"botsort\", \"bytetrack\", \"clip\", \"deep-learning\", \"deepocsort\", \"improvedassociation\", \"machine-learning\", \"mot\", \"mots\", \"multi-object-tracking\", \"multi-object-tracking-segmentation\", \"ocsort\", \"oriented-bounding-box-tracking\", \"osnet\", \"segmentation\", \"strongsort\", \"tensorrt\", \"tracking-by-detection\", \"yolo\"]",
    "created_at": "2020-06-26T09:26:23Z",
    "updated_at": "2026-01-15T06:34:36Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.837063",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  },
  {
    "id": "644293378",
    "name": "X-AnyLabeling",
    "full_name": "CVHub520/X-AnyLabeling",
    "category": "multimodal",
    "stars": 7817,
    "forks": 860,
    "description": "Effortless data labeling with AI support from Segment Anything and other awesome models.",
    "url": "https://github.com/CVHub520/X-AnyLabeling",
    "homepage": "https://github.com/CVHub520/X-AnyLabeling-Server",
    "language": "Python",
    "topics": "[\"artificial-intelligence\", \"clip\", \"computer-vision\", \"deep-learning\", \"groundingdino\", \"image-annotation-tool\", \"image-classification\", \"image-labeling-tool\", \"image-matting\", \"instance-segmentation\", \"machine-learning\", \"object-detection\", \"ocr\", \"onnxruntime\", \"paddlepaddle\", \"pose-estimation\", \"rotated-object-detection\", \"sam\", \"vision-language-model\", \"yolo\"]",
    "created_at": "2023-05-23T08:14:30Z",
    "updated_at": "2026-01-15T15:55:53Z",
    "readme_content": null,
    "ai_summary": null,
    "ai_tech_stack": null,
    "ai_use_cases": null,
    "ai_difficulty": null,
    "ai_quick_start": null,
    "ai_tutorial": null,
    "last_scanned": "2026-01-16T02:05:31.837063",
    "last_analyzed": null,
    "screenshot": null,
    "ai_visual_summary": null,
    "ai_rag_summary": null
  }
]